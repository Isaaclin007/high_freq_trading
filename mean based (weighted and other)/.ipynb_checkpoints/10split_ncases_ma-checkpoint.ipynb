{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from datetime import datetime,timedelta\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA'\n",
    "os.chdir('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA')\n",
    "file_list=os.listdir(path)\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '2019.01.02.csv',\n",
       " '2019.01.03.csv',\n",
       " '2019.01.04.csv',\n",
       " '2019.01.07.csv',\n",
       " '2019.01.08.csv',\n",
       " '2019.01.09.csv',\n",
       " '2019.01.10.csv',\n",
       " '2019.01.11.csv',\n",
       " '2019.01.14.csv',\n",
       " '2019.01.15.csv',\n",
       " '2019.01.16.csv',\n",
       " '2019.01.17.csv',\n",
       " '2019.01.18.csv',\n",
       " '2019.01.21.csv',\n",
       " '2019.01.22.csv',\n",
       " '2019.01.23.csv',\n",
       " '2019.01.24.csv',\n",
       " '2019.01.25.csv',\n",
       " '2019.01.28.csv',\n",
       " '2019.01.29.csv',\n",
       " '2019.01.30.csv',\n",
       " '2019.01.31.csv',\n",
       " '2019.02.01.csv',\n",
       " '2019.02.11.csv',\n",
       " '2019.02.12.csv',\n",
       " '2019.02.13.csv',\n",
       " '2019.02.14.csv',\n",
       " '2019.02.15.csv',\n",
       " '2019.02.18.csv',\n",
       " '2019.02.19.csv',\n",
       " '2019.02.20.csv',\n",
       " '2019.02.21.csv',\n",
       " '2019.02.22.csv',\n",
       " '2019.02.25.csv',\n",
       " '2019.02.26.csv',\n",
       " '2019.02.27.csv',\n",
       " '2019.02.28.csv',\n",
       " '2019.03.01.csv',\n",
       " '2019.03.04.csv',\n",
       " '2019.03.05.csv',\n",
       " '2019.03.06.csv',\n",
       " '2019.03.07.csv',\n",
       " '2019.03.08.csv',\n",
       " '2019.03.11.csv',\n",
       " '2019.03.12.csv',\n",
       " '2019.03.13.csv',\n",
       " '2019.03.14.csv',\n",
       " '2019.03.15.csv',\n",
       " '2019.03.18.csv',\n",
       " '2019.03.19.csv',\n",
       " '2019.03.20.csv',\n",
       " '2019.03.21.csv',\n",
       " '2019.03.22.csv',\n",
       " '2019.03.25.csv',\n",
       " '2019.03.26.csv',\n",
       " '2019.03.27.csv',\n",
       " '2019.03.28.csv',\n",
       " '2019.03.29.csv',\n",
       " '2019.04.01.csv',\n",
       " '2019.04.02.csv',\n",
       " '2019.04.03.csv',\n",
       " '2019.04.04.csv',\n",
       " '2019.04.08.csv',\n",
       " '2019.04.09.csv',\n",
       " '2019.04.10.csv',\n",
       " '2019.04.11.csv',\n",
       " '2019.04.12.csv',\n",
       " '2019.04.15.csv',\n",
       " '2019.04.16.csv',\n",
       " '2019.04.17.csv',\n",
       " '2019.04.18.csv',\n",
       " '2019.04.19.csv',\n",
       " '2019.04.22.csv',\n",
       " '2019.04.23.csv',\n",
       " '2019.04.24.csv',\n",
       " '2019.04.25.csv',\n",
       " '2019.04.26.csv',\n",
       " '2019.04.29.csv',\n",
       " '2019.04.30.csv',\n",
       " '2019.05.06.csv',\n",
       " '2019.05.07.csv',\n",
       " '2019.05.08.csv',\n",
       " '2019.05.09.csv',\n",
       " 'results']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CSV files available for product TA and their dates\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for splitting the data into categories based on their percentiles  \n",
    "class categorise():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(7)\n",
    "                else:\n",
    "                    temp.append(8)\n",
    "            if i<0:\n",
    "                if i>self.threshold[0][2]:\n",
    "                    temp.append(4)\n",
    "                elif i>self.threshold[0][1]:\n",
    "                    temp.append(3)\n",
    "                elif i>self.threshold[0][0]:\n",
    "                    temp.append(2)\n",
    "                else:\n",
    "                    temp.append(1)\n",
    "        return np.asarray(temp)\n",
    "    \n",
    "class categorise_simple():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        self.threshold.append(np.percentile(array,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                else:\n",
    "                    temp.append(4)\n",
    "        return np.asarray(temp)    \n",
    "    \n",
    "class categorise_10():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[10,20,30,40,50,60,70,80,90]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(11)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(12)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(13)\n",
    "                elif i<self.threshold[1][3]:\n",
    "                    temp.append(14)\n",
    "                elif i<self.threshold[1][4]:\n",
    "                    temp.append(15)\n",
    "                elif i<self.threshold[1][5]:\n",
    "                    temp.append(16)\n",
    "                elif i<self.threshold[1][6]:\n",
    "                    temp.append(17)\n",
    "                elif i<self.threshold[1][7]:\n",
    "                    temp.append(18)\n",
    "                elif i<self.threshold[1][8]:\n",
    "                    temp.append(19)                    \n",
    "                else:\n",
    "                    temp.append(20)\n",
    "            if i<0:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                elif i<self.threshold[0][3]:\n",
    "                    temp.append(4)\n",
    "                elif i<self.threshold[0][4]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[0][5]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[0][6]:\n",
    "                    temp.append(7)\n",
    "                elif i<self.threshold[0][7]:\n",
    "                    temp.append(8)\n",
    "                elif i<self.threshold[0][8]:\n",
    "                    temp.append(9)                    \n",
    "                else:\n",
    "                    temp.append(10)\n",
    "        return np.asarray(temp)    \n",
    "    \n",
    "class categorise_x(): #flexible number of categories\n",
    "    \n",
    "    def __init__(self,x):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[]\n",
    "        self.num=x\n",
    "        for i in range(1,x):\n",
    "            self.percentiles.append(i*100/x)        \n",
    "            \n",
    "    def fit(self,array):\n",
    "        \n",
    "        positive=array[array>0]\n",
    "        negative=array[array<=0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "        \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for num in array:\n",
    "            if num<0:\n",
    "                counter=0\n",
    "                for i in self.threshold[0]:\n",
    "                    if num>=i:\n",
    "                        counter+=1\n",
    "                    else:\n",
    "                        break\n",
    "                temp.append(counter+1)\n",
    "            else:\n",
    "                counter=0\n",
    "                for i in self.threshold[1]:\n",
    "                    if num>=i:\n",
    "                        counter+=1\n",
    "                    else:\n",
    "                        break\n",
    "                temp.append(counter+self.num+1)\n",
    "        return np.asarray(temp)\n",
    "    \n",
    "#class for keeping track of time since last cross, cross being positive to negative or reverse        \n",
    "class cross():\n",
    "    def __init__(self):\n",
    "        self.time_last_cross=0\n",
    "        self.current_sign=True\n",
    "        self.last_time=datetime(1900, 1, 1, 8, 59)\n",
    "    def get_time(self,time,price):\n",
    "        if (time-self.last_time)>timedelta(minutes=1):\n",
    "            self.last_time=time\n",
    "            self.time_last_cross=time\n",
    "            return 0\n",
    "        self.last_time=time\n",
    "        if (price>0) and self.current_sign : #if price positive and current trend is also positive\n",
    "            return (time-self.time_last_cross).total_seconds()\n",
    "        elif (price<0) and (not self.current_sign): #if price negative and current trend is negative\n",
    "            return (time-self.time_last_cross).total_seconds()\n",
    "        else: #if price positive, trend negative or price negative, trend positive\n",
    "            self.time_last_cross=time\n",
    "            self.current_sign=(price>0)\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for calculating indicators\n",
    "def calc_smart_price(dataset):\n",
    "    data=dataset.copy()\n",
    "    \n",
    "    #to combat the limit up event, where price is set to 0. \n",
    "    rows=(data.loc[:,'BidPrice1']==0) #count rows of bid price equal 0\n",
    "    if (np.any(rows)): #if there is such a row\n",
    "        data.at[rows,'BidPrice1']=data.loc[rows,'AskPrice1'] #for that row, assign ask price to it\n",
    "    rows=(data.loc[:,'AskPrice1']==0) #do the same for ask price\n",
    "    if (np.any(rows)):\n",
    "        data.at[rows,'AskPrice1']=data.loc[rows,'BidPrice1'] \n",
    "        \n",
    "    data['smart_price']=data.loc[:,'BidPrice1']*data.loc[:,'AskVol1']+data.loc[:,'AskPrice1']*data.loc[:,'BidVol1']\n",
    "    data.at[:,'smart_price']=data.loc[:,'smart_price']/(data.loc[:,['BidVol1','AskVol1']].sum(axis=1))  \n",
    "    return data\n",
    "\n",
    "def calc_present_vol(dataset):\n",
    "    data=dataset.copy()\n",
    "    data['current_vol']=data.loc[:,'Volume'].diff().fillna(0)/2\n",
    "    return data\n",
    "\n",
    "def calc_future_price(dataset,time_ahead=30,time_index=44, price_col=-2):\n",
    "    data=dataset.copy()\n",
    "    future_price=[]\n",
    "    length=len(data)\n",
    "    for i in range(len(data)):\n",
    "        current_time=data[i,time_index]+timedelta(seconds=time_ahead)\n",
    "        \n",
    "        j=0 #could alternatively use 30 x 3 then search forward and backward\n",
    "        \n",
    "        #search forwards\n",
    "        while((i+j)<length and current_time>data[(i+j),time_index]):\n",
    "            j+=1\n",
    "        if (i+j)<length:\n",
    "            #if index is in the dataframe\n",
    "            future_price.append(data[(i+j),price_col]) \n",
    "        else:\n",
    "            #price ahead does not exist\n",
    "            future_price.append(np.nan) \n",
    "    future_price=np.asarray(future_price)\n",
    "    future_price=np.expand_dims(future_price,axis=1)\n",
    "    return np.concatenate((data,future_price),axis=1)\n",
    "\n",
    "def calc_edge(dataset,future_col,current_col):\n",
    "    data=dataset.copy()\n",
    "    temp=data[:,future_col]-data[:,current_col]\n",
    "    temp=np.expand_dims(temp,axis=1)\n",
    "    return np.concatenate((data,temp),axis=1)\n",
    "\n",
    "def set_index(dataset,time_index=44):\n",
    "    data=dataset.copy()\n",
    "    index=data[:,time_index].astype(int)\n",
    "    new_index=[]\n",
    "    for j in range(len(index)):\n",
    "        i=str(index[j]*1000)\n",
    "        if len(i)==11:\n",
    "            i='0'+i\n",
    "        i=i[:-10]+':'+i[-10:]\n",
    "        i=i[:-8]+':'+i[-8:]\n",
    "        i=i[:-6]+':'+i[-6:]\n",
    "        new_index.append(datetime.strptime(i,\"%H:%M:%S:%f\"))\n",
    "    data[:,time_index]=new_index\n",
    "    return data\n",
    "\n",
    "def calc_sma_fast(dataset,price_col,duration=1,time_index=44): #faster way to calculate SMA, 0.05 seconds for 5000 rows\n",
    "    data=dataset.copy()\n",
    "    sma_values=[] \n",
    "    smart_sum=np.cumsum(data[:,price_col]) #smart price column is -4\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        #finding ending point\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        \n",
    "        #finding start point\n",
    "        j=220*duration#4x60=240\n",
    "        \n",
    "        if i-j>0:\n",
    "            if data[i-j,time_index]>last_time: \n",
    "                \n",
    "                #if starting point time is greater than ending point time\n",
    "                #search backward\n",
    "                while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "                    j+=1\n",
    "                    \n",
    "                #activate next line in order to debug and troubleshoot\n",
    "                #if data[i-j,time_index]!=last_time:\n",
    "                #    print('backward',i,j,data[i,time_index],data[i-j,time_index],last_time)\n",
    "\n",
    "                sma=(smart_sum[i]-smart_sum[i-j])/j\n",
    "                sma_values.append(sma)                \n",
    "                \n",
    "            else: \n",
    "                \n",
    "                #search forward\n",
    "                while(data[i-j,time_index]<last_time):\n",
    "                    j-=1\n",
    "                    \n",
    "                #activate next line in order to debug and troubleshoot\n",
    "                #if data[i-j,time_index]!=last_time:\n",
    "                #    print('forward',i,j,data[i,time_index],data[i-j,time_index],last_time)\n",
    "                \n",
    "                if j!=0:\n",
    "                    if data[i-j,time_index]!=last_time:\n",
    "                        j+=1\n",
    "                    sma=(smart_sum[i]-smart_sum[i-j])/j\n",
    "                    sma_values.append(sma)   \n",
    "                    \n",
    "                else:\n",
    "                    sma_values.append(data[i,price_col])\n",
    "                    \n",
    "        else: #starting point is at 0\n",
    "            \n",
    "            sma=smart_sum[i]/(i+1)\n",
    "            sma_values.append(sma)                       \n",
    "\n",
    "    sma_values=np.asarray(sma_values)\n",
    "    sma_values=data[:,price_col]-sma_values\n",
    "    sma_values=np.expand_dims(sma_values,axis=1)\n",
    "    return np.concatenate((data,sma_values),axis=1)  \n",
    "\n",
    "def calc_volatility_slow(dataset,price_col,duration=15,time_index=44): \n",
    "    data=dataset.copy()\n",
    "    diff=np.diff(dataset[:,price_col])\n",
    "    diff=np.insert(diff,0,0)\n",
    "    \n",
    "    volatility_values=[]\n",
    "    for i in range(len(data)):\n",
    "            \n",
    "        #finding ending point\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        \n",
    "        #finding start point\n",
    "        j=220*duration#4x60=240\n",
    "        \n",
    "        if i-j>0:\n",
    "            if data[i-j,time_index]>last_time: \n",
    "                #if starting point time is greater than ending point time\n",
    "                #search backward\n",
    "                while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "                    j+=1\n",
    "                vol=np.std(diff[i-j:i])\n",
    "                volatility_values.append(vol)                     \n",
    "            else: \n",
    "                #search forward\n",
    "                while(data[i-j,time_index]<last_time):\n",
    "                    j-=1\n",
    "                if j!=0:\n",
    "                    vol=np.std(diff[i-j:i])\n",
    "                    volatility_values.append(vol) \n",
    "                else:\n",
    "                    volatility_values.append(0)\n",
    "        else: #starting point is at 0\n",
    "            if i==0:\n",
    "                volatility_values.append(0)\n",
    "                continue\n",
    "            vol=np.std(diff[:i])\n",
    "            volatility_values.append(vol)   \n",
    "            \n",
    "    volatility_values=np.asarray(volatility_values)\n",
    "    volatility_values=np.expand_dims(volatility_values,axis=1)\n",
    "    return np.concatenate((data,volatility_values),axis=1)\n",
    "\n",
    "def calc_past_vol(dataset,vol_col,duration=1,time_index=44): #\n",
    "    data=dataset.copy()\n",
    "    vol_values=[] \n",
    "    vol_sum=np.cumsum(data[:,vol_col])\n",
    "    for i in range(len(data)):\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        j=220*duration#4x60=240\n",
    "        while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "            j+=1\n",
    "        if (i-j>=0):\n",
    "            vol=(vol_sum[i]-vol_sum[i-j])\n",
    "            vol_values.append(vol)\n",
    "        else:\n",
    "            vol=vol_sum[i]\n",
    "            vol_values.append(vol)\n",
    "    vol_values=np.asarray(vol_values)\n",
    "    vol_values=np.expand_dims(vol_values,axis=1)\n",
    "    return np.concatenate((data,vol_values),axis=1) \n",
    "\n",
    "def last_cross(dataset,price_col,time_index=44):\n",
    "    data=dataset.copy()\n",
    "    last_cross=cross()\n",
    "    timings=[]\n",
    "    for i in range(len(data)):\n",
    "        timings.append(last_cross.get_time(data[i,time_index],data[i,price_col]))\n",
    "    timings=np.asarray(timings)\n",
    "    timings=np.expand_dims(timings,axis=1)\n",
    "    return np.concatenate((data,timings),axis=1)\n",
    "\n",
    "def get_case(array):\n",
    "    current=1\n",
    "    previous=0\n",
    "    temp=[]\n",
    "    for i in array:\n",
    "        if i==current:\n",
    "            if i>previous:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        elif i>current:\n",
    "            previous=current\n",
    "            current=i\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            previous=current\n",
    "            current=i\n",
    "            temp.append(0)\n",
    "    return np.asarray(temp)\n",
    "\n",
    "\n",
    "def binaryToDecimal(binary): \n",
    "      \n",
    "    binary1 = binary \n",
    "    decimal, i, n = 0, 0, 0\n",
    "    while(binary != 0): \n",
    "        dec = binary % 10\n",
    "        decimal = decimal + dec * pow(2, i) \n",
    "        binary = binary//10\n",
    "        i += 1\n",
    "    return(decimal) \n",
    "    \n",
    "#function to split the data into 4 sets, based on whether the past 2 smartprices have increased or decreased, 2^2=4     \n",
    "def get_case_n(array,n=2):\n",
    "    temp=[]\n",
    "    if n==1:\n",
    "        return(\"error\")\n",
    "    previous=np.zeros(n+1)\n",
    "    for i in array:\n",
    "        #print(i,previous)\n",
    "        final=''\n",
    "        if i==int(previous[-1]):\n",
    "            before=10\n",
    "            for j in previous:\n",
    "                if j>before:\n",
    "                    final+='1'\n",
    "                else:\n",
    "                    final+='0'\n",
    "                before=int(j)\n",
    "            final=final[1:]\n",
    "        else:\n",
    "            before=10\n",
    "            for j in previous[1:]:\n",
    "                if j>before:\n",
    "                    final+='1'\n",
    "                else:\n",
    "                    final+='0'\n",
    "                before=int(j)\n",
    "            final=final[1:]\n",
    "            if i>before:\n",
    "                final+='1'\n",
    "            else:\n",
    "                final+='0'\n",
    "        \n",
    "            previous=np.delete(previous,0)\n",
    "            previous=np.insert(previous,n,i)\n",
    "        #print(final)\n",
    "        temp.append(binaryToDecimal(int(final)))\n",
    "    return np.asarray(temp)    \n",
    "\n",
    "def process(dataset,sma_duration=1,vol_duration=1,time_index=44):\n",
    "    data=dataset.copy()\n",
    "    data=calc_smart_price(data).values #new\n",
    "    data=set_index(data,time_index=time_index) #no change\n",
    "    data=calc_future_price(data,time_index=time_index,price_col=-1) #new\n",
    "    data=calc_edge(data,future_col=-1,current_col=-2) #new\n",
    "    data=calc_sma_fast(data,duration=sma_duration,time_index=time_index,price_col=-3) #new\n",
    "    return data\n",
    "\n",
    "#function to calculate all indicators needed\n",
    "def process_light(dataset,sma_duration=1,vol_duration=1):\n",
    "    data=dataset.copy()\n",
    "    data=calc_smart_price(data)\n",
    "    data=data.loc[:,['Time','smart_price']].values.astype(object) #new\n",
    "    data=set_index(data,time_index=0) #no change\n",
    "    data=calc_future_price(data,time_index=0,price_col=-1) #new\n",
    "    data=calc_edge(data,future_col=-1,current_col=-2) #new\n",
    "    data=calc_sma_fast(data,duration=sma_duration,time_index=0,price_col=-3) #new\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#demonstration of get_case_n function\n",
    "x=get_case_n(np.array([12,14,13,4,4,4]),2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.01.02.csv read\n",
      "2019.01.03.csv read\n",
      "2019.01.04.csv read\n",
      "2019.01.07.csv read\n",
      "2019.01.08.csv read\n",
      "2019.01.09.csv read\n",
      "2019.01.10.csv read\n",
      "2019.01.11.csv read\n",
      "2019.01.14.csv read\n",
      "2019.01.15.csv read\n",
      "2019.01.16.csv read\n",
      "2019.01.17.csv read\n",
      "2019.01.18.csv read\n",
      "2019.01.21.csv read\n",
      "2019.01.22.csv read\n",
      "2019.01.23.csv read\n",
      "2019.01.24.csv read\n",
      "2019.01.25.csv read\n",
      "2019.01.28.csv read\n",
      "2019.01.29.csv read\n",
      "2019.01.30.csv read\n",
      "2019.01.31.csv read\n",
      "2019.02.01.csv read\n",
      "2019.02.11.csv read\n",
      "2019.02.12.csv read\n",
      "2019.02.13.csv read\n",
      "2019.02.14.csv read\n",
      "2019.02.15.csv read\n",
      "2019.02.18.csv read\n",
      "2019.02.19.csv read\n",
      "2019.02.20.csv read\n",
      "2019.02.21.csv read\n",
      "2019.02.22.csv read\n",
      "2019.02.25.csv read\n",
      "2019.02.26.csv read\n",
      "2019.02.27.csv read\n",
      "2019.02.28.csv read\n",
      "2019.03.01.csv read\n",
      "2019.03.04.csv read\n",
      "2019.03.05.csv read\n",
      "2019.03.06.csv read\n",
      "2019.03.07.csv read\n",
      "2019.03.08.csv read\n",
      "2019.03.11.csv read\n",
      "2019.03.12.csv read\n",
      "2019.03.13.csv read\n",
      "2019.03.14.csv read\n",
      "2019.03.15.csv read\n",
      "2019.03.18.csv read\n",
      "2019.03.19.csv read\n",
      "2019.03.20.csv read\n",
      "2019.03.21.csv read\n",
      "2019.03.22.csv read\n",
      "2019.03.25.csv read\n",
      "2019.03.26.csv read\n",
      "2019.03.27.csv read\n",
      "2019.03.28.csv read\n",
      "2019.03.29.csv read\n",
      "2019.04.01.csv read\n",
      "2019.04.02.csv read\n",
      "2019.04.03.csv read\n",
      "2019.04.04.csv read\n",
      "2019.04.08.csv read\n",
      "2019.04.09.csv read\n",
      "2019.04.10.csv read\n",
      "2019.04.11.csv read\n",
      "2019.04.12.csv read\n",
      "2019.04.15.csv read\n",
      "2019.04.16.csv read\n",
      "2019.04.17.csv read\n",
      "2019.04.18.csv read\n",
      "2019.04.19.csv read\n",
      "2019.04.22.csv read\n",
      "2019.04.23.csv read\n",
      "2019.04.24.csv read\n",
      "2019.04.25.csv read\n",
      "2019.04.26.csv read\n",
      "2019.04.29.csv read\n",
      "2019.04.30.csv read\n",
      "2019.05.06.csv read\n",
      "2019.05.07.csv read\n",
      "2019.05.08.csv read\n",
      "2019.05.09.csv read\n"
     ]
    }
   ],
   "source": [
    "#processing raw data to get technicals\n",
    "#add all dataframes to df_list\n",
    "df_list=[]\n",
    "name_list=[]\n",
    "ma_time=10\n",
    "path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/'\n",
    "for file in file_list: #read all files and add them to file_list\n",
    "    if file[-3:]=='csv': #check if file is a CSV\n",
    "        name_list.append(file)\n",
    "        df_list.append(process_light(pd.read_csv(path+file),sma_duration=ma_time))\n",
    "        print(file,'read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.01.29.csv\n",
      "2019.01.30.csv\n",
      "2019.01.31.csv\n",
      "2019.02.01.csv\n",
      "2019.02.11.csv\n",
      "2019.02.12.csv\n",
      "2019.02.13.csv\n",
      "2019.02.14.csv\n",
      "2019.02.15.csv\n",
      "2019.02.18.csv\n",
      "2019.02.19.csv\n",
      "2019.02.20.csv\n",
      "2019.02.21.csv\n",
      "2019.02.22.csv\n",
      "2019.02.25.csv\n",
      "2019.02.26.csv\n",
      "2019.02.27.csv\n",
      "2019.02.28.csv\n",
      "2019.03.01.csv\n",
      "2019.03.04.csv\n",
      "2019.03.05.csv\n",
      "2019.03.06.csv\n",
      "2019.03.07.csv\n",
      "2019.03.08.csv\n",
      "2019.03.11.csv\n",
      "2019.03.12.csv\n",
      "2019.03.13.csv\n",
      "2019.03.14.csv\n",
      "2019.03.15.csv\n",
      "2019.03.18.csv\n",
      "2019.03.19.csv\n",
      "2019.03.20.csv\n",
      "2019.03.21.csv\n",
      "2019.03.22.csv\n",
      "2019.03.25.csv\n",
      "2019.03.26.csv\n",
      "2019.03.27.csv\n",
      "2019.03.28.csv\n",
      "2019.03.29.csv\n",
      "2019.04.01.csv\n",
      "2019.04.02.csv\n",
      "2019.04.03.csv\n",
      "2019.04.04.csv\n",
      "2019.04.08.csv\n",
      "2019.04.09.csv\n",
      "2019.04.10.csv\n",
      "2019.04.11.csv\n",
      "2019.04.12.csv\n",
      "2019.04.15.csv\n",
      "2019.04.16.csv\n",
      "2019.04.17.csv\n",
      "2019.04.18.csv\n",
      "2019.04.19.csv\n",
      "2019.04.22.csv\n",
      "2019.04.23.csv\n",
      "2019.04.24.csv\n",
      "2019.04.25.csv\n",
      "2019.04.26.csv\n",
      "2019.04.29.csv\n",
      "2019.04.30.csv\n",
      "2019.05.06.csv\n",
      "2019.05.07.csv\n",
      "2019.05.08.csv\n",
      "2019.05.09.csv\n",
      "done /Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10split_4cases_10min_sma_weightedmean_new.csv\n"
     ]
    }
   ],
   "source": [
    "#calculating results\n",
    "df_path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/'\n",
    "analysis_path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/case analysis/'\n",
    "n=2\n",
    "\n",
    "#create a list to hold all the data\n",
    "data_list=[]\n",
    "#creating a list for each category\n",
    "for i in range(20):\n",
    "    data_list.append([])\n",
    "    #creating a list for each quartile\n",
    "    for _ in range((2**n)):\n",
    "        data_list[i].append([])\n",
    "        \n",
    "for i in range(len(df_list)): #for each 20 day rolling window\n",
    "    if i<19: #skip first 19 days\n",
    "        continue\n",
    "    print(name_list[i])\n",
    "\n",
    "    #get -19 day\n",
    "    sma=df_list[i-19][:,-1].copy() #column for SMA\n",
    "    \n",
    "    #get -18 to 0 day (19 days in total)\n",
    "    for k in range((i-18),i+1): #get 20 day moving averages\n",
    "        sma=np.concatenate((sma,df_list[k][:,-1].copy()))\n",
    "        \n",
    "    cat_sma=categorise_10()\n",
    "    cat_sma.fit(sma) #calculate quartile thresholds for past 20 days\n",
    "\n",
    "    #get x,y for regression\n",
    "    x_today=df_list[i][:,-1].copy().astype(float) #column for SMA     \n",
    "    y_today=df_list[i][:,-2].copy().astype(float) #column for edge\n",
    "    \n",
    "    #removing all NA\n",
    "    isnum=(~np.isnan(x_today)) & (~np.isnan(y_today))\n",
    "    x_today=x_today[isnum]\n",
    "    y_today=y_today[isnum]\n",
    "    \n",
    "    #get categories of today's sma  \n",
    "    cat_x_today=cat_sma.return_quartile(x_today)\n",
    "\n",
    "    change=get_case_n(cat_x_today.copy())\n",
    "\n",
    "    #for each category\n",
    "    for cat in range(1,21):\n",
    "    \n",
    "        #today's sma filter\n",
    "        sma_filter_today=(cat_x_today==cat)\n",
    "\n",
    "        #for each case\n",
    "        for case in range(2**n):\n",
    "                \n",
    "            filtered= sma_filter_today & (change==case) #filtering by SMA and case\n",
    "            filtered[:2]=False #removing first 2 entries due to insufficient data\n",
    "            new_y=y_today[filtered].copy()\n",
    "\n",
    "            if (len(new_y)!=0):\n",
    "                #add today's data into the list by category and case\n",
    "                data_list[(cat-1)][case].append(new_y) \n",
    "                \n",
    "final_df=pd.DataFrame()                 \n",
    "for cat in range(20):\n",
    "    for case in range(2**n):\n",
    "        reg_result={}\n",
    "        if len(data_list[cat][case])==0:\n",
    "            reg_result['category']=cat+1\n",
    "            reg_result['case']=case+1\n",
    "            reg_result['mean']=np.nan\n",
    "            reg_result['std']=np.nan\n",
    "            reg_result['num obs']=0\n",
    "            final_df=final_df.append(reg_result,ignore_index=True)             \n",
    "            continue\n",
    "            \n",
    "        #getting all the data needed to calculate mean and std\n",
    "        all_data=data_list[cat][case][0].copy()\n",
    "        for i in range(1,(len(data_list[cat][case]))):\n",
    "            all_data=np.concatenate((all_data,data_list[cat][case][i].copy()))\n",
    "\n",
    "        #adding results to output\n",
    "        reg_result['category']=cat+1\n",
    "        reg_result['case']=case+1\n",
    "        reg_result['mean']=np.mean(all_data)\n",
    "        reg_result['std']=np.std(all_data)\n",
    "        reg_result['num obs']=len(all_data)\n",
    "        final_df=final_df.append(reg_result,ignore_index=True) \n",
    "             \n",
    "temp=df_path+'result_10split_'+str(2**n)+'cases_'+str(ma_time)+'min_sma_weightedmean_new.csv'\n",
    "final_df.to_csv(temp)\n",
    "print('done',temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 1\n",
      "01 2\n",
      "10 3\n",
      "11 4\n"
     ]
    }
   ],
   "source": [
    "#interpretation of case results\n",
    "for x in ['0','1']:\n",
    "    for y in ['0','1']:\n",
    "        print(x+y,binaryToDecimal(int(x+y))+1)\n",
    "# 0 indicates decrease, 1 indicates increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 minute MA\n",
      "mean\n",
      "[[-0.15707977         nan -0.01526818         nan]\n",
      " [-0.22432963  0.07451811 -0.20702137         nan]\n",
      " [-0.30849692 -0.04560965 -0.26019859  0.03381705]\n",
      " [-0.23318078 -0.03591182 -0.16739341  0.01558353]\n",
      " [-0.36404783 -0.06298882 -0.21863177  0.13420138]\n",
      " [-0.31194633 -0.16356036 -0.20740974  0.09426032]\n",
      " [-0.24774466 -0.11757976 -0.26148695  0.07402522]\n",
      " [-0.35090885 -0.08119375 -0.29217667  0.02089411]\n",
      " [-0.32942903 -0.11335671 -0.15644405  0.09220461]\n",
      " [-0.25260451  0.01362005 -0.06159319  0.12512678]\n",
      " [-0.28616861  0.09718981 -0.07304333  0.23568003]\n",
      " [-0.22138117  0.20536967  0.02850372  0.23722997]\n",
      " [-0.14262826  0.25508298  0.07546102  0.32018908]\n",
      " [-0.17582056  0.2274647   0.05877015  0.28398263]\n",
      " [-0.12684284  0.21805602  0.07982552  0.26889813]\n",
      " [-0.10926458  0.25725371  0.13004272  0.29267219]\n",
      " [-0.11259938  0.27108598  0.12970074  0.32259374]\n",
      " [-0.01765611  0.2140748   0.05207068  0.27531622]\n",
      " [        nan  0.36635876 -0.04497216  0.32020018]\n",
      " [        nan  0.2401591          nan  0.38891338]]\n",
      "std\n",
      "[[4.43862225        nan 4.63190947        nan]\n",
      " [3.07821708 3.4378915  3.81134759        nan]\n",
      " [2.92428433 2.93214111 2.96646971 3.28403617]\n",
      " [2.74746611 2.69658595 2.69371411 2.82918433]\n",
      " [2.48832258 2.62099689 2.58605696 2.54866574]\n",
      " [2.60860461 2.43451745 2.53652694 2.51917068]\n",
      " [2.54334162 2.56259373 2.5310874  2.50046626]\n",
      " [2.47799707 2.48535419 2.44727376 2.45149037]\n",
      " [2.27769559 2.3290622  2.30978355 2.249726  ]\n",
      " [2.35485316 2.37679271 2.31690977 2.3257969 ]\n",
      " [2.36654095 2.41117776 2.30826719 2.41827698]\n",
      " [2.46500804 2.50047359 2.26438174 2.39609938]\n",
      " [2.37916207 2.41203508 2.44687275 2.39125276]\n",
      " [2.5214067  2.55943153 2.5060067  2.39138772]\n",
      " [2.60885766 2.5666711  2.53058791 2.50884823]\n",
      " [2.62224212 2.73777967 2.70636373 2.69464367]\n",
      " [3.11163536 2.8834047  2.76089234 2.81719941]\n",
      " [3.08855195 2.98164853 2.88431458 2.86849311]\n",
      " [       nan 3.24423217 3.38518374 3.1499403 ]\n",
      " [       nan 4.53392855        nan 4.49108983]]\n",
      "num obs\n",
      "[[83725.     0. 57752.     0.]\n",
      " [48759. 57261. 39664.     0.]\n",
      " [42414. 54781. 35144. 18615.]\n",
      " [42768. 51764. 31447. 27860.]\n",
      " [40362. 49368. 31711. 33795.]\n",
      " [40818. 47637. 32297. 38653.]\n",
      " [39719. 44245. 33795. 42272.]\n",
      " [40957. 42830. 34239. 45312.]\n",
      " [42151. 41393. 38618. 43585.]\n",
      " [43149. 43842. 42150. 42361.]\n",
      " [45542. 42115. 41053. 42011.]\n",
      " [42452. 36489. 42719. 41851.]\n",
      " [43095. 34684. 41423. 40534.]\n",
      " [41909. 31233. 43533. 40260.]\n",
      " [37826. 31936. 47548. 39677.]\n",
      " [32943. 31731. 48397. 39832.]\n",
      " [27195. 30825. 49066. 41373.]\n",
      " [17985. 33666. 51356. 42894.]\n",
      " [    0. 38410. 54472. 48508.]\n",
      " [    0. 56032.     0. 81399.]]\n",
      "3 minute MA\n",
      "mean\n",
      "[[-0.05038143         nan  0.04475746         nan]\n",
      " [-0.05570749  0.00670143 -0.0783667          nan]\n",
      " [-0.12244053  0.06605456 -0.19517531  0.14970656]\n",
      " [-0.27452612  0.0212699  -0.22277964  0.15916253]\n",
      " [-0.42258734 -0.12070327 -0.25773461  0.03761201]\n",
      " [-0.38556351 -0.17815678 -0.27286418  0.03649289]\n",
      " [-0.43382547 -0.09237473 -0.26089003  0.07800268]\n",
      " [-0.38508785 -0.05538123 -0.19715072  0.0962439 ]\n",
      " [-0.23070567 -0.10133262 -0.16897622  0.03286596]\n",
      " [-0.24163853  0.00699585 -0.12192975  0.06974447]\n",
      " [-0.30624514  0.00773549 -0.15847952  0.1195652 ]\n",
      " [-0.16476153  0.06997057 -0.00955106  0.35794126]\n",
      " [-0.15329563  0.23185048  0.06273656  0.25994399]\n",
      " [-0.18764897  0.20286361  0.06914011  0.20314375]\n",
      " [-0.11934107  0.25534979  0.11211298  0.2114765 ]\n",
      " [-0.20530493  0.34039687  0.01112785  0.23417449]\n",
      " [-0.13984354  0.33794936  0.09204638  0.42377137]\n",
      " [ 0.25326413  0.24753513  0.06091452  0.20518921]\n",
      " [        nan  0.28679964  0.20114117  0.26403453]\n",
      " [        nan  0.31350898         nan  0.22361355]]\n",
      "std\n",
      "[[5.00944298        nan 4.14421265        nan]\n",
      " [3.46379369 3.31620165 3.51719457        nan]\n",
      " [2.95214498 3.01816285 3.23468813 2.90925501]\n",
      " [2.70146761 2.69626973 2.57021878 2.74390199]\n",
      " [2.59741974 2.4957529  2.55252578 2.51737828]\n",
      " [2.45717377 2.47256318 2.61160468 2.42752532]\n",
      " [2.40452056 2.40397712 2.53065209 2.47287601]\n",
      " [2.31707787 2.28500864 2.39135652 2.23889443]\n",
      " [2.50753779 2.29002252 2.23970085 2.10556061]\n",
      " [2.40419027 2.26779082 2.26995867 2.26306415]\n",
      " [2.33982224 2.29226181 2.17619282 2.30799926]\n",
      " [2.20605318 2.27710501 2.47290337 2.6147771 ]\n",
      " [2.41987097 2.42099095 2.57899049 2.38916385]\n",
      " [2.46115014 2.43638809 2.4498625  2.55380628]\n",
      " [2.54120011 2.7178073  2.53794    2.39846645]\n",
      " [2.69000865 2.62582368 2.63112473 2.70746237]\n",
      " [2.63966379 2.89195897 2.77480074 2.87631059]\n",
      " [2.94898251 3.05927903 3.07442029 2.94946022]\n",
      " [       nan 3.53575002 3.27307567 3.44829323]\n",
      " [       nan 4.5663164         nan 4.40600256]]\n",
      "num obs\n",
      "[[75559.     0. 68629.     0.]\n",
      " [45353. 58497. 42316.     0.]\n",
      " [44587. 49644. 40692. 15516.]\n",
      " [45382. 48839. 40158. 22419.]\n",
      " [44029. 47361. 40282. 28555.]\n",
      " [43400. 47005. 38933. 32369.]\n",
      " [42926. 45651. 40683. 36464.]\n",
      " [43563. 43116. 41061. 34952.]\n",
      " [41373. 44843. 41300. 37650.]\n",
      " [39627. 43758. 42653. 38666.]\n",
      " [40709. 41357. 42377. 39133.]\n",
      " [36518. 39700. 43535. 38929.]\n",
      " [35106. 40211. 43083. 41296.]\n",
      " [33190. 39282. 45120. 41515.]\n",
      " [29909. 37020. 45213. 44360.]\n",
      " [27171. 37947. 44778. 41919.]\n",
      " [22864. 37790. 46925. 42787.]\n",
      " [15788. 39199. 49459. 39306.]\n",
      " [    0. 41393. 57123. 41735.]\n",
      " [    0. 68117.     0. 71512.]]\n",
      "5 minute MA\n",
      "mean\n",
      "[[ 0.13186657         nan  0.07847074         nan]\n",
      " [ 0.08756617 -0.06588187 -0.0751949          nan]\n",
      " [-0.07577967  0.05159176 -0.22887031  0.06709616]\n",
      " [-0.24852956  0.04116707 -0.24900447  0.01651981]\n",
      " [-0.39261616 -0.06147637 -0.26922592 -0.0938975 ]\n",
      " [-0.37134532  0.00116712 -0.15346538  0.0481065 ]\n",
      " [-0.363047   -0.03934818 -0.29205535  0.12089277]\n",
      " [-0.32684232  0.04186165 -0.11809695  0.0280113 ]\n",
      " [-0.38183113 -0.00125613 -0.3129711   0.09174648]\n",
      " [-0.35566003  0.02268009 -0.17306742  0.15913035]\n",
      " [-0.29120085  0.10463421 -0.14100941  0.27142085]\n",
      " [-0.20678198  0.08088274 -0.02396416  0.26790561]\n",
      " [-0.25530692  0.17457233  0.07293912  0.24566982]\n",
      " [-0.23047342  0.21881193  0.025402    0.42807626]\n",
      " [-0.2089761   0.2780127  -0.01631813  0.38688703]\n",
      " [-0.17074065  0.40976101 -0.17288334  0.41810688]\n",
      " [-0.00092072  0.25366399  0.08211123  0.32921444]\n",
      " [-0.06945137  0.41755595 -0.09847068  0.30000302]\n",
      " [        nan  0.22297365  0.03674503  0.13736301]\n",
      " [        nan  0.04335681         nan  0.27216416]]\n",
      "std\n",
      "[[4.74674301        nan 4.34259338        nan]\n",
      " [3.26051882 3.69350627 3.27317579        nan]\n",
      " [2.95899931 2.77590228 2.95421696 2.9764849 ]\n",
      " [2.97124322 2.63531414 2.9073848  2.85376486]\n",
      " [2.74046034 2.6982587  2.41470865 2.64198692]\n",
      " [2.55755593 2.41577117 2.47684012 2.51254149]\n",
      " [2.4741535  2.37130159 2.48459234 2.29015631]\n",
      " [2.3331154  2.37831093 2.31976585 2.36180633]\n",
      " [2.39926932 2.26351376 2.3083766  2.30101602]\n",
      " [2.42892164 2.1901975  2.28091172 2.20507813]\n",
      " [2.46019871 2.29275901 2.38370672 2.33459987]\n",
      " [2.29757812 2.39777963 2.39274714 2.46349224]\n",
      " [2.28733376 2.34765001 2.50109554 2.46024864]\n",
      " [2.37927578 2.42293609 2.4305215  2.59536824]\n",
      " [2.35623492 2.76700028 2.54952173 2.69950584]\n",
      " [2.51753454 2.75261566 2.57773877 2.76597241]\n",
      " [2.7006738  2.91234876 2.79846932 2.94019415]\n",
      " [2.97462691 3.2238203  2.932426   3.18005125]\n",
      " [       nan 3.47574428 3.07477497 3.44798328]\n",
      " [       nan 4.16156495        nan 4.7473592 ]]\n",
      "num obs\n",
      "[[63791.     0. 79756.     0.]\n",
      " [41990. 60479. 47274.     0.]\n",
      " [39231. 53405. 47268. 13406.]\n",
      " [41106. 49713. 44409. 23351.]\n",
      " [42134. 48032. 43508. 28228.]\n",
      " [43415. 46551. 43436. 30155.]\n",
      " [40907. 44747. 43450. 35091.]\n",
      " [41305. 45469. 44814. 34433.]\n",
      " [38767. 48396. 43678. 35561.]\n",
      " [38595. 43921. 45029. 37836.]\n",
      " [37881. 41595. 42136. 37845.]\n",
      " [36342. 39547. 44411. 38002.]\n",
      " [32251. 38847. 44743. 41707.]\n",
      " [29700. 42604. 44445. 39772.]\n",
      " [29993. 38591. 45520. 41665.]\n",
      " [26224. 38119. 46328. 40940.]\n",
      " [21962. 41626. 46344. 37143.]\n",
      " [14044. 40989. 51042. 36165.]\n",
      " [    0. 42555. 63780. 35397.]\n",
      " [    0. 69105.     0. 69190.]]\n",
      "10 minute MA\n",
      "mean\n",
      "[[ 0.28407173         nan -0.0017753          nan]\n",
      " [ 0.08228724  0.04939593 -0.06701639         nan]\n",
      " [-0.15512527  0.04369846 -0.33126957 -0.3131413 ]\n",
      " [-0.08075945 -0.036961   -0.32434183  0.02687793]\n",
      " [-0.15102623  0.18600722 -0.12063006  0.10420222]\n",
      " [-0.27233559 -0.04087401 -0.32046844  0.23587171]\n",
      " [-0.12292671 -0.00975556 -0.36196092 -0.06690008]\n",
      " [-0.35232651  0.03239333 -0.12102258 -0.05114834]\n",
      " [-0.24529055  0.09974238 -0.01386411  0.28279826]\n",
      " [-0.2154443   0.2215983  -0.14893152  0.16037553]\n",
      " [-0.24323694  0.10581146 -0.12135608  0.2405425 ]\n",
      " [-0.29983524  0.13932938 -0.02458746  0.17966626]\n",
      " [-0.15246566  0.31340604 -0.0357606   0.25036505]\n",
      " [-0.16639104  0.26030616  0.06726275  0.3289755 ]\n",
      " [-0.13459649  0.28421584 -0.09956413  0.47579094]\n",
      " [-0.17464308  0.18279308  0.03362927  0.42167189]\n",
      " [-0.37128667  0.51241689 -0.37430384  0.23184617]\n",
      " [-0.34061921 -0.02581159 -0.07434372  0.22015344]\n",
      " [        nan  0.19721751 -0.09123494  0.36928707]\n",
      " [        nan -0.1987884          nan  0.20298021]]\n",
      "std\n",
      "[[4.74168969        nan 4.23518981        nan]\n",
      " [3.79617145 3.05809421 3.34371535        nan]\n",
      " [3.35422658 2.81036399 3.19403468 2.84929362]\n",
      " [3.03472103 2.75433782 3.04523615 2.62442878]\n",
      " [2.803716   2.43967525 2.70582749 2.37098579]\n",
      " [2.73892407 2.43764436 2.55596161 2.34359043]\n",
      " [2.42465436 2.37381305 2.30482779 2.73895811]\n",
      " [2.55790267 2.35178478 2.40649387 2.24339014]\n",
      " [2.33108852 2.24067216 2.29134441 2.51072987]\n",
      " [2.25179503 2.30058448 2.14567491 2.37830162]\n",
      " [2.51616815 2.28525353 2.32142218 2.51126095]\n",
      " [2.55224863 2.34357462 2.43043623 2.36234676]\n",
      " [2.39439969 2.39084411 2.31793516 2.45752664]\n",
      " [2.28446099 2.48691757 2.69352991 2.52554589]\n",
      " [2.56432854 2.7991752  2.63525732 2.84519455]\n",
      " [2.5851289  2.73319327 2.65195263 2.91714075]\n",
      " [2.84785725 2.8504057  2.6179847  3.04135101]\n",
      " [2.65368336 3.02626359 2.80935355 3.30381683]\n",
      " [       nan 3.4257975  3.16516875 4.05515146]\n",
      " [       nan 3.98109833        nan 4.6705669 ]]\n",
      "num obs\n",
      "[[51521.     0. 88574.     0.]\n",
      " [31681. 67011. 53246.     0.]\n",
      " [31775. 60480. 49453. 13315.]\n",
      " [36305. 52931. 47129. 23256.]\n",
      " [40044. 50322. 49298. 24626.]\n",
      " [37723. 51331. 45060. 26277.]\n",
      " [39214. 45613. 48530. 29667.]\n",
      " [36869. 48036. 48068. 32173.]\n",
      " [37537. 49054. 43899. 33553.]\n",
      " [37713. 47057. 50894. 35177.]\n",
      " [34392. 45971. 48011. 33296.]\n",
      " [32350. 45591. 43959. 36851.]\n",
      " [31510. 45720. 42629. 37612.]\n",
      " [28775. 43236. 45419. 35062.]\n",
      " [25064. 45549. 45851. 36653.]\n",
      " [25355. 43521. 49085. 33129.]\n",
      " [18219. 45191. 51420. 33945.]\n",
      " [13039. 42484. 55508. 32277.]\n",
      " [    0. 48111. 68774. 26424.]\n",
      " [    0. 76896.     0. 59896.]]\n"
     ]
    }
   ],
   "source": [
    "for time in [1,3,5,10]:\n",
    "    try:\n",
    "        data=pd.read_csv('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10split_4cases_'+str(time)+'min_sma_weightedmean_new.csv')\n",
    "    except:\n",
    "        continue\n",
    "    length=len(data)\n",
    "    print(time,'minute MA')\n",
    "    print('mean')\n",
    "    print(np.reshape(data.loc[:,'mean'].values,(20,4)))\n",
    "    print('std')\n",
    "    print(np.reshape(data.loc[:,'std'].values,(20,4)))\n",
    "    print('num obs')\n",
    "    x2=np.reshape(data.loc[:,'num obs'].values,(20,4))\n",
    "    print(np.reshape(data.loc[:,'num obs'].values,(20,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at 5 minute MA, left column, top row of mean is 0.131\n",
    "#this means when the price drops consecutively two times, and when the price is already very low, mean_reversion occurs\n",
    "#a value of 0.131 represents the average edge, meaning we can expect price of the futures to increase"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
