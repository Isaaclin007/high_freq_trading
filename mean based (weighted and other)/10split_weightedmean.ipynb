{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into 20 categories (10-90% percentile for positive and negative so 10x2) based on SMA 1 minute from past 20 days, \n",
    "#then within each SMA category, separate into quartiles based on cumulative volume in 1 minute\n",
    "#calculate the mean and std of the edge in each case\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from datetime import datetime,timedelta\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA'\n",
    "os.chdir('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA')\n",
    "file_list=os.listdir(path)\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '2019.01.02.csv',\n",
       " '2019.01.03.csv',\n",
       " '2019.01.04.csv',\n",
       " '2019.01.07.csv',\n",
       " '2019.01.08.csv',\n",
       " '2019.01.09.csv',\n",
       " '2019.01.10.csv',\n",
       " '2019.01.11.csv',\n",
       " '2019.01.14.csv',\n",
       " '2019.01.15.csv',\n",
       " '2019.01.16.csv',\n",
       " '2019.01.17.csv',\n",
       " '2019.01.18.csv',\n",
       " '2019.01.21.csv',\n",
       " '2019.01.22.csv',\n",
       " '2019.01.23.csv',\n",
       " '2019.01.24.csv',\n",
       " '2019.01.25.csv',\n",
       " '2019.01.28.csv',\n",
       " '2019.01.29.csv',\n",
       " '2019.01.30.csv',\n",
       " '2019.01.31.csv',\n",
       " '2019.02.01.csv',\n",
       " '2019.02.11.csv',\n",
       " '2019.02.12.csv',\n",
       " '2019.02.13.csv',\n",
       " '2019.02.14.csv',\n",
       " '2019.02.15.csv',\n",
       " '2019.02.18.csv',\n",
       " '2019.02.19.csv',\n",
       " '2019.02.20.csv',\n",
       " '2019.02.21.csv',\n",
       " '2019.02.22.csv',\n",
       " '2019.02.25.csv',\n",
       " '2019.02.26.csv',\n",
       " '2019.02.27.csv',\n",
       " '2019.02.28.csv',\n",
       " '2019.03.01.csv',\n",
       " '2019.03.04.csv',\n",
       " '2019.03.05.csv',\n",
       " '2019.03.06.csv',\n",
       " '2019.03.07.csv',\n",
       " '2019.03.08.csv',\n",
       " '2019.03.11.csv',\n",
       " '2019.03.12.csv',\n",
       " '2019.03.13.csv',\n",
       " '2019.03.14.csv',\n",
       " '2019.03.15.csv',\n",
       " '2019.03.18.csv',\n",
       " '2019.03.19.csv',\n",
       " '2019.03.20.csv',\n",
       " '2019.03.21.csv',\n",
       " '2019.03.22.csv',\n",
       " '2019.03.25.csv',\n",
       " '2019.03.26.csv',\n",
       " '2019.03.27.csv',\n",
       " '2019.03.28.csv',\n",
       " '2019.03.29.csv',\n",
       " '2019.04.01.csv',\n",
       " '2019.04.02.csv',\n",
       " '2019.04.03.csv',\n",
       " '2019.04.04.csv',\n",
       " '2019.04.08.csv',\n",
       " '2019.04.09.csv',\n",
       " '2019.04.10.csv',\n",
       " '2019.04.11.csv',\n",
       " '2019.04.12.csv',\n",
       " '2019.04.15.csv',\n",
       " '2019.04.16.csv',\n",
       " '2019.04.17.csv',\n",
       " '2019.04.18.csv',\n",
       " '2019.04.19.csv',\n",
       " '2019.04.22.csv',\n",
       " '2019.04.23.csv',\n",
       " '2019.04.24.csv',\n",
       " '2019.04.25.csv',\n",
       " '2019.04.26.csv',\n",
       " '2019.04.29.csv',\n",
       " '2019.04.30.csv',\n",
       " '2019.05.06.csv',\n",
       " '2019.05.07.csv',\n",
       " '2019.05.08.csv',\n",
       " '2019.05.09.csv',\n",
       " 'results']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class categorise():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(7)\n",
    "                else:\n",
    "                    temp.append(8)\n",
    "            if i<0:\n",
    "                if i>self.threshold[0][2]:\n",
    "                    temp.append(4)\n",
    "                elif i>self.threshold[0][1]:\n",
    "                    temp.append(3)\n",
    "                elif i>self.threshold[0][0]:\n",
    "                    temp.append(2)\n",
    "                else:\n",
    "                    temp.append(1)\n",
    "        return np.asarray(temp)\n",
    "    \n",
    "class categorise_simple():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        self.threshold.append(np.percentile(array,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                else:\n",
    "                    temp.append(4)\n",
    "        return np.asarray(temp)    \n",
    "    \n",
    "class categorise_10():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[10,20,30,40,50,60,70,80,90]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(11)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(12)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(13)\n",
    "                elif i<self.threshold[1][3]:\n",
    "                    temp.append(14)\n",
    "                elif i<self.threshold[1][4]:\n",
    "                    temp.append(15)\n",
    "                elif i<self.threshold[1][5]:\n",
    "                    temp.append(16)\n",
    "                elif i<self.threshold[1][6]:\n",
    "                    temp.append(17)\n",
    "                elif i<self.threshold[1][7]:\n",
    "                    temp.append(18)\n",
    "                elif i<self.threshold[1][8]:\n",
    "                    temp.append(19)                    \n",
    "                else:\n",
    "                    temp.append(20)\n",
    "            if i<0:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                elif i<self.threshold[0][3]:\n",
    "                    temp.append(4)\n",
    "                elif i<self.threshold[0][4]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[0][5]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[0][6]:\n",
    "                    temp.append(7)\n",
    "                elif i<self.threshold[0][7]:\n",
    "                    temp.append(8)\n",
    "                elif i<self.threshold[0][8]:\n",
    "                    temp.append(9)                    \n",
    "                else:\n",
    "                    temp.append(10)\n",
    "        return np.asarray(temp)    \n",
    "class cross():\n",
    "    def __init__(self):\n",
    "        self.time_last_cross=0\n",
    "        self.current_sign=True\n",
    "        self.last_time=datetime(1900, 1, 1, 8, 59)\n",
    "    def get_time(self,time,price):\n",
    "        if (time-self.last_time)>timedelta(minutes=1):\n",
    "            self.last_time=time\n",
    "            self.time_last_cross=time\n",
    "            return 0\n",
    "        self.last_time=time\n",
    "        if (price>0) and self.current_sign : #if price positive and current trend is also positive\n",
    "            return (time-self.time_last_cross).total_seconds()\n",
    "        elif (price<0) and (not self.current_sign): #if price negative and current trend is negative\n",
    "            return (time-self.time_last_cross).total_seconds()\n",
    "        else: #if price positive, trend negative or price negative, trend positive\n",
    "            self.time_last_cross=time\n",
    "            self.current_sign=(price>0)\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_smart_price(dataset):\n",
    "    data=dataset.copy()\n",
    "    \n",
    "    #to combat the limit up event, where price is set to 0. \n",
    "    rows=(data.loc[:,'BidPrice1']==0) #count rows of bid price equal 0\n",
    "    if (np.any(rows)): #if there is such a row\n",
    "        data.at[rows,'BidPrice1']=data.loc[rows,'AskPrice1'] #for that row, assign ask price to it\n",
    "    rows=(data.loc[:,'AskPrice1']==0) #do the same for ask price\n",
    "    if (np.any(rows)):\n",
    "        data.at[rows,'AskPrice1']=data.loc[rows,'BidPrice1'] \n",
    "        \n",
    "    data['smart_price']=data.loc[:,'BidPrice1']*data.loc[:,'AskVol1']+data.loc[:,'AskPrice1']*data.loc[:,'BidVol1']\n",
    "    data.at[:,'smart_price']=data.loc[:,'smart_price']/(data.loc[:,['BidVol1','AskVol1']].sum(axis=1))  \n",
    "    return data\n",
    "\n",
    "def calc_present_vol(dataset):\n",
    "    data=dataset.copy()\n",
    "    data['current_vol']=data.loc[:,'Volume'].diff().fillna(0)/2\n",
    "    return data\n",
    "\n",
    "def calc_future_price(dataset,time_ahead=30,time_index=44, price_col=-2):\n",
    "    data=dataset.copy()\n",
    "    future_price=[]\n",
    "    length=len(data)\n",
    "    for i in range(len(data)):\n",
    "        current_time=data[i,time_index]+timedelta(seconds=time_ahead)\n",
    "        \n",
    "        j=0 #could alternatively use 30 x 3 then search forward and backward\n",
    "        \n",
    "        #search forwards\n",
    "        while((i+j)<length and current_time>data[(i+j),time_index]):\n",
    "            j+=1\n",
    "        if (i+j)<length:\n",
    "            #if index is in the dataframe\n",
    "            future_price.append(data[(i+j),price_col]) \n",
    "        else:\n",
    "            #price ahead does not exist\n",
    "            future_price.append(np.nan) \n",
    "    future_price=np.asarray(future_price)\n",
    "    future_price=np.expand_dims(future_price,axis=1)\n",
    "    return np.concatenate((data,future_price),axis=1)\n",
    "\n",
    "\n",
    "def calc_edge(dataset,future_col=-1,current_col=-3):\n",
    "    data=dataset.copy()\n",
    "    temp=data[:,future_col]-data[:,current_col]\n",
    "    temp=np.expand_dims(temp,axis=1)\n",
    "    return np.concatenate((data,temp),axis=1)\n",
    "\n",
    "def set_index(dataset,time_index=44):\n",
    "    data=dataset.copy()\n",
    "    index=data[:,time_index]\n",
    "    new_index=[]\n",
    "    for j in range(len(index)):\n",
    "        i=str(index[j]*1000)\n",
    "        if len(i)==11:\n",
    "            i='0'+i\n",
    "        i=i[:-10]+':'+i[-10:]\n",
    "        i=i[:-8]+':'+i[-8:]\n",
    "        i=i[:-6]+':'+i[-6:]\n",
    "        new_index.append(datetime.strptime(i,\"%H:%M:%S:%f\"))\n",
    "    data[:,time_index]=new_index\n",
    "    return data\n",
    "\n",
    "def calc_sma_fast(dataset,price_col,duration=1,time_index=44): #faster way to calculate SMA, 0.05 seconds for 5000 rows\n",
    "    data=dataset.copy()\n",
    "    sma_values=[] \n",
    "    smart_sum=np.cumsum(data[:,price_col]) #smart price column is -4\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        #finding ending point\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        \n",
    "        #finding start point\n",
    "        j=220*duration#4x60=240\n",
    "        \n",
    "        if i-j>0:\n",
    "            if data[i-j,time_index]>last_time: \n",
    "                \n",
    "                #if starting point time is greater than ending point time\n",
    "                #search backward\n",
    "                while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "                    j+=1\n",
    "                    \n",
    "                #activate next line in order to debug and troubleshoot\n",
    "                #print('backward',i,j,data[i,time_index],data[i-j,time_index],last_time)\n",
    "                \n",
    "                sma=(smart_sum[i]-smart_sum[i-j])/(j)\n",
    "                sma_values.append(sma)                \n",
    "                \n",
    "            else: \n",
    "                \n",
    "                #search forward\n",
    "                while(data[i-j,time_index]<last_time):\n",
    "                    j-=1\n",
    "                    \n",
    "                #activate next line in order to debug and troubleshoot\n",
    "                #print('forward',i,j,data[i,time_index],data[i-j,time_index],last_time)\n",
    "                \n",
    "                if j!=0:\n",
    "                    sma=(smart_sum[i]-smart_sum[i-j])/(j)\n",
    "                    sma_values.append(sma)   \n",
    "                    \n",
    "                else:\n",
    "                    sma_values.append(0)\n",
    "                    \n",
    "        else: #starting point is at 0\n",
    "            \n",
    "            sma=smart_sum[i]/(i+1)\n",
    "            sma_values.append(sma)                       \n",
    "\n",
    "    sma_values=np.asarray(sma_values)\n",
    "    sma_values=data[:,price_col]-sma_values\n",
    "    sma_values=np.expand_dims(sma_values,axis=1)\n",
    "    return np.concatenate((data,sma_values),axis=1)   \n",
    "\n",
    "def calc_past_vol(dataset,duration=1,time_index=44,vol_col=-4): #\n",
    "    data=dataset[:].copy()\n",
    "    vol_values=[] \n",
    "    vol_sum=np.cumsum(data[:,vol_col])\n",
    "    for i in range(len(data)):\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        j=220*duration#4x60=240\n",
    "        while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "            j+=1\n",
    "        if (i-j>=0):\n",
    "            vol=(vol_sum[i]-vol_sum[i-j])\n",
    "            vol_values.append(vol)\n",
    "        else:\n",
    "            vol=vol_sum[i]\n",
    "            vol_values.append(vol)\n",
    "    vol_values=np.asarray(vol_values)\n",
    "    vol_values=np.expand_dims(vol_values,axis=1)\n",
    "    return np.concatenate((data,vol_values),axis=1) \n",
    "\n",
    "def last_cross(dataset,time_index=44,price_col=-3):\n",
    "    data=dataset.copy()\n",
    "    last_cross=cross()\n",
    "    timings=[]\n",
    "    for i in range(len(data)):\n",
    "        timings.append(last_cross.get_time(data[i,time_index],data[i,price_col]))\n",
    "    timings=np.asarray(timings)\n",
    "    timings=np.expand_dims(timings,axis=1)\n",
    "    return np.concatenate((data,timings),axis=1)\n",
    "\n",
    "def process(dataset,sma_duration=1,vol_duration=1,time_index=44):\n",
    "    data=dataset[:]\n",
    "    data=calc_smart_price(data).values #new\n",
    "    data=set_index(data,time_index=time_index) #no change\n",
    "    data=calc_future_price(data,time_index=time_index,price_col=-1) #new\n",
    "    data=calc_edge(data,future_col=-1,current_col=-2) #new\n",
    "    data=calc_sma_fast(data,duration=sma_duration,time_index=time_index,price_col=-3) #new\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.01.02.csv read\n",
      "2019.01.03.csv read\n",
      "2019.01.04.csv read\n",
      "2019.01.07.csv read\n",
      "2019.01.08.csv read\n",
      "2019.01.09.csv read\n",
      "2019.01.10.csv read\n",
      "2019.01.11.csv read\n",
      "2019.01.14.csv read\n",
      "2019.01.15.csv read\n",
      "2019.01.16.csv read\n",
      "2019.01.17.csv read\n",
      "2019.01.18.csv read\n",
      "2019.01.21.csv read\n",
      "2019.01.22.csv read\n",
      "2019.01.23.csv read\n",
      "2019.01.24.csv read\n",
      "2019.01.25.csv read\n",
      "2019.01.28.csv read\n",
      "2019.01.29.csv read\n",
      "2019.01.30.csv read\n",
      "2019.01.31.csv read\n",
      "2019.02.01.csv read\n",
      "2019.02.11.csv read\n",
      "2019.02.12.csv read\n",
      "2019.02.13.csv read\n",
      "2019.02.14.csv read\n",
      "2019.02.15.csv read\n",
      "2019.02.18.csv read\n",
      "2019.02.19.csv read\n",
      "2019.02.20.csv read\n",
      "2019.02.21.csv read\n",
      "2019.02.22.csv read\n",
      "2019.02.25.csv read\n",
      "2019.02.26.csv read\n",
      "2019.02.27.csv read\n",
      "2019.02.28.csv read\n",
      "2019.03.01.csv read\n",
      "2019.03.04.csv read\n",
      "2019.03.05.csv read\n",
      "2019.03.06.csv read\n",
      "2019.03.07.csv read\n",
      "2019.03.08.csv read\n",
      "2019.03.11.csv read\n",
      "2019.03.12.csv read\n",
      "2019.03.13.csv read\n",
      "2019.03.14.csv read\n",
      "2019.03.15.csv read\n",
      "2019.03.18.csv read\n",
      "2019.03.19.csv read\n",
      "2019.03.20.csv read\n",
      "2019.03.21.csv read\n",
      "2019.03.22.csv read\n",
      "2019.03.25.csv read\n",
      "2019.03.26.csv read\n",
      "2019.03.27.csv read\n",
      "2019.03.28.csv read\n",
      "2019.03.29.csv read\n",
      "2019.04.01.csv read\n",
      "2019.04.02.csv read\n",
      "2019.04.03.csv read\n",
      "2019.04.04.csv read\n",
      "2019.04.08.csv read\n",
      "2019.04.09.csv read\n",
      "2019.04.10.csv read\n",
      "2019.04.11.csv read\n",
      "2019.04.12.csv read\n",
      "2019.04.15.csv read\n",
      "2019.04.16.csv read\n",
      "2019.04.17.csv read\n",
      "2019.04.18.csv read\n",
      "2019.04.19.csv read\n",
      "2019.04.22.csv read\n",
      "2019.04.23.csv read\n",
      "2019.04.24.csv read\n",
      "2019.04.25.csv read\n",
      "2019.04.26.csv read\n",
      "2019.04.29.csv read\n",
      "2019.04.30.csv read\n",
      "2019.05.06.csv read\n",
      "2019.05.07.csv read\n",
      "2019.05.08.csv read\n",
      "2019.05.09.csv read\n"
     ]
    }
   ],
   "source": [
    "#processing raw data to get technicals\n",
    "df_list=[]\n",
    "name_list=[]\n",
    "path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/'\n",
    "for file in file_list: #read all files and add them to file_list\n",
    "    if file[-3:]=='csv': #check if file is a CSV\n",
    "        name_list.append(file)\n",
    "        df_list.append(process(pd.read_csv(path+file),sma_duration=10))\n",
    "        print(file,'read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.01.29.csv\n",
      "2019.01.30.csv\n",
      "2019.01.31.csv\n",
      "2019.02.01.csv\n",
      "2019.02.11.csv\n",
      "2019.02.12.csv\n",
      "2019.02.13.csv\n",
      "2019.02.14.csv\n",
      "2019.02.15.csv\n",
      "2019.02.18.csv\n",
      "2019.02.19.csv\n",
      "2019.02.20.csv\n",
      "2019.02.21.csv\n",
      "2019.02.22.csv\n",
      "2019.02.25.csv\n",
      "2019.02.26.csv\n",
      "2019.02.27.csv\n",
      "2019.02.28.csv\n",
      "2019.03.01.csv\n",
      "2019.03.04.csv\n",
      "2019.03.05.csv\n",
      "2019.03.06.csv\n",
      "2019.03.07.csv\n",
      "2019.03.08.csv\n",
      "2019.03.11.csv\n",
      "2019.03.12.csv\n",
      "2019.03.13.csv\n",
      "2019.03.14.csv\n",
      "2019.03.15.csv\n",
      "2019.03.18.csv\n",
      "2019.03.19.csv\n",
      "2019.03.20.csv\n",
      "2019.03.21.csv\n",
      "2019.03.22.csv\n",
      "2019.03.25.csv\n",
      "2019.03.26.csv\n",
      "2019.03.27.csv\n",
      "2019.03.28.csv\n",
      "2019.03.29.csv\n",
      "2019.04.01.csv\n",
      "2019.04.02.csv\n",
      "2019.04.03.csv\n",
      "2019.04.04.csv\n",
      "2019.04.08.csv\n",
      "2019.04.09.csv\n",
      "2019.04.10.csv\n",
      "2019.04.11.csv\n",
      "2019.04.12.csv\n",
      "2019.04.15.csv\n",
      "2019.04.16.csv\n",
      "2019.04.17.csv\n",
      "2019.04.18.csv\n",
      "2019.04.19.csv\n",
      "2019.04.22.csv\n",
      "2019.04.23.csv\n",
      "2019.04.24.csv\n",
      "2019.04.25.csv\n",
      "2019.04.26.csv\n",
      "2019.04.29.csv\n",
      "2019.04.30.csv\n",
      "2019.05.06.csv\n",
      "2019.05.07.csv\n",
      "2019.05.08.csv\n",
      "2019.05.09.csv\n",
      "done /Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10split_10min_sma_weightedmean.csv\n"
     ]
    }
   ],
   "source": [
    "#calculating results\n",
    "df_path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/'\n",
    "\n",
    "#create a list to hold all the data\n",
    "data_list=[]\n",
    "#creating a list for each category\n",
    "for i in range(20):\n",
    "    data_list.append([])\n",
    "\n",
    "final_df=pd.DataFrame()    \n",
    "\n",
    "#for each 20 day rolling window\n",
    "for i in range(len(df_list)): \n",
    "    \n",
    "    #skip first 19 days\n",
    "    if i<19: \n",
    "        continue\n",
    "    print(name_list[i])\n",
    "\n",
    "    #get -19 day\n",
    "    sma=df_list[i-19][:,-1].copy() #column for SMA\n",
    "    \n",
    "    #get -18 to 0 day (19 days in total)\n",
    "    for k in range((i-18),i+1): #get 20 day moving averages\n",
    "        sma=np.concatenate((sma,df_list[k][:,-1].copy()))\n",
    "        \n",
    "    cat_sma=categorise_10()\n",
    "    cat_sma.fit(sma) #calculate quartile thresholds for past 20 days\n",
    "    \n",
    "\n",
    "    #get x,y for regression\n",
    "    x_today=df_list[i][:,-1].copy().astype(float) #column for SMA     \n",
    "    y_today=df_list[i][:,-2].copy().astype(float) #column for edge\n",
    "    \n",
    "    #removing all NA\n",
    "    isnum=(~np.isnan(x_today)) & (~np.isnan(y_today))\n",
    "    #get categories of today's sma  \n",
    "    cat_x_today=cat_sma.return_quartile(x_today)\n",
    "    \n",
    "    #for each category\n",
    "    for cat in range(1,21):\n",
    "    \n",
    "        #today's sma filter\n",
    "        sma_filter_today=(cat_x_today==cat)\n",
    "        #filtering NA and sma category\n",
    "        filtered= (isnum & sma_filter_today) \n",
    "        new_y=y_today[filtered].copy()\n",
    "\n",
    "        if (len(new_y)!=0):\n",
    "            data_list[(cat-1)].append(new_y)\n",
    "                \n",
    "reg_result={}                 \n",
    "for cat in range(20):\n",
    "    all_data=data_list[cat][0]\n",
    "    for i in range(1,(len(data_list[cat]))):\n",
    "        all_data=np.concatenate((all_data,data_list[cat][i]))\n",
    "    reg_result['category']=cat+1\n",
    "    reg_result['mean']=np.mean(all_data)\n",
    "    reg_result['std']=np.std(all_data)\n",
    "    reg_result['num obs']=len(all_data)\n",
    "    final_df=final_df.append(reg_result,ignore_index=True)  \n",
    "             \n",
    "temp=df_path+'result_10split_10min_sma_weightedmean.csv'\n",
    "final_df.to_csv(temp)\n",
    "print('done',temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 minute MA\n",
      "mean\n",
      "0    -0.097878\n",
      "1    -0.102309\n",
      "2    -0.159260\n",
      "3    -0.110232\n",
      "4    -0.128544\n",
      "5    -0.146153\n",
      "6    -0.131840\n",
      "7    -0.165528\n",
      "8    -0.124867\n",
      "9    -0.043679\n",
      "10   -0.010687\n",
      "11    0.056937\n",
      "12    0.117166\n",
      "13    0.089648\n",
      "14    0.106341\n",
      "15    0.145953\n",
      "16    0.169440\n",
      "17    0.145777\n",
      "18    0.190879\n",
      "19    0.327253\n",
      "Name: mean, dtype: float64\n",
      "std\n",
      "0     4.515839\n",
      "1     3.432063\n",
      "2     2.980095\n",
      "3     2.743142\n",
      "4     2.573277\n",
      "5     2.522582\n",
      "6     2.542715\n",
      "7     2.470853\n",
      "8     2.299982\n",
      "9     2.358504\n",
      "10    2.384090\n",
      "11    2.410150\n",
      "12    2.408884\n",
      "13    2.502660\n",
      "14    2.559723\n",
      "15    2.694579\n",
      "16    2.872284\n",
      "17    2.931190\n",
      "18    3.273122\n",
      "19    4.514525\n",
      "Name: std, dtype: float64\n",
      "num obs\n",
      "0     141494.0\n",
      "1     145685.0\n",
      "2     150987.0\n",
      "3     153908.0\n",
      "4     155209.0\n",
      "5     159423.0\n",
      "6     160042.0\n",
      "7     163353.0\n",
      "8     165660.0\n",
      "9     171547.0\n",
      "10    170631.0\n",
      "11    163532.0\n",
      "12    159731.0\n",
      "13    156984.0\n",
      "14    156981.0\n",
      "15    152858.0\n",
      "16    148535.0\n",
      "17    145915.0\n",
      "18    141376.0\n",
      "19    137464.0\n",
      "Name: num obs, dtype: float64\n",
      "3 minute MA\n",
      "mean\n",
      "0     0.001250\n",
      "1    -0.041198\n",
      "2    -0.051883\n",
      "3    -0.107162\n",
      "4    -0.209769\n",
      "5    -0.216094\n",
      "6    -0.184283\n",
      "7    -0.147182\n",
      "8    -0.119763\n",
      "9    -0.071557\n",
      "10   -0.085535\n",
      "11    0.064709\n",
      "12    0.111848\n",
      "13    0.081464\n",
      "14    0.130309\n",
      "15    0.116106\n",
      "16    0.212054\n",
      "17    0.172494\n",
      "18    0.244311\n",
      "19    0.267470\n",
      "Name: mean, dtype: float64\n",
      "std\n",
      "0     4.602023\n",
      "1     3.432969\n",
      "2     3.050956\n",
      "3     2.680858\n",
      "4     2.540269\n",
      "5     2.505704\n",
      "6     2.461950\n",
      "7     2.320579\n",
      "8     2.295340\n",
      "9     2.319146\n",
      "10    2.281472\n",
      "11    2.407022\n",
      "12    2.466412\n",
      "13    2.481010\n",
      "14    2.547988\n",
      "15    2.667970\n",
      "16    2.820199\n",
      "17    3.024411\n",
      "18    3.404355\n",
      "19    4.490967\n",
      "Name: std, dtype: float64\n",
      "num obs\n",
      "0     144185.0\n",
      "1     146194.0\n",
      "2     150465.0\n",
      "3     156816.0\n",
      "4     160223.0\n",
      "5     161739.0\n",
      "6     165766.0\n",
      "7     162698.0\n",
      "8     165168.0\n",
      "9     164675.0\n",
      "10    163510.0\n",
      "11    158731.0\n",
      "12    159680.0\n",
      "13    159109.0\n",
      "14    156509.0\n",
      "15    151837.0\n",
      "16    150346.0\n",
      "17    143769.0\n",
      "18    140240.0\n",
      "19    139655.0\n",
      "Name: num obs, dtype: float64\n",
      "5 minute MA\n",
      "mean\n",
      "0     0.105941\n",
      "1    -0.025516\n",
      "2    -0.068087\n",
      "3    -0.118541\n",
      "4    -0.209455\n",
      "5    -0.129873\n",
      "6    -0.153979\n",
      "7    -0.094543\n",
      "8    -0.153285\n",
      "9    -0.088024\n",
      "10   -0.011948\n",
      "11    0.030239\n",
      "12    0.076027\n",
      "13    0.131456\n",
      "14    0.128268\n",
      "15    0.132522\n",
      "16    0.180384\n",
      "17    0.153371\n",
      "18    0.117535\n",
      "19    0.158331\n",
      "Name: mean, dtype: float64\n",
      "std\n",
      "0     4.517636\n",
      "1     3.443871\n",
      "2     2.905725\n",
      "3     2.838151\n",
      "4     2.630724\n",
      "5     2.488701\n",
      "6     2.423161\n",
      "7     2.355596\n",
      "8     2.324552\n",
      "9     2.302108\n",
      "10    2.367235\n",
      "11    2.399430\n",
      "12    2.421573\n",
      "13    2.472781\n",
      "14    2.619350\n",
      "15    2.679747\n",
      "16    2.856165\n",
      "17    3.094874\n",
      "18    3.294875\n",
      "19    4.471395\n",
      "Name: std, dtype: float64\n",
      "num obs\n",
      "0     143547.0\n",
      "1     149736.0\n",
      "2     153344.0\n",
      "3     158583.0\n",
      "4     161928.0\n",
      "5     163553.0\n",
      "6     164238.0\n",
      "7     166012.0\n",
      "8     166464.0\n",
      "9     165344.0\n",
      "10    159430.0\n",
      "11    158248.0\n",
      "12    157567.0\n",
      "13    156589.0\n",
      "14    155741.0\n",
      "15    151634.0\n",
      "16    147080.0\n",
      "17    142234.0\n",
      "18    141709.0\n",
      "19    138334.0\n",
      "Name: num obs, dtype: float64\n",
      "10 minute MA\n",
      "mean\n",
      "0     0.103581\n",
      "1     0.018730\n",
      "2    -0.146253\n",
      "3    -0.124247\n",
      "4    -0.001486\n",
      "5    -0.128039\n",
      "6    -0.152174\n",
      "7    -0.115995\n",
      "8     0.027554\n",
      "9     0.002102\n",
      "10   -0.006698\n",
      "11    0.015583\n",
      "12    0.110061\n",
      "13    0.136677\n",
      "14    0.146759\n",
      "15    0.126522\n",
      "16    0.033025\n",
      "17   -0.018667\n",
      "18    0.091371\n",
      "19   -0.022801\n",
      "Name: mean, dtype: float64\n",
      "std\n",
      "0     4.429564\n",
      "1     3.312904\n",
      "2     3.058038\n",
      "3     2.899154\n",
      "4     2.612549\n",
      "5     2.534606\n",
      "6     2.433620\n",
      "7     2.409975\n",
      "8     2.342946\n",
      "9     2.283748\n",
      "10    2.393845\n",
      "11    2.428492\n",
      "12    2.395093\n",
      "13    2.529061\n",
      "14    2.736729\n",
      "15    2.729946\n",
      "16    2.845054\n",
      "17    2.983240\n",
      "18    3.437210\n",
      "19    4.307419\n",
      "Name: std, dtype: float64\n",
      "num obs\n",
      "0     140108.0\n",
      "1     151928.0\n",
      "2     155050.0\n",
      "3     159623.0\n",
      "4     164341.0\n",
      "5     160411.0\n",
      "6     162961.0\n",
      "7     165176.0\n",
      "8     164147.0\n",
      "9     170790.0\n",
      "10    161606.0\n",
      "11    158808.0\n",
      "12    157478.0\n",
      "13    152463.0\n",
      "14    153113.0\n",
      "15    151118.0\n",
      "16    148769.0\n",
      "17    143311.0\n",
      "18    143294.0\n",
      "19    136820.0\n",
      "Name: num obs, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for time in [1,3,5,10]:\n",
    "    print(time,'minute MA')\n",
    "    data=pd.read_csv('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10split_'+str(time)+'min_sma_weightedmean.csv')\n",
    "    print('mean')\n",
    "    print(data.loc[:,'mean'])\n",
    "    print('std')\n",
    "    print(data.loc[:,'std'])\n",
    "    print('num obs')\n",
    "    print(data.loc[:,'num obs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category</th>\n",
       "      <th>mean</th>\n",
       "      <th>num obs</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.097878</td>\n",
       "      <td>141494.0</td>\n",
       "      <td>4.515839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.102309</td>\n",
       "      <td>145685.0</td>\n",
       "      <td>3.432063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.159260</td>\n",
       "      <td>150987.0</td>\n",
       "      <td>2.980095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.110232</td>\n",
       "      <td>153908.0</td>\n",
       "      <td>2.743142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.128544</td>\n",
       "      <td>155209.0</td>\n",
       "      <td>2.573277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.146153</td>\n",
       "      <td>159423.0</td>\n",
       "      <td>2.522582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.131840</td>\n",
       "      <td>160042.0</td>\n",
       "      <td>2.542715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.165528</td>\n",
       "      <td>163353.0</td>\n",
       "      <td>2.470853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.124867</td>\n",
       "      <td>165660.0</td>\n",
       "      <td>2.299982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.043679</td>\n",
       "      <td>171547.0</td>\n",
       "      <td>2.358504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.010687</td>\n",
       "      <td>170631.0</td>\n",
       "      <td>2.384090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.056937</td>\n",
       "      <td>163532.0</td>\n",
       "      <td>2.410150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.117166</td>\n",
       "      <td>159731.0</td>\n",
       "      <td>2.408884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.089648</td>\n",
       "      <td>156984.0</td>\n",
       "      <td>2.502660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.106341</td>\n",
       "      <td>156981.0</td>\n",
       "      <td>2.559723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.145953</td>\n",
       "      <td>152858.0</td>\n",
       "      <td>2.694579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.169440</td>\n",
       "      <td>148535.0</td>\n",
       "      <td>2.872284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.145777</td>\n",
       "      <td>145915.0</td>\n",
       "      <td>2.931190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.190879</td>\n",
       "      <td>141376.0</td>\n",
       "      <td>3.273122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.327253</td>\n",
       "      <td>137464.0</td>\n",
       "      <td>4.514525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  category      mean   num obs       std\n",
       "0            0       1.0 -0.097878  141494.0  4.515839\n",
       "1            1       2.0 -0.102309  145685.0  3.432063\n",
       "2            2       3.0 -0.159260  150987.0  2.980095\n",
       "3            3       4.0 -0.110232  153908.0  2.743142\n",
       "4            4       5.0 -0.128544  155209.0  2.573277\n",
       "5            5       6.0 -0.146153  159423.0  2.522582\n",
       "6            6       7.0 -0.131840  160042.0  2.542715\n",
       "7            7       8.0 -0.165528  163353.0  2.470853\n",
       "8            8       9.0 -0.124867  165660.0  2.299982\n",
       "9            9      10.0 -0.043679  171547.0  2.358504\n",
       "10          10      11.0 -0.010687  170631.0  2.384090\n",
       "11          11      12.0  0.056937  163532.0  2.410150\n",
       "12          12      13.0  0.117166  159731.0  2.408884\n",
       "13          13      14.0  0.089648  156984.0  2.502660\n",
       "14          14      15.0  0.106341  156981.0  2.559723\n",
       "15          15      16.0  0.145953  152858.0  2.694579\n",
       "16          16      17.0  0.169440  148535.0  2.872284\n",
       "17          17      18.0  0.145777  145915.0  2.931190\n",
       "18          18      19.0  0.190879  141376.0  3.273122\n",
       "19          19      20.0  0.327253  137464.0  4.514525"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10split_1min_sma_weightedmean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
