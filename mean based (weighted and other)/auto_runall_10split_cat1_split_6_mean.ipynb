{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from datetime import datetime,timedelta\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "dir_path='/Users/hudsonyeo/Desktop/Python/leo/data/day'\n",
    "os.chdir('/Users/hudsonyeo/Desktop/Python/leo/data/day')\n",
    "import time\n",
    "def process_dir(dir_list):\n",
    "    x=[]\n",
    "    for dir_ in dir_list:\n",
    "        if dir_!='.DS_Store':\n",
    "            x.append(dir_path+'/'+dir_+'/')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'RM', 'SR', 'TA', 'c', 'fu', 'm', 'ni', 'zn']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/hudsonyeo/Desktop/Python/leo/data/day/RM/',\n",
       " '/Users/hudsonyeo/Desktop/Python/leo/data/day/SR/',\n",
       " '/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/',\n",
       " '/Users/hudsonyeo/Desktop/Python/leo/data/day/c/',\n",
       " '/Users/hudsonyeo/Desktop/Python/leo/data/day/fu/',\n",
       " '/Users/hudsonyeo/Desktop/Python/leo/data/day/m/',\n",
       " '/Users/hudsonyeo/Desktop/Python/leo/data/day/ni/',\n",
       " '/Users/hudsonyeo/Desktop/Python/leo/data/day/zn/']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_list_names=os.listdir(dir_path)\n",
    "dir_list_names.sort()\n",
    "print(dir_list_names)\n",
    "dir_list=process_dir(dir_list_names)\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(dir_path):\n",
    "    return os.listdir(dir_path)\n",
    "\n",
    "class categorise():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(7)\n",
    "                else:\n",
    "                    temp.append(8)\n",
    "            if i<0:\n",
    "                if i>self.threshold[0][2]:\n",
    "                    temp.append(4)\n",
    "                elif i>self.threshold[0][1]:\n",
    "                    temp.append(3)\n",
    "                elif i>self.threshold[0][0]:\n",
    "                    temp.append(2)\n",
    "                else:\n",
    "                    temp.append(1)\n",
    "        return np.asarray(temp)\n",
    "    \n",
    "class categorise_simple():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        self.threshold.append(np.percentile(array,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                else:\n",
    "                    temp.append(4)\n",
    "        return np.asarray(temp)    \n",
    "    \n",
    "class categorise_10():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[10,20,30,40,50,60,70,80,90]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(11)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(12)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(13)\n",
    "                elif i<self.threshold[1][3]:\n",
    "                    temp.append(14)\n",
    "                elif i<self.threshold[1][4]:\n",
    "                    temp.append(15)\n",
    "                elif i<self.threshold[1][5]:\n",
    "                    temp.append(16)\n",
    "                elif i<self.threshold[1][6]:\n",
    "                    temp.append(17)\n",
    "                elif i<self.threshold[1][7]:\n",
    "                    temp.append(18)\n",
    "                elif i<self.threshold[1][8]:\n",
    "                    temp.append(19)                    \n",
    "                else:\n",
    "                    temp.append(20)\n",
    "            if i<0:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                elif i<self.threshold[0][3]:\n",
    "                    temp.append(4)\n",
    "                elif i<self.threshold[0][4]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[0][5]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[0][6]:\n",
    "                    temp.append(7)\n",
    "                elif i<self.threshold[0][7]:\n",
    "                    temp.append(8)\n",
    "                elif i<self.threshold[0][8]:\n",
    "                    temp.append(9)                    \n",
    "                else:\n",
    "                    temp.append(10)\n",
    "        return np.asarray(temp)    \n",
    "    \n",
    "class cross():\n",
    "    def __init__(self):\n",
    "        self.time_last_cross=0\n",
    "        self.current_sign=True\n",
    "        self.last_time=datetime(1900, 1, 1, 8, 59)\n",
    "    def get_time(self,time,price):\n",
    "        if (time-self.last_time)>timedelta(minutes=1):\n",
    "            self.last_time=time\n",
    "            self.time_last_cross=time\n",
    "            return 0\n",
    "        self.last_time=time\n",
    "        if (price>0) and self.current_sign : #if price positive and current trend is also positive\n",
    "            return (time-self.time_last_cross).total_seconds()\n",
    "        elif (price<0) and (not self.current_sign): #if price negative and current trend is negative\n",
    "            return (time-self.time_last_cross).total_seconds()\n",
    "        else: #if price positive, trend negative or price negative, trend positive\n",
    "            self.time_last_cross=time\n",
    "            self.current_sign=(price>0)\n",
    "            return 0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_smart_price(dataset):\n",
    "    data=dataset[:]\n",
    "    \n",
    "    #to combat the limit up event, where price is set to 0. \n",
    "    rows=(data.loc[:,'BidPrice1']==0) #count rows of bid price equal 0\n",
    "    if (np.any(rows)): #if there is such a row\n",
    "        data.at[rows,'BidPrice1']=data.loc[rows,'AskPrice1'] #for that row, assign ask price to it\n",
    "    rows=(data.loc[:,'AskPrice1']==0) #do the same for ask price\n",
    "    if (np.any(rows)):\n",
    "        data.at[rows,'AskPrice1']=data.loc[rows,'BidPrice1'] \n",
    "        \n",
    "    data['smart_price']=data.loc[:,'BidPrice1']*data.loc[:,'AskVol1']+data.loc[:,'AskPrice1']*data.loc[:,'BidVol1']\n",
    "    data.at[:,'smart_price']=data.loc[:,'smart_price']/(data.loc[:,['BidVol1','AskVol1']].sum(axis=1))  \n",
    "    return data\n",
    "\n",
    "def calc_present_vol(dataset):\n",
    "    data=dataset[:]\n",
    "    data['current_vol']=data.loc[:,'Volume'].diff().fillna(0)/2\n",
    "    return data\n",
    "\n",
    "def calc_future_price(dataset,time_ahead=30,time_index=44, price_col=-2):\n",
    "    data=dataset[:]\n",
    "    future_price=[]\n",
    "    length=len(data)\n",
    "    for i in range(len(data)):\n",
    "        current_time=data[i,time_index]+timedelta(seconds=time_ahead)\n",
    "        #print(data[i,44])\n",
    "        j=0\n",
    "        #print(current_time)\n",
    "        while((i+j)<length and current_time>data[(i+j),time_index]):\n",
    "            j+=1\n",
    "        if (i+j)<length:\n",
    "            future_price.append(data[(i+j),price_col]) \n",
    "        else:\n",
    "            future_price.append(np.nan)\n",
    "    future_price=np.asarray(future_price)\n",
    "    future_price=np.expand_dims(future_price,axis=1)\n",
    "    return np.concatenate((data,future_price),axis=1)\n",
    "\n",
    "\n",
    "def calc_edge(dataset,future_col=-1,current_col=-3):\n",
    "    data=dataset.copy()\n",
    "    temp=data[:,future_col]-data[:,current_col]\n",
    "    temp=np.expand_dims(temp,axis=1)\n",
    "    return np.concatenate((data,temp),axis=1)\n",
    "\n",
    "def set_index(dataset,time_index=44):\n",
    "    data=dataset[:]\n",
    "    index=data[:,time_index]\n",
    "    new_index=[]\n",
    "    for j in range(len(index)):\n",
    "        i=str(index[j]*1000)\n",
    "        if len(i)==11:\n",
    "            i='0'+i\n",
    "        i=i[:-10]+':'+i[-10:]\n",
    "        i=i[:-8]+':'+i[-8:]\n",
    "        i=i[:-6]+':'+i[-6:]\n",
    "        new_index.append(datetime.strptime(i,\"%H:%M:%S:%f\"))\n",
    "    data[:,time_index]=new_index\n",
    "    return data\n",
    "\n",
    "def calc_sma_fast(dataset,duration=1,time_index=44,price_col=-4): #faster way to calculate SMA, 0.05 seconds for 5000 rows\n",
    "    data=dataset[:]\n",
    "    sma_values=[] \n",
    "    smart_sum=np.cumsum(data[:,price_col]) #smart price column is -4\n",
    "    for i in range(len(data)):\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        j=220*duration#4x60=240\n",
    "        while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "            j+=1\n",
    "        if (i-j>=0):\n",
    "            sma=(smart_sum[i]-smart_sum[i-j])/(j)\n",
    "            sma_values.append(sma)\n",
    "        else:\n",
    "            sma=smart_sum[i]/(i+1)\n",
    "            sma_values.append(sma)\n",
    "\n",
    "    sma_values=np.asarray(sma_values)\n",
    "    sma_values=data[:,price_col]-sma_values\n",
    "    sma_values=np.expand_dims(sma_values,axis=1)\n",
    "    return np.concatenate((data,sma_values),axis=1)  \n",
    "\n",
    "def calc_past_vol(dataset,duration=1,time_index=44,vol_col=-4): #\n",
    "    data=dataset[:].copy()\n",
    "    vol_values=[] \n",
    "    vol_sum=np.cumsum(data[:,vol_col])\n",
    "    for i in range(len(data)):\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        j=220*duration#4x60=240\n",
    "        while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "            j+=1\n",
    "        if (i-j>=0):\n",
    "            vol=(vol_sum[i]-vol_sum[i-j])\n",
    "            vol_values.append(vol)\n",
    "        else:\n",
    "            vol=vol_sum[i]\n",
    "            vol_values.append(vol)\n",
    "    vol_values=np.asarray(vol_values)\n",
    "    vol_values=np.expand_dims(vol_values,axis=1)\n",
    "    return np.concatenate((data,vol_values),axis=1) \n",
    "\n",
    "def last_cross(dataset,time_index=44,price_col=-3):\n",
    "    data=dataset[:]\n",
    "    last_cross=cross()\n",
    "    timings=[]\n",
    "    for i in range(len(data)):\n",
    "        timings.append(last_cross.get_time(data[i,time_index],data[i,price_col]))\n",
    "    timings=np.asarray(timings)\n",
    "    timings=np.expand_dims(timings,axis=1)\n",
    "    return np.concatenate((data,timings),axis=1)\n",
    "\n",
    "def process(dataset,sma_duration=1,vol_duration=1,time_index=44):\n",
    "    data=dataset[:]\n",
    "    data=calc_smart_price(data).values #new\n",
    "    data=set_index(data,time_index=time_index) #no change\n",
    "    data=calc_future_price(data,time_index=time_index,price_col=-1) #new\n",
    "    data=calc_edge(data,future_col=-1,current_col=-2) #new\n",
    "    data=calc_sma_fast(data,duration=sma_duration,time_index=time_index,price_col=-3) #new\n",
    "    data=last_cross(data,time_index=time_index,price_col=-1) #new\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(path,file_list,sma_duration=1,time_index=44):\n",
    "    df_list=[]\n",
    "    name_list=[]\n",
    "    print('processing files...')\n",
    "    for file in file_list: #read all files and add them to file_list\n",
    "        if file[-3:]=='csv': #check if file is a CSV\n",
    "            name_list.append(file)\n",
    "            df_list.append(process(pd.read_csv(path+file),sma_duration=sma_duration,time_index=time_index))   \n",
    "            print(file)\n",
    "    print('complete processing')\n",
    "    return name_list,df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(df_path, df_list,name_list,sma_duration=1):\n",
    "    error_list=[]\n",
    "    final_df=pd.DataFrame()    \n",
    "\n",
    "    for i in range(len(df_list)): #for each 20 day rolling window\n",
    "        if i<19:\n",
    "            continue\n",
    "        print(name_list[i])\n",
    "\n",
    "        #get -19 day\n",
    "        sma=df_list[i-19][:,-2].copy() #column for SMA\n",
    "        time_cross=df_list[i-19][:,-1].copy()\n",
    "\n",
    "        #get -18 to 0 day (19 days in total)\n",
    "        for k in range((i-18),i+1): #get 20 day moving averages\n",
    "            sma=np.concatenate((sma,df_list[k][:,-2].copy()))\n",
    "            time_cross=np.concatenate((time_cross,df_list[k][:,-1].copy()))\n",
    "\n",
    "        cat_sma=categorise_10()\n",
    "        cat_sma.fit(sma) #calculate quartile thresholds for past 20 days\n",
    "\n",
    "        #get categories for past 20 days\n",
    "        cat_sma_20=(cat_sma.return_quartile(sma))   \n",
    "\n",
    "        #get x,y for regression\n",
    "        x_today=df_list[i][:,-2].copy().astype(float) #column for SMA     \n",
    "        y_today=df_list[i][:,-3].copy().astype(float) #column for edge\n",
    "        time_cross_today=df_list[i][:,-1].copy()    \n",
    "\n",
    "        #removing all NA\n",
    "        isnum=(~np.isnan(x_today)) & (~np.isnan(y_today))\n",
    "        #get categories of today's sma  \n",
    "        cat_x_today=cat_sma.return_quartile(x_today)\n",
    "\n",
    "        reg_result={}\n",
    "        reg_result['date']=name_list[i]\n",
    "        reg_result['total_obs']=len(x_today[isnum])   \n",
    "\n",
    "        for cat in range(1,21):\n",
    "            #check past 20 days quartiles and filter time_cross by category\n",
    "            time_cross_fit=time_cross[cat_sma_20==cat].copy()\n",
    "\n",
    "            #simple quartile categorisation\n",
    "            cat_time=categorise_simple()\n",
    "            cat_time.fit(time_cross_fit)\n",
    "\n",
    "            #today's sma filter\n",
    "            sma_filter_today=(cat_x_today==cat)\n",
    "            #today's time categories\n",
    "            cat_time_today=cat_time.return_quartile(time_cross_today)\n",
    "\n",
    "\n",
    "            for quartile in [1,2,3,4]:\n",
    "\n",
    "                filtered= (isnum & sma_filter_today) #filtering NA and sma quartile\n",
    "                filtered= filtered & (cat_time_today==quartile) #filtering volume\n",
    "                new_y=y_today[filtered].copy()\n",
    "\n",
    "                q='ma_cat_'+str(cat)+'_timecross_quartile'+str(quartile)+'_'\n",
    "                if (len(new_y)!=0):\n",
    "                    if np.abs(np.mean(new_y))>10:\n",
    "                        error_list.append((name_list[i],cat,quartile,new_y))  \n",
    "                        print('error detected cat',cat,'quartile',quartile)\n",
    "                    reg_result[(q+'mean')]=np.mean(new_y)\n",
    "                    reg_result[(q+'std')]=np.std(new_y)\n",
    "                    reg_result[(q+'num_obs')]=len(new_y)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    reg_result[(q+'mean')]=np.nan\n",
    "                    reg_result[(q+'std')]=np.nan\n",
    "                    reg_result[(q+'num_obs')]='0'\n",
    "\n",
    "        final_df=final_df.append(reg_result,ignore_index=True)                \n",
    "    temp=df_path+'result_10split_time_cross_'+str(sma_duration)+'min_sma_mean.csv'\n",
    "    final_df.to_csv(temp)\n",
    "    print('done',temp)   \n",
    "    return error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each path in the directory\n",
    "for dir_path in dir_list:\n",
    "    \n",
    "    file_list=get_file_list(dir_path)\n",
    "    file_list.sort()\n",
    "    test_df=pd.read_csv(dir_path+file_list[1])\n",
    "    \n",
    "    test_columns=test_df.columns \n",
    "    time_index=np.where(test_columns=='Time')[0][0]         \n",
    "    print('time index',time_index)\n",
    "    \n",
    "    for sma_duration in [1,3,5,10]:\n",
    "        start=time.time()\n",
    "        print('start',dir_path,sma_duration) \n",
    "\n",
    "        name_list,df_list=process_files(dir_path, file_list,sma_duration=sma_duration,time_index=time_index) #process, get SMA and vol data\n",
    "        mid=time.time()\n",
    "        print(mid-start)\n",
    "        #split into categories and get means\n",
    "        error_list=run_analysis(dir_path+'/results/', df_list,name_list,sma_duration=sma_duration)  \n",
    "        if len(error_list)!=0:\n",
    "            print(error_list)\n",
    "        end=time.time()\n",
    "        print('complete',end-mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path='/Users/hudsonyeo/Desktop/Python/leo/data/day'\n",
    "dir_list_names=os.listdir(dir_path)\n",
    "dir_list_names.sort()\n",
    "dir_list=process_dir(dir_list_names)\n",
    "#dir_list=dir_list[4:]\n",
    "for i in range(len(dir_list)):\n",
    "    dir_list[i]+='results/result_10sma,6vol_1min,'\n",
    "dir_list,dir_list_names[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dir_list_names[1:]:\n",
    "    for num in [1,3,5,10]:\n",
    "        path='/Users/hudsonyeo/Desktop/Python/leo/data/day/'+i+'/results/result_10sma,6vol_1min,'+str(num)+'min_sma,vol_mean.csv'\n",
    "        print(i)\n",
    "        print('sma:',num)\n",
    "        data=pd.read_csv(path)\n",
    "        x=[]\n",
    "        x_std=[]\n",
    "        pos=[]\n",
    "        num_obs=[]\n",
    "        for ma_cat in range(1,21):\n",
    "            for vol_cat in range(1,5):\n",
    "                col='ma_cat_'+str(ma_cat)+'_vol_quartile'+str(vol_cat)+'_mean'\n",
    "                std=data.loc[:,col].std()\n",
    "                mean=data.loc[:,col].mean()\n",
    "                column=data.loc[:,col]\n",
    "                x_std.append(std)\n",
    "                x.append(mean)\n",
    "                percentage=len(column[column>=0])/len(column)\n",
    "                pos.append(percentage)  \n",
    "\n",
    "                obs='ma_cat_'+str(ma_cat)+'_vol_quartile'+str(vol_cat)+'_num_obs'\n",
    "                obs=data.loc[:,obs].sum()\n",
    "                num_obs.append(obs)\n",
    "        x=np.asarray(x)\n",
    "        x=np.reshape(x,(20,4))\n",
    "        x=np.around(x,3)\n",
    "        x_std=np.asarray(x_std)\n",
    "        x_std=np.reshape(x_std,(20,4))\n",
    "        pos=np.asarray(pos)\n",
    "        pos=np.reshape(pos,(20,4))\n",
    "        num_obs=np.asarray(num_obs)\n",
    "        num_obs=np.reshape(num_obs,(20,4))\n",
    "        print('mean\\n',x)\n",
    "        print('std\\n',x_std)\n",
    "        print('% positive\\n',pos)\n",
    "        print('num obs\\n',num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/Users/hudsonyeo/Desktop/Python/leo/data/day/fu/results/second/result_10sma,6vol_1min,5min_sma,vol_mean.csv')\n",
    "x=[]\n",
    "x_std=[]\n",
    "pos=[]\n",
    "num_obs=[]\n",
    "for ma_cat in range(1,21):\n",
    "    for vol_cat in range(1,5):\n",
    "        col='ma_cat_'+str(ma_cat)+'_vol_quartile'+str(vol_cat)+'_mean'\n",
    "        std=data.loc[:,col].std()\n",
    "        mean=data.loc[:,col].mean()\n",
    "        column=data.loc[:,col]\n",
    "        x_std.append(std)\n",
    "        x.append(mean)\n",
    "        percentage=len(column[column>=0])/len(column)\n",
    "        pos.append(percentage)  \n",
    "        \n",
    "        obs='ma_cat_'+str(ma_cat)+'_vol_quartile'+str(vol_cat)+'_num_obs'\n",
    "        obs=data.loc[:,obs].sum()\n",
    "        num_obs.append(obs)\n",
    "x=np.asarray(x)\n",
    "x=np.reshape(x,(20,4))\n",
    "x=np.around(x,3)\n",
    "x_std=np.asarray(x_std)\n",
    "x_std=np.reshape(x_std,(20,4))\n",
    "pos=np.asarray(pos)\n",
    "pos=np.reshape(pos,(20,4))\n",
    "num_obs=np.asarray(num_obs)\n",
    "num_obs=np.reshape(num_obs,(20,4))\n",
    "print('mean\\n',x)\n",
    "print('std\\n',x_std)\n",
    "print('% positive\\n',pos)\n",
    "print('num obs\\n',num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('/Users/hudsonyeo/Desktop/Python/leo/data/day/ni/2019.01.03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index=np.where(test.columns.values=='Time')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "processed=process(test,time_index=time_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2019-01-03', 1546477449971876, 'A', 'ni1905',\n",
       "       datetime.datetime(1900, 1, 1, 9, 4, 10, 500000), 86080, 88580,\n",
       "       86080, 88260, 0, 405076, 0, 35390392960, 332948, 372986, 0, 87170,\n",
       "       0, 86280, 92400, 81930, 88260, 4, 88270, 3, 20190103, 20190103,\n",
       "       20190103, 0, 32650000, '192.168.30.96:22', 88265.71428571429,\n",
       "       88260.76923076923, -4.945054945055745, -2.251073097329936, 0.0],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
