{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into 20 categories (10-90% percentile for positive and negative so 10x2) based on SMA 1 minute from past 20 days, \n",
    "#then within each SMA category, separate into quartiles based on cumulative volume in 1 minute\n",
    "#calculate the mean and std of the edge in each case\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from datetime import datetime,timedelta\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA'\n",
    "os.chdir('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA')\n",
    "file_list=os.listdir(path)\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '2019.01.02.csv',\n",
       " '2019.01.03.csv',\n",
       " '2019.01.04.csv',\n",
       " '2019.01.07.csv',\n",
       " '2019.01.08.csv',\n",
       " '2019.01.09.csv',\n",
       " '2019.01.10.csv',\n",
       " '2019.01.11.csv',\n",
       " '2019.01.14.csv',\n",
       " '2019.01.15.csv',\n",
       " '2019.01.16.csv',\n",
       " '2019.01.17.csv',\n",
       " '2019.01.18.csv',\n",
       " '2019.01.21.csv',\n",
       " '2019.01.22.csv',\n",
       " '2019.01.23.csv',\n",
       " '2019.01.24.csv',\n",
       " '2019.01.25.csv',\n",
       " '2019.01.28.csv',\n",
       " '2019.01.29.csv',\n",
       " '2019.01.30.csv',\n",
       " '2019.01.31.csv',\n",
       " '2019.02.01.csv',\n",
       " '2019.02.11.csv',\n",
       " '2019.02.12.csv',\n",
       " '2019.02.13.csv',\n",
       " '2019.02.14.csv',\n",
       " '2019.02.15.csv',\n",
       " '2019.02.18.csv',\n",
       " '2019.02.19.csv',\n",
       " '2019.02.20.csv',\n",
       " '2019.02.21.csv',\n",
       " '2019.02.22.csv',\n",
       " '2019.02.25.csv',\n",
       " '2019.02.26.csv',\n",
       " '2019.02.27.csv',\n",
       " '2019.02.28.csv',\n",
       " '2019.03.01.csv',\n",
       " '2019.03.04.csv',\n",
       " '2019.03.05.csv',\n",
       " '2019.03.06.csv',\n",
       " '2019.03.07.csv',\n",
       " '2019.03.08.csv',\n",
       " '2019.03.11.csv',\n",
       " '2019.03.12.csv',\n",
       " '2019.03.13.csv',\n",
       " '2019.03.14.csv',\n",
       " '2019.03.15.csv',\n",
       " '2019.03.18.csv',\n",
       " '2019.03.19.csv',\n",
       " '2019.03.20.csv',\n",
       " '2019.03.21.csv',\n",
       " '2019.03.22.csv',\n",
       " '2019.03.25.csv',\n",
       " '2019.03.26.csv',\n",
       " '2019.03.27.csv',\n",
       " '2019.03.28.csv',\n",
       " '2019.03.29.csv',\n",
       " '2019.04.01.csv',\n",
       " '2019.04.02.csv',\n",
       " '2019.04.03.csv',\n",
       " '2019.04.04.csv',\n",
       " '2019.04.08.csv',\n",
       " '2019.04.09.csv',\n",
       " '2019.04.10.csv',\n",
       " '2019.04.11.csv',\n",
       " '2019.04.12.csv',\n",
       " '2019.04.15.csv',\n",
       " '2019.04.16.csv',\n",
       " '2019.04.17.csv',\n",
       " '2019.04.18.csv',\n",
       " '2019.04.19.csv',\n",
       " '2019.04.22.csv',\n",
       " '2019.04.23.csv',\n",
       " '2019.04.24.csv',\n",
       " '2019.04.25.csv',\n",
       " '2019.04.26.csv',\n",
       " '2019.04.29.csv',\n",
       " '2019.04.30.csv',\n",
       " '2019.05.06.csv',\n",
       " '2019.05.07.csv',\n",
       " '2019.05.08.csv',\n",
       " '2019.05.09.csv',\n",
       " 'results']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class categorise():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(7)\n",
    "                else:\n",
    "                    temp.append(8)\n",
    "            if i<0:\n",
    "                if i>self.threshold[0][2]:\n",
    "                    temp.append(4)\n",
    "                elif i>self.threshold[0][1]:\n",
    "                    temp.append(3)\n",
    "                elif i>self.threshold[0][0]:\n",
    "                    temp.append(2)\n",
    "                else:\n",
    "                    temp.append(1)\n",
    "        return np.asarray(temp)\n",
    "    \n",
    "class categorise_simple():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        self.threshold.append(np.percentile(array,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                else:\n",
    "                    temp.append(4)\n",
    "        return np.asarray(temp)    \n",
    "    \n",
    "class categorise_10():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[10,20,30,40,50,60,70,80,90]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(11)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(12)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(13)\n",
    "                elif i<self.threshold[1][3]:\n",
    "                    temp.append(14)\n",
    "                elif i<self.threshold[1][4]:\n",
    "                    temp.append(15)\n",
    "                elif i<self.threshold[1][5]:\n",
    "                    temp.append(16)\n",
    "                elif i<self.threshold[1][6]:\n",
    "                    temp.append(17)\n",
    "                elif i<self.threshold[1][7]:\n",
    "                    temp.append(18)\n",
    "                elif i<self.threshold[1][8]:\n",
    "                    temp.append(19)                    \n",
    "                else:\n",
    "                    temp.append(20)\n",
    "            if i<0:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                elif i<self.threshold[0][3]:\n",
    "                    temp.append(4)\n",
    "                elif i<self.threshold[0][4]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[0][5]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[0][6]:\n",
    "                    temp.append(7)\n",
    "                elif i<self.threshold[0][7]:\n",
    "                    temp.append(8)\n",
    "                elif i<self.threshold[0][8]:\n",
    "                    temp.append(9)                    \n",
    "                else:\n",
    "                    temp.append(10)\n",
    "        return np.asarray(temp)    \n",
    "class cross():\n",
    "    def __init__(self):\n",
    "        self.time_last_cross=0\n",
    "        self.current_sign=True\n",
    "        self.last_time=datetime(1900, 1, 1, 8, 59)\n",
    "    def get_time(self,time,price):\n",
    "        if (time-self.last_time)>timedelta(minutes=1):\n",
    "            self.last_time=time\n",
    "            self.time_last_cross=time\n",
    "            return 0\n",
    "        self.last_time=time\n",
    "        if (price>0) and self.current_sign : #if price positive and current trend is also positive\n",
    "            return (time-self.time_last_cross).total_seconds()\n",
    "        elif (price<0) and (not self.current_sign): #if price negative and current trend is negative\n",
    "            return (time-self.time_last_cross).total_seconds()\n",
    "        else: #if price positive, trend negative or price negative, trend positive\n",
    "            self.time_last_cross=time\n",
    "            self.current_sign=(price>0)\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_smart_price(dataset):\n",
    "    data=dataset.copy()\n",
    "    \n",
    "    #to combat the limit up event, where price is set to 0. \n",
    "    rows=(data.loc[:,'BidPrice1']==0) #count rows of bid price equal 0\n",
    "    if (np.any(rows)): #if there is such a row\n",
    "        data.at[rows,'BidPrice1']=data.loc[rows,'AskPrice1'] #for that row, assign ask price to it\n",
    "    rows=(data.loc[:,'AskPrice1']==0) #do the same for ask price\n",
    "    if (np.any(rows)):\n",
    "        data.at[rows,'AskPrice1']=data.loc[rows,'BidPrice1'] \n",
    "        \n",
    "    data['smart_price']=data.loc[:,'BidPrice1']*data.loc[:,'AskVol1']+data.loc[:,'AskPrice1']*data.loc[:,'BidVol1']\n",
    "    data.at[:,'smart_price']=data.loc[:,'smart_price']/(data.loc[:,['BidVol1','AskVol1']].sum(axis=1))  \n",
    "    return data\n",
    "\n",
    "def calc_present_vol(dataset):\n",
    "    data=dataset.copy()\n",
    "    data['current_vol']=data.loc[:,'Volume'].diff().fillna(0)/2\n",
    "    return data\n",
    "\n",
    "def calc_future_price(dataset,time_ahead=30,time_index=44, price_col=-2):\n",
    "    data=dataset.copy()\n",
    "    future_price=[]\n",
    "    length=len(data)\n",
    "    for i in range(len(data)):\n",
    "        current_time=data[i,time_index]+timedelta(seconds=time_ahead)\n",
    "        \n",
    "        j=0 #could alternatively use 30 x 3 then search forward and backward\n",
    "        \n",
    "        #search forwards\n",
    "        while((i+j)<length and current_time>data[(i+j),time_index]):\n",
    "            j+=1\n",
    "        if (i+j)<length:\n",
    "            #if index is in the dataframe\n",
    "            future_price.append(data[(i+j),price_col]) \n",
    "        else:\n",
    "            #price ahead does not exist\n",
    "            future_price.append(np.nan) \n",
    "    future_price=np.asarray(future_price)\n",
    "    future_price=np.expand_dims(future_price,axis=1)\n",
    "    return np.concatenate((data,future_price),axis=1)\n",
    "\n",
    "\n",
    "def calc_edge(dataset,future_col=-1,current_col=-3):\n",
    "    data=dataset.copy()\n",
    "    temp=data[:,future_col]-data[:,current_col]\n",
    "    temp=np.expand_dims(temp,axis=1)\n",
    "    return np.concatenate((data,temp),axis=1)\n",
    "\n",
    "def set_index(dataset,time_index=44):\n",
    "    data=dataset.copy()\n",
    "    index=data[:,time_index]\n",
    "    new_index=[]\n",
    "    for j in range(len(index)):\n",
    "        i=str(index[j]*1000)\n",
    "        if len(i)==11:\n",
    "            i='0'+i\n",
    "        i=i[:-10]+':'+i[-10:]\n",
    "        i=i[:-8]+':'+i[-8:]\n",
    "        i=i[:-6]+':'+i[-6:]\n",
    "        new_index.append(datetime.strptime(i,\"%H:%M:%S:%f\"))\n",
    "    data[:,time_index]=new_index\n",
    "    return data\n",
    "\n",
    "def calc_sma_fast(dataset,price_col,duration=1,time_index=44): #faster way to calculate SMA, 0.05 seconds for 5000 rows\n",
    "    data=dataset.copy()\n",
    "    sma_values=[] \n",
    "    smart_sum=np.cumsum(data[:,price_col]) #smart price column is -4\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        #finding ending point\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        \n",
    "        #finding start point\n",
    "        j=220*duration#4x60=240\n",
    "        \n",
    "        if i-j>0:\n",
    "            if data[i-j,time_index]>last_time: \n",
    "                \n",
    "                #if starting point time is greater than ending point time\n",
    "                #search backward\n",
    "                while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "                    j+=1\n",
    "                    \n",
    "                #activate next line in order to debug and troubleshoot\n",
    "                #print('backward',i,j,data[i,time_index],data[i-j,time_index],last_time)\n",
    "                \n",
    "                sma=(smart_sum[i]-smart_sum[i-j])/(j)\n",
    "                sma_values.append(sma)                \n",
    "                \n",
    "            else: \n",
    "                \n",
    "                #search forward\n",
    "                while(data[i-j,time_index]<last_time):\n",
    "                    j-=1\n",
    "                    \n",
    "                #activate next line in order to debug and troubleshoot\n",
    "                #print('forward',i,j,data[i,time_index],data[i-j,time_index],last_time)\n",
    "                \n",
    "                if j!=0:\n",
    "                    sma=(smart_sum[i]-smart_sum[i-j])/(j)\n",
    "                    sma_values.append(sma)   \n",
    "                    \n",
    "                else:\n",
    "                    sma_values.append(0)\n",
    "                    \n",
    "        else: #starting point is at 0\n",
    "            \n",
    "            sma=smart_sum[i]/(i+1)\n",
    "            sma_values.append(sma)                       \n",
    "\n",
    "    sma_values=np.asarray(sma_values)\n",
    "    sma_values=data[:,price_col]-sma_values\n",
    "    sma_values=np.expand_dims(sma_values,axis=1)\n",
    "    return np.concatenate((data,sma_values),axis=1)   \n",
    "\n",
    "def calc_past_vol(dataset,duration=1,time_index=44,vol_col=-4): #\n",
    "    data=dataset[:].copy()\n",
    "    vol_values=[] \n",
    "    vol_sum=np.cumsum(data[:,vol_col])\n",
    "    for i in range(len(data)):\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        j=220*duration#4x60=240\n",
    "        while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "            j+=1\n",
    "        if (i-j>=0):\n",
    "            vol=(vol_sum[i]-vol_sum[i-j])\n",
    "            vol_values.append(vol)\n",
    "        else:\n",
    "            vol=vol_sum[i]\n",
    "            vol_values.append(vol)\n",
    "    vol_values=np.asarray(vol_values)\n",
    "    vol_values=np.expand_dims(vol_values,axis=1)\n",
    "    return np.concatenate((data,vol_values),axis=1) \n",
    "\n",
    "def last_cross(dataset,time_index=44,price_col=-3):\n",
    "    data=dataset.copy()\n",
    "    last_cross=cross()\n",
    "    timings=[]\n",
    "    for i in range(len(data)):\n",
    "        timings.append(last_cross.get_time(data[i,time_index],data[i,price_col]))\n",
    "    timings=np.asarray(timings)\n",
    "    timings=np.expand_dims(timings,axis=1)\n",
    "    return np.concatenate((data,timings),axis=1)\n",
    "\n",
    "def process(dataset,sma_duration=1,vol_duration=1,time_index=44):\n",
    "    data=dataset[:]\n",
    "    data=calc_smart_price(data).values #new\n",
    "    data=set_index(data,time_index=time_index) #no change\n",
    "    data=calc_future_price(data,time_index=time_index,price_col=-1) #new\n",
    "    data=calc_edge(data,future_col=-1,current_col=-2) #new\n",
    "    data=calc_sma_fast(data,duration=sma_duration,time_index=time_index,price_col=-3) #new\n",
    "    data=last_cross(data,time_index=time_index,price_col=-1) #new\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.01.02.csv read\n",
      "2019.01.03.csv read\n",
      "2019.01.04.csv read\n",
      "2019.01.07.csv read\n",
      "2019.01.08.csv read\n",
      "2019.01.09.csv read\n",
      "2019.01.10.csv read\n",
      "2019.01.11.csv read\n",
      "2019.01.14.csv read\n",
      "2019.01.15.csv read\n",
      "2019.01.16.csv read\n",
      "2019.01.17.csv read\n",
      "2019.01.18.csv read\n",
      "2019.01.21.csv read\n",
      "2019.01.22.csv read\n",
      "2019.01.23.csv read\n",
      "2019.01.24.csv read\n",
      "2019.01.25.csv read\n",
      "2019.01.28.csv read\n",
      "2019.01.29.csv read\n",
      "2019.01.30.csv read\n",
      "2019.01.31.csv read\n",
      "2019.02.01.csv read\n",
      "2019.02.11.csv read\n",
      "2019.02.12.csv read\n",
      "2019.02.13.csv read\n",
      "2019.02.14.csv read\n",
      "2019.02.15.csv read\n",
      "2019.02.18.csv read\n",
      "2019.02.19.csv read\n",
      "2019.02.20.csv read\n",
      "2019.02.21.csv read\n",
      "2019.02.22.csv read\n",
      "2019.02.25.csv read\n",
      "2019.02.26.csv read\n",
      "2019.02.27.csv read\n",
      "2019.02.28.csv read\n",
      "2019.03.01.csv read\n",
      "2019.03.04.csv read\n",
      "2019.03.05.csv read\n",
      "2019.03.06.csv read\n",
      "2019.03.07.csv read\n",
      "2019.03.08.csv read\n",
      "2019.03.11.csv read\n",
      "2019.03.12.csv read\n",
      "2019.03.13.csv read\n",
      "2019.03.14.csv read\n",
      "2019.03.15.csv read\n",
      "2019.03.18.csv read\n",
      "2019.03.19.csv read\n",
      "2019.03.20.csv read\n",
      "2019.03.21.csv read\n",
      "2019.03.22.csv read\n",
      "2019.03.25.csv read\n",
      "2019.03.26.csv read\n",
      "2019.03.27.csv read\n",
      "2019.03.28.csv read\n",
      "2019.03.29.csv read\n",
      "2019.04.01.csv read\n",
      "2019.04.02.csv read\n",
      "2019.04.03.csv read\n",
      "2019.04.04.csv read\n",
      "2019.04.08.csv read\n",
      "2019.04.09.csv read\n",
      "2019.04.10.csv read\n",
      "2019.04.11.csv read\n",
      "2019.04.12.csv read\n",
      "2019.04.15.csv read\n",
      "2019.04.16.csv read\n",
      "2019.04.17.csv read\n",
      "2019.04.18.csv read\n",
      "2019.04.19.csv read\n",
      "2019.04.22.csv read\n",
      "2019.04.23.csv read\n",
      "2019.04.24.csv read\n",
      "2019.04.25.csv read\n",
      "2019.04.26.csv read\n",
      "2019.04.29.csv read\n",
      "2019.04.30.csv read\n",
      "2019.05.06.csv read\n",
      "2019.05.07.csv read\n",
      "2019.05.08.csv read\n",
      "2019.05.09.csv read\n"
     ]
    }
   ],
   "source": [
    "#processing raw data to get technicals\n",
    "df_list=[]\n",
    "name_list=[]\n",
    "path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/'\n",
    "for file in file_list: #read all files and add them to file_list\n",
    "    if file[-3:]=='csv': #check if file is a CSV\n",
    "        name_list.append(file)\n",
    "        df_list.append(process(pd.read_csv(path+file),sma_duration=10))\n",
    "        print(file,'read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.01.29.csv\n",
      "2019.01.30.csv\n",
      "2019.01.31.csv\n",
      "2019.02.01.csv\n",
      "2019.02.11.csv\n",
      "2019.02.12.csv\n",
      "2019.02.13.csv\n",
      "2019.02.14.csv\n",
      "2019.02.15.csv\n",
      "2019.02.18.csv\n",
      "2019.02.19.csv\n",
      "2019.02.20.csv\n",
      "2019.02.21.csv\n",
      "2019.02.22.csv\n",
      "2019.02.25.csv\n",
      "2019.02.26.csv\n",
      "2019.02.27.csv\n",
      "2019.02.28.csv\n",
      "2019.03.01.csv\n",
      "2019.03.04.csv\n",
      "2019.03.05.csv\n",
      "2019.03.06.csv\n",
      "2019.03.07.csv\n",
      "2019.03.08.csv\n",
      "2019.03.11.csv\n",
      "2019.03.12.csv\n",
      "2019.03.13.csv\n",
      "2019.03.14.csv\n",
      "2019.03.15.csv\n",
      "2019.03.18.csv\n",
      "2019.03.19.csv\n",
      "2019.03.20.csv\n",
      "2019.03.21.csv\n",
      "2019.03.22.csv\n",
      "2019.03.25.csv\n",
      "2019.03.26.csv\n",
      "2019.03.27.csv\n",
      "2019.03.28.csv\n",
      "2019.03.29.csv\n",
      "2019.04.01.csv\n",
      "2019.04.02.csv\n",
      "2019.04.03.csv\n",
      "2019.04.04.csv\n",
      "2019.04.08.csv\n",
      "2019.04.09.csv\n",
      "2019.04.10.csv\n",
      "2019.04.11.csv\n",
      "2019.04.12.csv\n",
      "2019.04.15.csv\n",
      "2019.04.16.csv\n",
      "2019.04.17.csv\n",
      "2019.04.18.csv\n",
      "2019.04.19.csv\n",
      "2019.04.22.csv\n",
      "2019.04.23.csv\n",
      "2019.04.24.csv\n",
      "2019.04.25.csv\n",
      "2019.04.26.csv\n",
      "2019.04.29.csv\n",
      "2019.04.30.csv\n",
      "2019.05.06.csv\n",
      "2019.05.07.csv\n",
      "2019.05.08.csv\n",
      "2019.05.09.csv\n",
      "done /Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10split_time_cross_10min_sma_weightedmean.csv\n"
     ]
    }
   ],
   "source": [
    "#calculating results\n",
    "df_path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/'\n",
    "\n",
    "#create a list to hold all the data\n",
    "data_list=[]\n",
    "#creating a list for each category\n",
    "for i in range(20):\n",
    "    data_list.append([])\n",
    "    #creating a list for each quartile\n",
    "    for _ in range(4):\n",
    "        data_list[i].append([])\n",
    "\n",
    "final_df=pd.DataFrame()    \n",
    "\n",
    "for i in range(len(df_list)): #for each 20 day rolling window\n",
    "    if i<19: #skip first 19 days\n",
    "        continue\n",
    "    print(name_list[i])\n",
    "\n",
    "    #get -19 day\n",
    "    sma=df_list[i-19][:,-2].copy() #column for SMA\n",
    "    time_cross=df_list[i-19][:,-1].copy()\n",
    "    \n",
    "    #get -18 to 0 day (19 days in total)\n",
    "    for k in range((i-18),i+1): #get 20 day moving averages\n",
    "        sma=np.concatenate((sma,df_list[k][:,-2].copy()))\n",
    "        time_cross=np.concatenate((time_cross,df_list[k][:,-1].copy()))\n",
    "        \n",
    "    cat_sma=categorise_10()\n",
    "    cat_sma.fit(sma) #calculate quartile thresholds for past 20 days\n",
    "    \n",
    "    #get categories for past 20 days\n",
    "    cat_sma_20=(cat_sma.return_quartile(sma))   \n",
    "\n",
    "    #get x,y for regression\n",
    "    x_today=df_list[i][:,-2].copy().astype(float) #column for SMA     \n",
    "    y_today=df_list[i][:,-3].copy().astype(float) #column for edge\n",
    "    time_cross_today=df_list[i][:,-1].copy() #column for time since last cross\n",
    "    \n",
    "    #removing all NA\n",
    "    isnum=(~np.isnan(x_today)) & (~np.isnan(y_today))\n",
    "    #get categories of today's sma  \n",
    "    cat_x_today=cat_sma.return_quartile(x_today)\n",
    "    \n",
    "    #for each category\n",
    "    for cat in range(1,21):\n",
    "        #check past 20 days quartiles and filter time_cross by category\n",
    "        time_cross_fit=time_cross[cat_sma_20==cat].copy()\n",
    "\n",
    "        #simple quartile categorisation\n",
    "        cat_time=categorise_simple()\n",
    "        cat_time.fit(time_cross_fit)\n",
    "    \n",
    "        #today's sma filter\n",
    "        sma_filter_today=(cat_x_today==cat)\n",
    "        #today's time categories\n",
    "        cat_time_today=cat_time.return_quartile(time_cross_today)\n",
    "\n",
    "        #for each quartile\n",
    "        for quartile in [1,2,3,4]:\n",
    "\n",
    "            filtered= (isnum & sma_filter_today) #filtering NA and sma quartile\n",
    "            filtered= filtered & (cat_time_today==quartile) #filtering volume\n",
    "            new_y=y_today[filtered].copy()\n",
    "\n",
    "            if (len(new_y)!=0):\n",
    "                data_list[(cat-1)][(quartile-1)].append(new_y)\n",
    "                \n",
    "reg_result={}                 \n",
    "for cat in range(20):\n",
    "    for quartile in range(4):\n",
    "        all_data=data_list[cat][quartile][0]\n",
    "        for i in range(1,(len(data_list[cat][quartile]))):\n",
    "            all_data=np.concatenate((all_data,data_list[cat][quartile][i]))\n",
    "        reg_result['category']=cat+1\n",
    "        reg_result['quartile']=quartile+1\n",
    "        reg_result['mean']=np.mean(all_data)\n",
    "        reg_result['std']=np.std(all_data)\n",
    "        reg_result['num obs']=len(all_data)\n",
    "        final_df=final_df.append(reg_result,ignore_index=True)  \n",
    "             \n",
    "temp=df_path+'result_10split_time_cross_10min_sma_weightedmean.csv'\n",
    "final_df.to_csv(temp)\n",
    "print('done',temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 minute MA\n",
      "mean\n",
      "[[-0.48699435 -0.30320703  0.11483776  0.27459406]\n",
      " [-0.34615033 -0.05184675 -0.05808005  0.03188106]\n",
      " [-0.33023893 -0.09738349 -0.09095732 -0.12857478]\n",
      " [-0.30314141 -0.16710325  0.0008073   0.01518897]\n",
      " [-0.29531727 -0.15115043 -0.05714864 -0.02204276]\n",
      " [-0.20876562 -0.16925553 -0.1614042  -0.05150922]\n",
      " [-0.19061335 -0.19983826 -0.07728973 -0.06647169]\n",
      " [-0.19316192 -0.34302362 -0.06267688 -0.07201276]\n",
      " [-0.12351581 -0.30422845 -0.08847168  0.00603849]\n",
      " [-0.15079889 -0.12471537  0.00690588  0.07314028]\n",
      " [ 0.13790434  0.11521073 -0.00331917 -0.25152772]\n",
      " [ 0.1753844   0.18684459 -0.00934665 -0.10565523]\n",
      " [ 0.24442808  0.26846452  0.07899375 -0.10652091]\n",
      " [ 0.21930117  0.24992793 -0.01359441 -0.07839962]\n",
      " [ 0.31617638  0.22934495 -0.03110108 -0.06995099]\n",
      " [ 0.28540802  0.17577396 -0.00927855  0.13907028]\n",
      " [ 0.36095868  0.05266408  0.09792786  0.17720306]\n",
      " [ 0.31454013  0.00303096  0.05078971  0.22246718]\n",
      " [ 0.38061537  0.13162273  0.00438581  0.25602784]\n",
      " [ 0.36785978  0.29457991  0.35223195  0.29632643]]\n",
      "std\n",
      "[[5.05686151 4.39399052 4.13724392 4.39073242]\n",
      " [3.73638358 3.11619747 3.29054441 3.55149785]\n",
      " [3.25140816 2.85295554 2.7974626  3.00688304]\n",
      " [2.99065531 2.643273   2.61374923 2.70609525]\n",
      " [2.84280324 2.41140878 2.47975112 2.53911302]\n",
      " [2.85074131 2.41723776 2.33839487 2.47072758]\n",
      " [2.83121899 2.58806536 2.316962   2.42878178]\n",
      " [2.75841817 2.57219944 2.22678995 2.31272299]\n",
      " [2.68763055 2.27089257 2.12219517 2.11093635]\n",
      " [2.62381195 2.34735354 2.22114013 2.26115536]\n",
      " [2.55084995 2.38664739 2.33357988 2.28310539]\n",
      " [2.61372905 2.40870457 2.18908299 2.41972078]\n",
      " [2.63538005 2.41848683 2.23436582 2.32981644]\n",
      " [2.83358964 2.5540137  2.18385175 2.41397692]\n",
      " [2.93627497 2.45506332 2.29812855 2.51096224]\n",
      " [3.0371344  2.65674433 2.40334797 2.65225645]\n",
      " [3.18143779 2.8130744  2.59179797 2.88156173]\n",
      " [3.25142366 2.69860267 2.72428832 3.02268691]\n",
      " [3.55983142 3.07454506 3.16385901 3.2812216 ]\n",
      " [4.87420531 4.16505753 4.64902811 4.35071883]]\n",
      "num obs\n",
      "[[35009. 35218. 35624. 35643.]\n",
      " [34923. 36680. 36420. 37662.]\n",
      " [35967. 37769. 38337. 38914.]\n",
      " [37181. 37900. 38838. 39989.]\n",
      " [37435. 38124. 39249. 40401.]\n",
      " [37920. 40177. 39989. 41337.]\n",
      " [37725. 39998. 41047. 41272.]\n",
      " [38105. 40779. 41983. 42486.]\n",
      " [38013. 41069. 42522. 44056.]\n",
      " [37422. 43916. 44851. 45358.]\n",
      " [33818. 45281. 45602. 45930.]\n",
      " [37254. 41391. 41661. 43226.]\n",
      " [37383. 40374. 40269. 41705.]\n",
      " [36556. 39262. 40232. 40934.]\n",
      " [37406. 38972. 40330. 40273.]\n",
      " [36923. 38404. 38832. 38699.]\n",
      " [35271. 37439. 37487. 38338.]\n",
      " [34664. 35953. 37818. 37480.]\n",
      " [33224. 35560. 35471. 37121.]\n",
      " [33088. 33934. 34768. 35674.]]\n",
      "3 minute MA\n",
      "mean\n",
      "[[-0.32765554  0.25916538  0.01831436  0.06404728]\n",
      " [-0.32116653 -0.0447627   0.01383278  0.16822789]\n",
      " [-0.22134471  0.00798996 -0.17845077  0.18261627]\n",
      " [-0.33313077 -0.05589483 -0.08834687  0.02927467]\n",
      " [-0.29037687 -0.23711401 -0.12934779 -0.19029101]\n",
      " [-0.40563567 -0.16622591 -0.13090179 -0.18444889]\n",
      " [-0.38701243 -0.26332952 -0.04909033 -0.06832437]\n",
      " [-0.30557897 -0.18772499 -0.13057293  0.0087365 ]\n",
      " [-0.16427196 -0.25203704 -0.03640485 -0.04057421]\n",
      " [-0.14053602 -0.15310011 -0.02248383  0.01602387]\n",
      " [ 0.08915221  0.07769931 -0.16753152 -0.29664028]\n",
      " [ 0.23246501  0.20177951  0.00190674 -0.14883365]\n",
      " [ 0.24598965  0.24736684  0.03500697 -0.05509408]\n",
      " [ 0.26031471  0.14209563 -0.02808084 -0.02367005]\n",
      " [ 0.29411208  0.14188665  0.0724044   0.02821874]\n",
      " [ 0.26067708  0.11735694  0.06815514  0.03125664]\n",
      " [ 0.39316371  0.09438353  0.244814    0.12238263]\n",
      " [ 0.19028164  0.25992561  0.20125156  0.03957571]\n",
      " [ 0.25272459  0.22030548  0.42864126  0.07454794]\n",
      " [ 0.40847381  0.19215921  0.23725651  0.23628819]]\n",
      "std\n",
      "[[5.21363492 4.37957187 4.35980894 4.35225653]\n",
      " [4.07838061 3.15009581 3.04258506 3.40028519]\n",
      " [3.48322252 2.7414343  2.75925675 3.17272049]\n",
      " [3.21275196 2.52699421 2.47921311 2.46549133]\n",
      " [2.86981981 2.52952869 2.32488533 2.43700329]\n",
      " [2.94530249 2.36619475 2.31854392 2.39110287]\n",
      " [2.82736838 2.51055707 2.18843084 2.30985168]\n",
      " [2.57576802 2.3760381  2.15865886 2.17534165]\n",
      " [2.69100393 2.30697794 2.1109598  2.06301068]\n",
      " [2.62354717 2.322608   2.24029564 2.09829044]\n",
      " [2.51449919 2.31854941 2.17118287 2.13419713]\n",
      " [2.66926615 2.43898573 2.3165642  2.19289714]\n",
      " [2.77969003 2.37520543 2.29454969 2.40161444]\n",
      " [2.83098998 2.51488128 2.23134425 2.34010973]\n",
      " [2.78261521 2.3805814  2.47360631 2.55030389]\n",
      " [3.09738799 2.56094337 2.40323987 2.59467333]\n",
      " [3.22370637 2.63833393 2.62163406 2.77084676]\n",
      " [3.3625342  3.03655852 2.74134589 2.94038229]\n",
      " [3.98759759 3.30411035 3.01979985 3.23557688]\n",
      " [4.77941062 3.79879682 4.41580459 4.94309534]]\n",
      "num obs\n",
      "[[36995. 36375. 36314. 34501.]\n",
      " [34556. 37351. 37241. 37046.]\n",
      " [35805. 36994. 39771. 37895.]\n",
      " [36827. 39341. 39946. 40702.]\n",
      " [36954. 40269. 40420. 42580.]\n",
      " [36506. 40133. 41554. 43546.]\n",
      " [38075. 40566. 42768. 44357.]\n",
      " [37452. 39356. 42093. 43797.]\n",
      " [38337. 40265. 42521. 44045.]\n",
      " [37406. 40866. 42969. 43434.]\n",
      " [34232. 42064. 43104. 44110.]\n",
      " [36734. 39249. 40653. 42095.]\n",
      " [37328. 38725. 41128. 42499.]\n",
      " [36883. 38837. 41790. 41599.]\n",
      " [36499. 39525. 40296. 40189.]\n",
      " [35564. 37979. 39410. 38884.]\n",
      " [35976. 37347. 39090. 37933.]\n",
      " [34041. 36998. 36040. 36690.]\n",
      " [34390. 35382. 35366. 35102.]\n",
      " [34479. 36630. 35533. 33013.]]\n",
      "5 minute MA\n",
      "mean\n",
      "[[-0.05477737  0.21742411 -0.09889841  0.37183773]\n",
      " [-0.30038544  0.08528535 -0.0088681   0.10463961]\n",
      " [-0.28167049  0.02190857 -0.10474021  0.08044683]\n",
      " [-0.19913658 -0.08489604 -0.02237419 -0.17529427]\n",
      " [-0.32774601 -0.25493583 -0.09852837 -0.17160629]\n",
      " [-0.23704401 -0.19959575 -0.10031099  0.00311152]\n",
      " [-0.2507108  -0.23700977 -0.16288324  0.0142609 ]\n",
      " [-0.19495908 -0.18972981 -0.02166776  0.01168623]\n",
      " [-0.24722785 -0.37720714 -0.08874286  0.07071333]\n",
      " [-0.14364177 -0.21953423 -0.10575152  0.10180729]\n",
      " [ 0.13137403  0.14524171  0.01603235 -0.30127096]\n",
      " [ 0.2952817   0.165096   -0.16096422 -0.14123023]\n",
      " [ 0.29211684  0.23459725 -0.06608743 -0.13638966]\n",
      " [ 0.4572097   0.1405876   0.01063781 -0.05486447]\n",
      " [ 0.31008601  0.15348305  0.17811812 -0.12028277]\n",
      " [ 0.34631405  0.18420139  0.17604357 -0.15748758]\n",
      " [ 0.38853064  0.27809577  0.15206772 -0.07315073]\n",
      " [ 0.27189237  0.37635327  0.08853078 -0.10536836]\n",
      " [ 0.28627971  0.28955108  0.05394672 -0.1612641 ]\n",
      " [ 0.48223405 -0.11594987  0.16054319  0.10091127]]\n",
      "std\n",
      "[[5.30357494 4.13340873 4.19195188 4.26922013]\n",
      " [4.03464531 3.23520328 2.82080491 3.5724917 ]\n",
      " [3.48582731 2.66002924 2.52430099 2.88770551]\n",
      " [3.47548712 2.7161018  2.38774409 2.73891822]\n",
      " [3.14786423 2.59581892 2.23109071 2.51604564]\n",
      " [2.77217254 2.5212253  2.34010034 2.31489491]\n",
      " [2.86138851 2.39336766 2.1850542  2.25081433]\n",
      " [2.73037589 2.41631104 2.05430443 2.21242973]\n",
      " [2.64945659 2.45083534 2.05091442 2.13168572]\n",
      " [2.69843228 2.31554283 2.06577082 2.11002007]\n",
      " [2.58431291 2.31093758 2.31881389 2.25537818]\n",
      " [2.85292609 2.39112918 2.23488328 2.07503686]\n",
      " [2.85946661 2.41294011 2.11055347 2.25497972]\n",
      " [2.86799076 2.46497099 2.28850702 2.22632889]\n",
      " [3.07179101 2.55348917 2.49982648 2.30804814]\n",
      " [3.22106222 2.58766458 2.45032354 2.41288576]\n",
      " [3.50413592 2.65971438 2.48037763 2.69985482]\n",
      " [3.60991731 2.94353847 2.86192503 2.93287208]\n",
      " [3.99367799 2.97554998 3.03126264 3.06279717]\n",
      " [4.9930345  3.55430058 4.65057608 4.559182  ]]\n",
      "num obs\n",
      "[[37527. 35449. 35445. 35126.]\n",
      " [35870. 37279. 37347. 39240.]\n",
      " [36502. 38222. 39535. 39085.]\n",
      " [36283. 39404. 41218. 41678.]\n",
      " [37706. 39670. 41933. 42619.]\n",
      " [38490. 40869. 40823. 43371.]\n",
      " [37220. 40451. 42931. 43636.]\n",
      " [38109. 41244. 43564. 43095.]\n",
      " [38045. 40441. 44384. 43594.]\n",
      " [38310. 40901. 42596. 43537.]\n",
      " [34437. 40763. 41054. 43176.]\n",
      " [36859. 38658. 40369. 42362.]\n",
      " [36648. 40210. 40518. 40191.]\n",
      " [36601. 39524. 41346. 39118.]\n",
      " [36652. 39390. 40724. 38975.]\n",
      " [35063. 39320. 38603. 38648.]\n",
      " [34721. 36868. 36898. 38593.]\n",
      " [33206. 35458. 37098. 36472.]\n",
      " [34999. 35768. 35872. 35070.]\n",
      " [35897. 36120. 35011. 31306.]]\n",
      "10 minute MA\n",
      "mean\n",
      "[[ 0.25321338 -0.31249     0.33378435  0.12908077]\n",
      " [ 0.03350713  0.02939296  0.08824267 -0.07291604]\n",
      " [-0.35129485 -0.00387973 -0.24521886  0.02054967]\n",
      " [-0.29768979 -0.07950534 -0.10525246 -0.03192532]\n",
      " [-0.09015666 -0.11239192  0.05700781  0.12301278]\n",
      " [-0.27709134 -0.10357422 -0.07265435 -0.07271869]\n",
      " [-0.23335052 -0.07763511 -0.21276952 -0.09521948]\n",
      " [-0.20459026 -0.14076447 -0.12088656 -0.01259959]\n",
      " [-0.11677029 -0.06985055  0.04679099  0.2299248 ]\n",
      " [-0.10860746 -0.15462137  0.04588265  0.1968343 ]\n",
      " [ 0.20260734  0.1581174  -0.05636584 -0.29774527]\n",
      " [ 0.31294987  0.13865757 -0.05996166 -0.30210587]\n",
      " [ 0.3956883   0.12031573  0.07414313 -0.13832434]\n",
      " [ 0.29165948  0.19052538  0.16917128 -0.09150649]\n",
      " [ 0.39062415  0.29563542 -0.01473621 -0.06256179]\n",
      " [ 0.40226162  0.21622854 -0.0708691  -0.02638798]\n",
      " [ 0.27245264  0.20022929 -0.12916147 -0.21541626]\n",
      " [ 0.13685754  0.00309795 -0.23413058  0.02585821]\n",
      " [ 0.43436996  0.04172519 -0.07279702 -0.05695488]\n",
      " [ 0.15662074 -0.10248905  0.12818091 -0.31321535]]\n",
      "std\n",
      "[[4.92703742 4.10820978 4.38761933 4.20477328]\n",
      " [4.11151338 3.2410467  2.77578877 3.00233672]\n",
      " [3.96299527 2.60939501 2.6805012  2.80408518]\n",
      " [3.76726978 2.48919022 2.56100663 2.67101063]\n",
      " [3.19312758 2.37942731 2.34602562 2.50503866]\n",
      " [3.24025559 2.43057344 2.03960675 2.3362063 ]\n",
      " [2.84463036 2.35762721 2.14430816 2.38109479]\n",
      " [3.00681937 2.30957295 2.11530249 2.18762041]\n",
      " [2.83699218 2.33105077 2.0448171  2.11236508]\n",
      " [2.67549008 2.24295513 2.10981325 2.09516627]\n",
      " [2.68165362 2.49896462 2.28480982 2.08264831]\n",
      " [2.88281954 2.42809952 2.14911096 2.19220833]\n",
      " [2.87978146 2.27361427 2.09112542 2.27049771]\n",
      " [2.98847769 2.41307698 2.3451548  2.34836505]\n",
      " [3.40416133 2.6341362  2.4972629  2.31591526]\n",
      " [3.45705714 2.63049396 2.38795357 2.30423595]\n",
      " [3.59535502 2.58099582 2.46960474 2.59469277]\n",
      " [3.49592194 2.86425592 2.53917604 2.94126011]\n",
      " [3.92226707 3.1444612  3.15570972 3.4400554 ]\n",
      " [4.59412186 4.19728134 3.96965171 4.41972496]]\n",
      "num obs\n",
      "[[35959. 33997. 34077. 36075.]\n",
      " [36848. 37885. 38013. 39182.]\n",
      " [37640. 38240. 41135. 38035.]\n",
      " [37161. 40467. 40029. 41966.]\n",
      " [37604. 40612. 43694. 42431.]\n",
      " [37529. 39107. 40750. 43025.]\n",
      " [37001. 41126. 41629. 43205.]\n",
      " [37292. 41326. 42684. 43874.]\n",
      " [38525. 40490. 42178. 42954.]\n",
      " [39106. 41683. 44147. 45854.]\n",
      " [36060. 40963. 42749. 41834.]\n",
      " [36923. 40022. 41717. 40146.]\n",
      " [37573. 39595. 41465. 38845.]\n",
      " [35166. 38396. 40227. 38674.]\n",
      " [35907. 38617. 40663. 37926.]\n",
      " [36417. 38034. 38901. 37766.]\n",
      " [36126. 38402. 39117. 35124.]\n",
      " [36600. 36224. 36998. 33489.]\n",
      " [36911. 37363. 35860. 33160.]\n",
      " [36625. 33540. 35023. 31632.]]\n"
     ]
    }
   ],
   "source": [
    "for time in [1,3,5,10]:\n",
    "    print(time,'minute MA')\n",
    "    data=pd.read_csv('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10split_time_cross_'+str(time)+'min_sma_weightedmean.csv')\n",
    "    mean=np.reshape(data.loc[:,'mean'].values,(20,4))\n",
    "    std=np.reshape(data.loc[:,'std'].values,(20,4))\n",
    "    num=np.reshape(data.loc[:,'num obs'].values,(20,4))\n",
    "    print('mean')\n",
    "    print(mean)\n",
    "    print('std')\n",
    "    print(std)\n",
    "    print('num obs')\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5929757219855674\n"
     ]
    }
   ],
   "source": [
    "test=pd.read_csv('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/2019.01.02.csv')\n",
    "time_index=np.where(test.columns.values==\"Time\")[0][0]\n",
    "start=timer()\n",
    "process(test,time_index=time_index)\n",
    "print(timer()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
