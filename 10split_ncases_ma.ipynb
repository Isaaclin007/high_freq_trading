{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from datetime import datetime,timedelta\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA'\n",
    "os.chdir('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA')\n",
    "file_list=os.listdir(path)\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '2019.01.02.csv',\n",
       " '2019.01.03.csv',\n",
       " '2019.01.04.csv',\n",
       " '2019.01.07.csv',\n",
       " '2019.01.08.csv',\n",
       " '2019.01.09.csv',\n",
       " '2019.01.10.csv',\n",
       " '2019.01.11.csv',\n",
       " '2019.01.14.csv',\n",
       " '2019.01.15.csv',\n",
       " '2019.01.16.csv',\n",
       " '2019.01.17.csv',\n",
       " '2019.01.18.csv',\n",
       " '2019.01.21.csv',\n",
       " '2019.01.22.csv',\n",
       " '2019.01.23.csv',\n",
       " '2019.01.24.csv',\n",
       " '2019.01.25.csv',\n",
       " '2019.01.28.csv',\n",
       " '2019.01.29.csv',\n",
       " '2019.01.30.csv',\n",
       " '2019.01.31.csv',\n",
       " '2019.02.01.csv',\n",
       " '2019.02.11.csv',\n",
       " '2019.02.12.csv',\n",
       " '2019.02.13.csv',\n",
       " '2019.02.14.csv',\n",
       " '2019.02.15.csv',\n",
       " '2019.02.18.csv',\n",
       " '2019.02.19.csv',\n",
       " '2019.02.20.csv',\n",
       " '2019.02.21.csv',\n",
       " '2019.02.22.csv',\n",
       " '2019.02.25.csv',\n",
       " '2019.02.26.csv',\n",
       " '2019.02.27.csv',\n",
       " '2019.02.28.csv',\n",
       " '2019.03.01.csv',\n",
       " '2019.03.04.csv',\n",
       " '2019.03.05.csv',\n",
       " '2019.03.06.csv',\n",
       " '2019.03.07.csv',\n",
       " '2019.03.08.csv',\n",
       " '2019.03.11.csv',\n",
       " '2019.03.12.csv',\n",
       " '2019.03.13.csv',\n",
       " '2019.03.14.csv',\n",
       " '2019.03.15.csv',\n",
       " '2019.03.18.csv',\n",
       " '2019.03.19.csv',\n",
       " '2019.03.20.csv',\n",
       " '2019.03.21.csv',\n",
       " '2019.03.22.csv',\n",
       " '2019.03.25.csv',\n",
       " '2019.03.26.csv',\n",
       " '2019.03.27.csv',\n",
       " '2019.03.28.csv',\n",
       " '2019.03.29.csv',\n",
       " '2019.04.01.csv',\n",
       " '2019.04.02.csv',\n",
       " '2019.04.03.csv',\n",
       " '2019.04.04.csv',\n",
       " '2019.04.08.csv',\n",
       " '2019.04.09.csv',\n",
       " '2019.04.10.csv',\n",
       " '2019.04.11.csv',\n",
       " '2019.04.12.csv',\n",
       " '2019.04.15.csv',\n",
       " '2019.04.16.csv',\n",
       " '2019.04.17.csv',\n",
       " '2019.04.18.csv',\n",
       " '2019.04.19.csv',\n",
       " '2019.04.22.csv',\n",
       " '2019.04.23.csv',\n",
       " '2019.04.24.csv',\n",
       " '2019.04.25.csv',\n",
       " '2019.04.26.csv',\n",
       " '2019.04.29.csv',\n",
       " '2019.04.30.csv',\n",
       " '2019.05.06.csv',\n",
       " '2019.05.07.csv',\n",
       " '2019.05.08.csv',\n",
       " '2019.05.09.csv',\n",
       " 'results']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class categorise():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(7)\n",
    "                else:\n",
    "                    temp.append(8)\n",
    "            if i<0:\n",
    "                if i>self.threshold[0][2]:\n",
    "                    temp.append(4)\n",
    "                elif i>self.threshold[0][1]:\n",
    "                    temp.append(3)\n",
    "                elif i>self.threshold[0][0]:\n",
    "                    temp.append(2)\n",
    "                else:\n",
    "                    temp.append(1)\n",
    "        return np.asarray(temp)\n",
    "    \n",
    "class categorise_simple():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        self.threshold.append(np.percentile(array,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                else:\n",
    "                    temp.append(4)\n",
    "        return np.asarray(temp)    \n",
    "    \n",
    "class categorise_10():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[10,20,30,40,50,60,70,80,90]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(11)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(12)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(13)\n",
    "                elif i<self.threshold[1][3]:\n",
    "                    temp.append(14)\n",
    "                elif i<self.threshold[1][4]:\n",
    "                    temp.append(15)\n",
    "                elif i<self.threshold[1][5]:\n",
    "                    temp.append(16)\n",
    "                elif i<self.threshold[1][6]:\n",
    "                    temp.append(17)\n",
    "                elif i<self.threshold[1][7]:\n",
    "                    temp.append(18)\n",
    "                elif i<self.threshold[1][8]:\n",
    "                    temp.append(19)                    \n",
    "                else:\n",
    "                    temp.append(20)\n",
    "            if i<0:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                elif i<self.threshold[0][3]:\n",
    "                    temp.append(4)\n",
    "                elif i<self.threshold[0][4]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[0][5]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[0][6]:\n",
    "                    temp.append(7)\n",
    "                elif i<self.threshold[0][7]:\n",
    "                    temp.append(8)\n",
    "                elif i<self.threshold[0][8]:\n",
    "                    temp.append(9)                    \n",
    "                else:\n",
    "                    temp.append(10)\n",
    "        return np.asarray(temp)    \n",
    "    \n",
    "class categorise_x(): #flexible number of categories\n",
    "    \n",
    "    def __init__(self,x):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[]\n",
    "        self.num=x\n",
    "        for i in range(1,x):\n",
    "            self.percentiles.append(i*100/x)        \n",
    "            \n",
    "    def fit(self,array):\n",
    "        \n",
    "        positive=array[array>0]\n",
    "        negative=array[array<=0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "        \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for num in array:\n",
    "            if num<0:\n",
    "                counter=0\n",
    "                for i in self.threshold[0]:\n",
    "                    if num>=i:\n",
    "                        counter+=1\n",
    "                    else:\n",
    "                        break\n",
    "                temp.append(counter+1)\n",
    "            else:\n",
    "                counter=0\n",
    "                for i in self.threshold[1]:\n",
    "                    if num>=i:\n",
    "                        counter+=1\n",
    "                    else:\n",
    "                        break\n",
    "                temp.append(counter+self.num+1)\n",
    "        return np.asarray(temp)\n",
    "    \n",
    "class cross():\n",
    "    def __init__(self):\n",
    "        self.time_last_cross=0\n",
    "        self.current_sign=True\n",
    "        self.last_time=datetime(1900, 1, 1, 8, 59)\n",
    "    def get_time(self,time,price):\n",
    "        if (time-self.last_time)>timedelta(minutes=1):\n",
    "            self.last_time=time\n",
    "            self.time_last_cross=time\n",
    "            return 0\n",
    "        self.last_time=time\n",
    "        if (price>0) and self.current_sign : #if price positive and current trend is also positive\n",
    "            return (time-self.time_last_cross).total_seconds()\n",
    "        elif (price<0) and (not self.current_sign): #if price negative and current trend is negative\n",
    "            return (time-self.time_last_cross).total_seconds()\n",
    "        else: #if price positive, trend negative or price negative, trend positive\n",
    "            self.time_last_cross=time\n",
    "            self.current_sign=(price>0)\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_smart_price(dataset):\n",
    "    data=dataset.copy()\n",
    "    \n",
    "    #to combat the limit up event, where price is set to 0. \n",
    "    rows=(data.loc[:,'BidPrice1']==0) #count rows of bid price equal 0\n",
    "    if (np.any(rows)): #if there is such a row\n",
    "        data.at[rows,'BidPrice1']=data.loc[rows,'AskPrice1'] #for that row, assign ask price to it\n",
    "    rows=(data.loc[:,'AskPrice1']==0) #do the same for ask price\n",
    "    if (np.any(rows)):\n",
    "        data.at[rows,'AskPrice1']=data.loc[rows,'BidPrice1'] \n",
    "        \n",
    "    data['smart_price']=data.loc[:,'BidPrice1']*data.loc[:,'AskVol1']+data.loc[:,'AskPrice1']*data.loc[:,'BidVol1']\n",
    "    data.at[:,'smart_price']=data.loc[:,'smart_price']/(data.loc[:,['BidVol1','AskVol1']].sum(axis=1))  \n",
    "    return data\n",
    "\n",
    "def calc_present_vol(dataset):\n",
    "    data=dataset.copy()\n",
    "    data['current_vol']=data.loc[:,'Volume'].diff().fillna(0)/2\n",
    "    return data\n",
    "\n",
    "def calc_future_price(dataset,time_ahead=30,time_index=44, price_col=-2):\n",
    "    data=dataset.copy()\n",
    "    future_price=[]\n",
    "    length=len(data)\n",
    "    for i in range(len(data)):\n",
    "        current_time=data[i,time_index]+timedelta(seconds=time_ahead)\n",
    "        \n",
    "        j=0 #could alternatively use 30 x 3 then search forward and backward\n",
    "        \n",
    "        #search forwards\n",
    "        while((i+j)<length and current_time>data[(i+j),time_index]):\n",
    "            j+=1\n",
    "        if (i+j)<length:\n",
    "            #if index is in the dataframe\n",
    "            future_price.append(data[(i+j),price_col]) \n",
    "        else:\n",
    "            #price ahead does not exist\n",
    "            future_price.append(np.nan) \n",
    "    future_price=np.asarray(future_price)\n",
    "    future_price=np.expand_dims(future_price,axis=1)\n",
    "    return np.concatenate((data,future_price),axis=1)\n",
    "\n",
    "def calc_edge(dataset,future_col,current_col):\n",
    "    data=dataset.copy()\n",
    "    temp=data[:,future_col]-data[:,current_col]\n",
    "    temp=np.expand_dims(temp,axis=1)\n",
    "    return np.concatenate((data,temp),axis=1)\n",
    "\n",
    "def set_index(dataset,time_index=44):\n",
    "    data=dataset.copy()\n",
    "    index=data[:,time_index]\n",
    "    new_index=[]\n",
    "    for j in range(len(index)):\n",
    "        i=str(index[j]*1000)\n",
    "        if len(i)==11:\n",
    "            i='0'+i\n",
    "        i=i[:-10]+':'+i[-10:]\n",
    "        i=i[:-8]+':'+i[-8:]\n",
    "        i=i[:-6]+':'+i[-6:]\n",
    "        new_index.append(datetime.strptime(i,\"%H:%M:%S:%f\"))\n",
    "    data[:,time_index]=new_index\n",
    "    return data\n",
    "\n",
    "def calc_sma_fast(dataset,price_col,duration=1,time_index=44): #faster way to calculate SMA, 0.05 seconds for 5000 rows\n",
    "    data=dataset.copy()\n",
    "    sma_values=[] \n",
    "    smart_sum=np.cumsum(data[:,price_col]) #smart price column is -4\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        #finding ending point\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        \n",
    "        #finding start point\n",
    "        j=220*duration#4x60=240\n",
    "        \n",
    "        if i-j>0:\n",
    "            if data[i-j,time_index]>last_time: \n",
    "                \n",
    "                #if starting point time is greater than ending point time\n",
    "                #search backward\n",
    "                while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "                    j+=1\n",
    "                    \n",
    "                #activate next line in order to debug and troubleshoot\n",
    "                #print('backward',i,j,data[i,time_index],data[i-j,time_index],last_time)\n",
    "                \n",
    "                sma=(smart_sum[i]-smart_sum[i-j-1])/(j+1)\n",
    "                sma_values.append(sma)                \n",
    "                \n",
    "            else: \n",
    "                \n",
    "                #search forward\n",
    "                while(data[i-j,time_index]<last_time):\n",
    "                    j-=1\n",
    "                    \n",
    "                #activate next line in order to debug and troubleshoot\n",
    "                #print('forward',i,j,data[i,time_index],data[i-j,time_index],last_time)\n",
    "                \n",
    "                if j!=0:\n",
    "                    sma=(smart_sum[i]-smart_sum[i-j-1])/(j+1)\n",
    "                    sma_values.append(sma)   \n",
    "                    \n",
    "                else:\n",
    "                    sma_values.append(data[i,price_col])\n",
    "                    \n",
    "        else: #starting point is at 0\n",
    "            \n",
    "            sma=smart_sum[i]/(i+1)\n",
    "            sma_values.append(sma)                       \n",
    "\n",
    "    sma_values=np.asarray(sma_values)\n",
    "    sma_values=data[:,price_col]-sma_values\n",
    "    sma_values=np.expand_dims(sma_values,axis=1)\n",
    "    return np.concatenate((data,sma_values),axis=1)  \n",
    "\n",
    "def calc_volatility_slow(dataset,price_col,duration=15,time_index=44): \n",
    "    data=dataset.copy()\n",
    "    diff=np.diff(dataset[:,price_col])\n",
    "    diff=np.insert(diff,0,0)\n",
    "    \n",
    "    volatility_values=[]\n",
    "    for i in range(len(data)):\n",
    "            \n",
    "        #finding ending point\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        \n",
    "        #finding start point\n",
    "        j=220*duration#4x60=240\n",
    "        \n",
    "        if i-j>0:\n",
    "            if data[i-j,time_index]>last_time: \n",
    "                #if starting point time is greater than ending point time\n",
    "                #search backward\n",
    "                while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "                    j+=1\n",
    "                vol=np.std(diff[i-j:i])\n",
    "                volatility_values.append(vol)                     \n",
    "            else: \n",
    "                #search forward\n",
    "                while(data[i-j,time_index]<last_time):\n",
    "                    j-=1\n",
    "                if j!=0:\n",
    "                    vol=np.std(diff[i-j:i])\n",
    "                    volatility_values.append(vol) \n",
    "                else:\n",
    "                    volatility_values.append(0)\n",
    "        else: #starting point is at 0\n",
    "            if i==0:\n",
    "                volatility_values.append(0)\n",
    "                continue\n",
    "            vol=np.std(diff[:i])\n",
    "            volatility_values.append(vol)   \n",
    "            \n",
    "    volatility_values=np.asarray(volatility_values)\n",
    "    volatility_values=np.expand_dims(volatility_values,axis=1)\n",
    "    return np.concatenate((data,volatility_values),axis=1)\n",
    "\n",
    "def calc_past_vol(dataset,vol_col,duration=1,time_index=44): #\n",
    "    data=dataset.copy()\n",
    "    vol_values=[] \n",
    "    vol_sum=np.cumsum(data[:,vol_col])\n",
    "    for i in range(len(data)):\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        j=220*duration#4x60=240\n",
    "        while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "            j+=1\n",
    "        if (i-j>=0):\n",
    "            vol=(vol_sum[i]-vol_sum[i-j])\n",
    "            vol_values.append(vol)\n",
    "        else:\n",
    "            vol=vol_sum[i]\n",
    "            vol_values.append(vol)\n",
    "    vol_values=np.asarray(vol_values)\n",
    "    vol_values=np.expand_dims(vol_values,axis=1)\n",
    "    return np.concatenate((data,vol_values),axis=1) \n",
    "\n",
    "def last_cross(dataset,price_col,time_index=44):\n",
    "    data=dataset.copy()\n",
    "    last_cross=cross()\n",
    "    timings=[]\n",
    "    for i in range(len(data)):\n",
    "        timings.append(last_cross.get_time(data[i,time_index],data[i,price_col]))\n",
    "    timings=np.asarray(timings)\n",
    "    timings=np.expand_dims(timings,axis=1)\n",
    "    return np.concatenate((data,timings),axis=1)\n",
    "\n",
    "def get_case(array):\n",
    "    current=1\n",
    "    previous=0\n",
    "    temp=[]\n",
    "    for i in array:\n",
    "        if i==current:\n",
    "            if i>previous:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        elif i>current:\n",
    "            previous=current\n",
    "            current=i\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            previous=current\n",
    "            current=i\n",
    "            temp.append(0)\n",
    "    return np.asarray(temp)\n",
    "\n",
    "\n",
    "def binaryToDecimal(binary): \n",
    "      \n",
    "    binary1 = binary \n",
    "    decimal, i, n = 0, 0, 0\n",
    "    while(binary != 0): \n",
    "        dec = binary % 10\n",
    "        decimal = decimal + dec * pow(2, i) \n",
    "        binary = binary//10\n",
    "        i += 1\n",
    "    return(decimal) \n",
    "    \n",
    "def get_case_n(array,n=2):\n",
    "    temp=[]\n",
    "    if n==1:\n",
    "        return(\"error\")\n",
    "    previous=np.zeros(n)\n",
    "    for i in array:\n",
    "        final=''\n",
    "        if i==int(previous[-1]):\n",
    "            before=10\n",
    "            for j in previous:\n",
    "                if j>before:\n",
    "                    final+='1'\n",
    "                else:\n",
    "                    final+='0'\n",
    "                before=int(j)\n",
    "        else:\n",
    "            before=10\n",
    "            for j in previous:\n",
    "                if j>before:\n",
    "                    final+='1'\n",
    "                else:\n",
    "                    final+='0'\n",
    "                before=int(j)\n",
    "            final=final[1:]\n",
    "            if i>before:\n",
    "                final+='1'\n",
    "            else:\n",
    "                final+='0'\n",
    "        \n",
    "            previous=np.delete(previous,0)\n",
    "            previous=np.insert(previous,(n-1),i)\n",
    "#        temp.append(final)            \n",
    "        temp.append(binaryToDecimal(int(final)))\n",
    "    return np.asarray(temp)    \n",
    "\n",
    "def process(dataset,sma_duration=1,vol_duration=1,time_index=44):\n",
    "    data=dataset[:]\n",
    "    data=calc_smart_price(data).values #new\n",
    "    data=set_index(data,time_index=time_index) #no change\n",
    "    data=calc_future_price(data,time_index=time_index,price_col=-1) #new\n",
    "    data=calc_edge(data,future_col=-1,current_col=-2) #new\n",
    "    data=calc_sma_fast(data,duration=sma_duration,time_index=time_index,price_col=-3) #new\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, 3, 1, 1, 1, 2, 4, 4, 4])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#demonstration of get_case_n function\n",
    "get_case_n(np.array([12,3,5,4,2,1,1,2,3,5,12]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.01.02.csv read\n",
      "2019.01.03.csv read\n",
      "2019.01.04.csv read\n",
      "2019.01.07.csv read\n",
      "2019.01.08.csv read\n",
      "2019.01.09.csv read\n",
      "2019.01.10.csv read\n",
      "2019.01.11.csv read\n",
      "2019.01.14.csv read\n",
      "2019.01.15.csv read\n",
      "2019.01.16.csv read\n",
      "2019.01.17.csv read\n",
      "2019.01.18.csv read\n",
      "2019.01.21.csv read\n",
      "2019.01.22.csv read\n",
      "2019.01.23.csv read\n",
      "2019.01.24.csv read\n",
      "2019.01.25.csv read\n",
      "2019.01.28.csv read\n",
      "2019.01.29.csv read\n",
      "2019.01.30.csv read\n",
      "2019.01.31.csv read\n",
      "2019.02.01.csv read\n",
      "2019.02.11.csv read\n",
      "2019.02.12.csv read\n",
      "2019.02.13.csv read\n",
      "2019.02.14.csv read\n",
      "2019.02.15.csv read\n",
      "2019.02.18.csv read\n",
      "2019.02.19.csv read\n",
      "2019.02.20.csv read\n",
      "2019.02.21.csv read\n",
      "2019.02.22.csv read\n",
      "2019.02.25.csv read\n",
      "2019.02.26.csv read\n",
      "2019.02.27.csv read\n",
      "2019.02.28.csv read\n",
      "2019.03.01.csv read\n",
      "2019.03.04.csv read\n",
      "2019.03.05.csv read\n",
      "2019.03.06.csv read\n",
      "2019.03.07.csv read\n",
      "2019.03.08.csv read\n",
      "2019.03.11.csv read\n",
      "2019.03.12.csv read\n",
      "2019.03.13.csv read\n",
      "2019.03.14.csv read\n",
      "2019.03.15.csv read\n",
      "2019.03.18.csv read\n",
      "2019.03.19.csv read\n",
      "2019.03.20.csv read\n",
      "2019.03.21.csv read\n",
      "2019.03.22.csv read\n",
      "2019.03.25.csv read\n",
      "2019.03.26.csv read\n",
      "2019.03.27.csv read\n",
      "2019.03.28.csv read\n",
      "2019.03.29.csv read\n",
      "2019.04.01.csv read\n"
     ]
    }
   ],
   "source": [
    "#processing raw data to get technicals\n",
    "df_list=[]\n",
    "name_list=[]\n",
    "ma_time=5\n",
    "path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/'\n",
    "for file in file_list: #read all files and add them to file_list\n",
    "    if file[-3:]=='csv': #check if file is a CSV\n",
    "        name_list.append(file)\n",
    "        df_list.append(process(pd.read_csv(path+file),sma_duration=ma_time))\n",
    "        print(file,'read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating results\n",
    "df_path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/'\n",
    "\n",
    "n=2\n",
    "\n",
    "#create a list to hold all the data\n",
    "data_list=[]\n",
    "#creating a list for each category\n",
    "for i in range(20):\n",
    "    data_list.append([])\n",
    "    #creating a list for each quartile\n",
    "    for _ in range((2**n)):\n",
    "        data_list[i].append([])\n",
    "        \n",
    "for i in range(len(df_list)): #for each 20 day rolling window\n",
    "    if i<19: #skip first 19 days\n",
    "        continue\n",
    "    print(name_list[i])\n",
    "\n",
    "    #get -19 day\n",
    "    sma=df_list[i-19][:,-1].copy() #column for SMA\n",
    "    \n",
    "    #get -18 to 0 day (19 days in total)\n",
    "    for k in range((i-18),i+1): #get 20 day moving averages\n",
    "        sma=np.concatenate((sma,df_list[k][:,-1].copy()))\n",
    "        \n",
    "    cat_sma=categorise_10()\n",
    "    cat_sma.fit(sma) #calculate quartile thresholds for past 20 days\n",
    "\n",
    "    #get x,y for regression\n",
    "    x_today=df_list[i][:,-1].copy().astype(float) #column for SMA     \n",
    "    y_today=df_list[i][:,-2].copy().astype(float) #column for edge\n",
    "    \n",
    "    #removing all NA\n",
    "    isnum=(~np.isnan(x_today)) & (~np.isnan(y_today))\n",
    "    x_today=x_today[isnum]\n",
    "    y_today=y_today[isnum]    \n",
    "    #get categories of today's sma  \n",
    "    cat_x_today=cat_sma.return_quartile(x_today)\n",
    "    change=get_case_n(cat_x_today,n)\n",
    "    \n",
    "    #for each category\n",
    "    for cat in range(1,21):\n",
    "    \n",
    "        #today's sma filter\n",
    "        sma_filter_today=(cat_x_today==cat)\n",
    "\n",
    "        #for each case\n",
    "        for case in range(2**n):\n",
    "                \n",
    "            filtered= sma_filter_today & (change==case) #filtering by SMA and case\n",
    "            new_y=y_today[filtered].copy()\n",
    "\n",
    "            if (len(new_y)!=0):\n",
    "                #add today's data into the list by category and case\n",
    "                data_list[(cat-1)][case].append(new_y) \n",
    "final_df=pd.DataFrame()                 \n",
    "for cat in range(20):\n",
    "    for case in range(2**n):\n",
    "        reg_result={}\n",
    "        if len(data_list[cat][case])==0:\n",
    "            reg_result['category']=cat+1\n",
    "            reg_result['case']=case+1\n",
    "            reg_result['mean']=np.nan\n",
    "            reg_result['std']=np.nan\n",
    "            reg_result['num obs']=0\n",
    "            final_df=final_df.append(reg_result,ignore_index=True)             \n",
    "            continue\n",
    "            \n",
    "        #getting all the data needed to calculate mean and std\n",
    "        all_data=data_list[cat][case][0].copy()\n",
    "        for i in range(1,(len(data_list[cat][case]))):\n",
    "            all_data=np.concatenate((all_data,data_list[cat][case][i].copy()))\n",
    "\n",
    "        #adding results to output\n",
    "        reg_result['category']=cat+1\n",
    "        reg_result['case']=case+1\n",
    "        reg_result['mean']=np.mean(all_data)\n",
    "        reg_result['std']=np.std(all_data)\n",
    "        reg_result['num obs']=len(all_data)\n",
    "        final_df=final_df.append(reg_result,ignore_index=True) \n",
    "             \n",
    "temp=df_path+'result_10split_'+str(2**n)+'cases_'+str(ma_time)+'min_sma_weightedmean.csv'\n",
    "final_df.to_csv(temp)\n",
    "print('done',temp)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 1\n",
      "01 2\n",
      "10 3\n",
      "11 4\n"
     ]
    }
   ],
   "source": [
    "#interpretation of case results\n",
    "for x in ['0','1']:\n",
    "    for y in ['0','1']:\n",
    "        print(x+y,binaryToDecimal(int(x+y))+1)\n",
    "# 0 indicates decrease, 1 indicates increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 minute MA\n",
      "mean\n",
      "[[-0.10123765         nan -0.22224872         nan]\n",
      " [-0.21845741  0.08265356 -0.34498651         nan]\n",
      " [-0.27631761 -0.03164807 -0.33938919  0.03531408]\n",
      " [-0.20701956 -0.02084277 -0.16618014  0.13997762]\n",
      " [-0.30108895  0.01080844 -0.32577298  0.18572127]\n",
      " [-0.29864848 -0.0557268  -0.0973267   0.16684549]\n",
      " [-0.26975039 -0.04590963 -0.13803736  0.16018784]\n",
      " [-0.36018879 -0.03437015 -0.19268968  0.17345851]\n",
      " [-0.28373105 -0.02128981 -0.09507237  0.20451147]\n",
      " [-0.32085268  0.05248896 -0.14408516  0.19682824]\n",
      " [-0.2294909   0.16387443 -0.18530666  0.26140565]\n",
      " [-0.22123366  0.09640732 -0.08697581  0.26075438]\n",
      " [-0.21236527  0.24242495 -0.02913809  0.30804359]\n",
      " [-0.19267353  0.21498476 -0.05540559  0.27182402]\n",
      " [-0.14719781  0.16353381 -0.00784121  0.27025168]\n",
      " [-0.09709343  0.40686389  0.04342834  0.25684396]\n",
      " [-0.12037499  0.34109759  0.05604844  0.28712703]\n",
      " [-0.10929727  0.31791287  0.04905949  0.23291513]\n",
      " [        nan  0.4190952  -0.0443465   0.33643283]\n",
      " [        nan  0.34712617         nan  0.32783911]]\n",
      "std\n",
      "[[4.47415727        nan 6.01706763        nan]\n",
      " [3.40351699 3.43501664 3.93636799        nan]\n",
      " [2.92129525 2.98933367 3.32358354 3.81959004]\n",
      " [2.71422445 2.71692153 2.83482053 3.29684159]\n",
      " [2.48514237 2.5745313  2.82933752 2.93367301]\n",
      " [2.52703942 2.46243992 2.82699928 2.82298093]\n",
      " [2.4910518  2.52286333 2.67166984 2.80543246]\n",
      " [2.44799129 2.44124579 2.54141586 2.84517308]\n",
      " [2.22812905 2.26361272 2.50639762 2.6813264 ]\n",
      " [2.7679596  2.31743095 2.311468   2.75083896]\n",
      " [2.81721299 2.39924688 2.3213995  2.63421301]\n",
      " [2.74218338 2.48580809 2.3405625  2.43732125]\n",
      " [2.77270856 2.58709899 2.38300892 2.36594499]\n",
      " [2.86207933 2.7222246  2.48961816 2.42341997]\n",
      " [2.8826279  2.76427337 2.54904389 2.48958642]\n",
      " [2.92261143 2.89142736 2.66505869 2.68195162]\n",
      " [3.46503493 2.99516924 2.87804883 2.81426774]\n",
      " [3.40566572 3.17421921 2.93249821 2.89612252]\n",
      " [       nan 3.50445904 3.3908879  3.17164178]\n",
      " [       nan 4.83309195        nan 4.51722272]]\n",
      "num obs\n",
      "[[138338.      0.   3064.      0.]\n",
      " [ 84202.  57233.   4115.      0.]\n",
      " [ 72648.  71316.   4967.   1982.]\n",
      " [ 67519.  76342.   6675.   3231.]\n",
      " [ 63617.  78941.   8680.   4050.]\n",
      " [ 63454.  81318.   9694.   4763.]\n",
      " [ 61878.  81255.  11648.   5315.]\n",
      " [ 62001.  82398.  13126.   5725.]\n",
      " [ 63078.  79405.  17421.   5676.]\n",
      " [  5563.  80775.  79511.   5559.]\n",
      " [  5615.  78600.  81095.   5607.]\n",
      " [  5547.  16457.  79756.  61847.]\n",
      " [  5515.  12506.  79031.  62695.]\n",
      " [  5185.  10753.  80269.  60750.]\n",
      " [  4774.   9457.  80518.  62428.]\n",
      " [  3914.   8894.  77455.  62676.]\n",
      " [  3059.   6412.  73318.  65662.]\n",
      " [  1834.   5162.  67673.  71392.]\n",
      " [     0.   4093.  54322.  82950.]\n",
      " [     0.   3212.      0. 134399.]]\n",
      "3 minute MA\n",
      "mean\n",
      "[[-0.01637774         nan  0.74385206         nan]\n",
      " [-0.06218306  0.00598126 -0.30611649         nan]\n",
      " [-0.14738036  0.08216374 -0.39672629  0.05605877]\n",
      " [-0.25628502  0.0759737  -0.25278494  0.01608621]\n",
      " [-0.33999266 -0.08005362 -0.25261633  0.12911011]\n",
      " [-0.32426184 -0.10324952 -0.36672929  0.08548193]\n",
      " [-0.34492242 -0.01380879 -0.40617801  0.13337594]\n",
      " [-0.31085516  0.00988186 -0.19556067  0.12050769]\n",
      " [-0.19587203 -0.04812732 -0.22674875  0.12455955]\n",
      " [-0.24753661  0.02990635 -0.16980727  0.14324406]\n",
      " [-0.21190162  0.06042124 -0.23313427  0.15617693]\n",
      " [-0.13456414  0.20732107 -0.07225534  0.21165738]\n",
      " [-0.18369753  0.26532778 -0.02516604  0.24153343]\n",
      " [-0.0678186   0.23375358 -0.04317089  0.20406434]\n",
      " [-0.15494677  0.23942438  0.02187688  0.2411223 ]\n",
      " [-0.2213369   0.49863933 -0.06771464  0.27536496]\n",
      " [-0.09942824  0.27517893  0.01284366  0.38872764]\n",
      " [ 0.25023777  0.40790416  0.12953287  0.20670461]\n",
      " [        nan  0.63489222  0.19681126  0.26621911]\n",
      " [        nan  0.15997856         nan  0.258404  ]]\n",
      "std\n",
      "[[4.60765271        nan 4.84894155        nan]\n",
      " [3.46983198 3.3108411  4.1306478         nan]\n",
      " [3.07166348 2.97891122 3.52479415 3.67186915]\n",
      " [2.60668976 2.67479559 3.28644275 3.36395652]\n",
      " [2.54676761 2.49965842 2.85197371 3.02799507]\n",
      " [2.49670516 2.4422219  3.04562759 2.80386485]\n",
      " [2.41557081 2.40166692 3.00564937 2.70971647]\n",
      " [2.31817941 2.24517964 2.55878888 2.70335826]\n",
      " [2.2471347  2.18470318 2.8219475  2.58085522]\n",
      " [2.85391522 2.24764458 2.31947744 2.6488843 ]\n",
      " [2.9073241  2.27863915 2.2400356  2.88581282]\n",
      " [2.78704629 2.40442034 2.33506109 2.46258452]\n",
      " [2.84209074 2.63343166 2.49616123 2.36640473]\n",
      " [2.99583248 2.67159245 2.43531815 2.48561325]\n",
      " [3.05910679 2.7418461  2.52132484 2.53354324]\n",
      " [3.18941899 3.01278635 2.63961605 2.65041252]\n",
      " [3.0461299  3.29609993 2.72435508 2.85964447]\n",
      " [3.77115162 3.54195959 3.04565932 2.98337375]\n",
      " [       nan 4.3094129  3.25885713 3.48001019]\n",
      " [       nan 4.65229154        nan 4.50184447]]\n",
      "num obs\n",
      "[[141666.      0.   2378.      0.]\n",
      " [ 85029.  58431.   2577.      0.]\n",
      " [ 82163.  64050.   3063.   1007.]\n",
      " [ 81901.  69679.   3433.   1642.]\n",
      " [ 79958.  73881.   3983.   2169.]\n",
      " [ 76699.  76884.   5428.   2583.]\n",
      " [ 74934.  79135.   8561.   2945.]\n",
      " [ 71863.  75128.  12512.   3076.]\n",
      " [ 65496.  79040.  17234.   3258.]\n",
      " [  3331.  78817.  79038.   3341.]\n",
      " [  3286.  76908.  80118.   3465.]\n",
      " [  3142.  16274.  76902.  62570.]\n",
      " [  2869.  11994.  75476.  69467.]\n",
      " [  2657.   7669.  76096.  72959.]\n",
      " [  2301.   5051.  72490.  76658.]\n",
      " [  1898.   3727.  70026.  76249.]\n",
      " [  1516.   3055.  68776.  77040.]\n",
      " [   892.   2788.  64385.  75993.]\n",
      " [     0.   2299.  57673.  80098.]\n",
      " [     0.   3017.      0. 137218.]]\n"
     ]
    }
   ],
   "source": [
    "for time in [1,3,5,10]:\n",
    "    try:\n",
    "        data=pd.read_csv('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10split_4cases_'+str(time)+'min_sma_weightedmean.csv')\n",
    "    except:\n",
    "        continue\n",
    "    length=len(data)\n",
    "    print(time,'minute MA')\n",
    "    print('mean')\n",
    "    print(np.reshape(data.loc[:,'mean'].values,(20,4)))\n",
    "    print('std')\n",
    "    print(np.reshape(data.loc[:,'std'].values,(20,4)))\n",
    "    print('num obs')\n",
    "    print(np.reshape(data.loc[:,'num obs'].values,(20,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10split_4cases_3min_sma_weightedmean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
