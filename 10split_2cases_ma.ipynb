{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into 20 categories (10-90% percentile for positive and negative so 10x2) based on SMA 1 minute from past 20 days, \n",
    "#then within each SMA category, separate into quartiles based on cumulative volume in 1 minute\n",
    "#calculate the mean and std of the edge in each case\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from datetime import datetime,timedelta\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA'\n",
    "os.chdir('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA')\n",
    "file_list=os.listdir(path)\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '2019.01.02.csv',\n",
       " '2019.01.03.csv',\n",
       " '2019.01.04.csv',\n",
       " '2019.01.07.csv',\n",
       " '2019.01.08.csv',\n",
       " '2019.01.09.csv',\n",
       " '2019.01.10.csv',\n",
       " '2019.01.11.csv',\n",
       " '2019.01.14.csv',\n",
       " '2019.01.15.csv',\n",
       " '2019.01.16.csv',\n",
       " '2019.01.17.csv',\n",
       " '2019.01.18.csv',\n",
       " '2019.01.21.csv',\n",
       " '2019.01.22.csv',\n",
       " '2019.01.23.csv',\n",
       " '2019.01.24.csv',\n",
       " '2019.01.25.csv',\n",
       " '2019.01.28.csv',\n",
       " '2019.01.29.csv',\n",
       " '2019.01.30.csv',\n",
       " '2019.01.31.csv',\n",
       " '2019.02.01.csv',\n",
       " '2019.02.11.csv',\n",
       " '2019.02.12.csv',\n",
       " '2019.02.13.csv',\n",
       " '2019.02.14.csv',\n",
       " '2019.02.15.csv',\n",
       " '2019.02.18.csv',\n",
       " '2019.02.19.csv',\n",
       " '2019.02.20.csv',\n",
       " '2019.02.21.csv',\n",
       " '2019.02.22.csv',\n",
       " '2019.02.25.csv',\n",
       " '2019.02.26.csv',\n",
       " '2019.02.27.csv',\n",
       " '2019.02.28.csv',\n",
       " '2019.03.01.csv',\n",
       " '2019.03.04.csv',\n",
       " '2019.03.05.csv',\n",
       " '2019.03.06.csv',\n",
       " '2019.03.07.csv',\n",
       " '2019.03.08.csv',\n",
       " '2019.03.11.csv',\n",
       " '2019.03.12.csv',\n",
       " '2019.03.13.csv',\n",
       " '2019.03.14.csv',\n",
       " '2019.03.15.csv',\n",
       " '2019.03.18.csv',\n",
       " '2019.03.19.csv',\n",
       " '2019.03.20.csv',\n",
       " '2019.03.21.csv',\n",
       " '2019.03.22.csv',\n",
       " '2019.03.25.csv',\n",
       " '2019.03.26.csv',\n",
       " '2019.03.27.csv',\n",
       " '2019.03.28.csv',\n",
       " '2019.03.29.csv',\n",
       " '2019.04.01.csv',\n",
       " '2019.04.02.csv',\n",
       " '2019.04.03.csv',\n",
       " '2019.04.04.csv',\n",
       " '2019.04.08.csv',\n",
       " '2019.04.09.csv',\n",
       " '2019.04.10.csv',\n",
       " '2019.04.11.csv',\n",
       " '2019.04.12.csv',\n",
       " '2019.04.15.csv',\n",
       " '2019.04.16.csv',\n",
       " '2019.04.17.csv',\n",
       " '2019.04.18.csv',\n",
       " '2019.04.19.csv',\n",
       " '2019.04.22.csv',\n",
       " '2019.04.23.csv',\n",
       " '2019.04.24.csv',\n",
       " '2019.04.25.csv',\n",
       " '2019.04.26.csv',\n",
       " '2019.04.29.csv',\n",
       " '2019.04.30.csv',\n",
       " '2019.05.06.csv',\n",
       " '2019.05.07.csv',\n",
       " '2019.05.08.csv',\n",
       " '2019.05.09.csv',\n",
       " 'results']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class categorise():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(7)\n",
    "                else:\n",
    "                    temp.append(8)\n",
    "            if i<0:\n",
    "                if i>self.threshold[0][2]:\n",
    "                    temp.append(4)\n",
    "                elif i>self.threshold[0][1]:\n",
    "                    temp.append(3)\n",
    "                elif i>self.threshold[0][0]:\n",
    "                    temp.append(2)\n",
    "                else:\n",
    "                    temp.append(1)\n",
    "        return np.asarray(temp)\n",
    "    \n",
    "class categorise_simple():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        self.threshold.append(np.percentile(array,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                else:\n",
    "                    temp.append(4)\n",
    "        return np.asarray(temp)    \n",
    "    \n",
    "class categorise_10():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[10,20,30,40,50,60,70,80,90]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(11)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(12)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(13)\n",
    "                elif i<self.threshold[1][3]:\n",
    "                    temp.append(14)\n",
    "                elif i<self.threshold[1][4]:\n",
    "                    temp.append(15)\n",
    "                elif i<self.threshold[1][5]:\n",
    "                    temp.append(16)\n",
    "                elif i<self.threshold[1][6]:\n",
    "                    temp.append(17)\n",
    "                elif i<self.threshold[1][7]:\n",
    "                    temp.append(18)\n",
    "                elif i<self.threshold[1][8]:\n",
    "                    temp.append(19)                    \n",
    "                else:\n",
    "                    temp.append(20)\n",
    "            if i<0:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                elif i<self.threshold[0][3]:\n",
    "                    temp.append(4)\n",
    "                elif i<self.threshold[0][4]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[0][5]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[0][6]:\n",
    "                    temp.append(7)\n",
    "                elif i<self.threshold[0][7]:\n",
    "                    temp.append(8)\n",
    "                elif i<self.threshold[0][8]:\n",
    "                    temp.append(9)                    \n",
    "                else:\n",
    "                    temp.append(10)\n",
    "        return np.asarray(temp)    \n",
    "    \n",
    "class categorise_x(): #flexible number of categories\n",
    "    \n",
    "    def __init__(self,x):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[]\n",
    "        self.num=x\n",
    "        for i in range(1,x):\n",
    "            self.percentiles.append(i*100/x)        \n",
    "            \n",
    "    def fit(self,array):\n",
    "        \n",
    "        positive=array[array>0]\n",
    "        negative=array[array<=0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "        \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for num in array:\n",
    "            if num<0:\n",
    "                counter=0\n",
    "                for i in self.threshold[0]:\n",
    "                    if num>=i:\n",
    "                        counter+=1\n",
    "                    else:\n",
    "                        break\n",
    "                temp.append(counter+1)\n",
    "            else:\n",
    "                counter=0\n",
    "                for i in self.threshold[1]:\n",
    "                    if num>=i:\n",
    "                        counter+=1\n",
    "                    else:\n",
    "                        break\n",
    "                temp.append(counter+self.num+1)\n",
    "        return np.asarray(temp)\n",
    "    \n",
    "class cross():\n",
    "    def __init__(self):\n",
    "        self.time_last_cross=0\n",
    "        self.current_sign=True\n",
    "        self.last_time=datetime(1900, 1, 1, 8, 59)\n",
    "    def get_time(self,time,price):\n",
    "        if (time-self.last_time)>timedelta(minutes=1):\n",
    "            self.last_time=time\n",
    "            self.time_last_cross=time\n",
    "            return 0\n",
    "        self.last_time=time\n",
    "        if (price>0) and self.current_sign : #if price positive and current trend is also positive\n",
    "            return (time-self.time_last_cross).total_seconds()\n",
    "        elif (price<0) and (not self.current_sign): #if price negative and current trend is negative\n",
    "            return (time-self.time_last_cross).total_seconds()\n",
    "        else: #if price positive, trend negative or price negative, trend positive\n",
    "            self.time_last_cross=time\n",
    "            self.current_sign=(price>0)\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_smart_price(dataset):\n",
    "    data=dataset.copy()\n",
    "    \n",
    "    #to combat the limit up event, where price is set to 0. \n",
    "    rows=(data.loc[:,'BidPrice1']==0) #count rows of bid price equal 0\n",
    "    if (np.any(rows)): #if there is such a row\n",
    "        data.at[rows,'BidPrice1']=data.loc[rows,'AskPrice1'] #for that row, assign ask price to it\n",
    "    rows=(data.loc[:,'AskPrice1']==0) #do the same for ask price\n",
    "    if (np.any(rows)):\n",
    "        data.at[rows,'AskPrice1']=data.loc[rows,'BidPrice1'] \n",
    "        \n",
    "    data['smart_price']=data.loc[:,'BidPrice1']*data.loc[:,'AskVol1']+data.loc[:,'AskPrice1']*data.loc[:,'BidVol1']\n",
    "    data.at[:,'smart_price']=data.loc[:,'smart_price']/(data.loc[:,['BidVol1','AskVol1']].sum(axis=1))  \n",
    "    return data\n",
    "\n",
    "def calc_present_vol(dataset):\n",
    "    data=dataset.copy()\n",
    "    data['current_vol']=data.loc[:,'Volume'].diff().fillna(0)/2\n",
    "    return data\n",
    "\n",
    "def calc_future_price(dataset,time_ahead=30,time_index=44, price_col=-2):\n",
    "    data=dataset.copy()\n",
    "    future_price=[]\n",
    "    length=len(data)\n",
    "    for i in range(len(data)):\n",
    "        current_time=data[i,time_index]+timedelta(seconds=time_ahead)\n",
    "        \n",
    "        j=0 #could alternatively use 30 x 3 then search forward and backward\n",
    "        \n",
    "        #search forwards\n",
    "        while((i+j)<length and current_time>data[(i+j),time_index]):\n",
    "            j+=1\n",
    "        if (i+j)<length:\n",
    "            #if index is in the dataframe\n",
    "            future_price.append(data[(i+j),price_col]) \n",
    "        else:\n",
    "            #price ahead does not exist\n",
    "            future_price.append(np.nan) \n",
    "    future_price=np.asarray(future_price)\n",
    "    future_price=np.expand_dims(future_price,axis=1)\n",
    "    return np.concatenate((data,future_price),axis=1)\n",
    "\n",
    "def calc_edge(dataset,future_col,current_col):\n",
    "    data=dataset.copy()\n",
    "    temp=data[:,future_col]-data[:,current_col]\n",
    "    temp=np.expand_dims(temp,axis=1)\n",
    "    return np.concatenate((data,temp),axis=1)\n",
    "\n",
    "def set_index(dataset,time_index=44):\n",
    "    data=dataset.copy()\n",
    "    index=data[:,time_index]\n",
    "    new_index=[]\n",
    "    for j in range(len(index)):\n",
    "        i=str(index[j]*1000)\n",
    "        if len(i)==11:\n",
    "            i='0'+i\n",
    "        i=i[:-10]+':'+i[-10:]\n",
    "        i=i[:-8]+':'+i[-8:]\n",
    "        i=i[:-6]+':'+i[-6:]\n",
    "        new_index.append(datetime.strptime(i,\"%H:%M:%S:%f\"))\n",
    "    data[:,time_index]=new_index\n",
    "    return data\n",
    "\n",
    "def calc_sma_fast(dataset,price_col,duration=1,time_index=44): #faster way to calculate SMA, 0.05 seconds for 5000 rows\n",
    "    data=dataset.copy()\n",
    "    sma_values=[] \n",
    "    smart_sum=np.cumsum(data[:,price_col]) #smart price column is -4\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        #finding ending point\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        \n",
    "        #finding start point\n",
    "        j=220*duration#4x60=240\n",
    "        \n",
    "        if i-j>0:\n",
    "            if data[i-j,time_index]>last_time: \n",
    "                \n",
    "                #if starting point time is greater than ending point time\n",
    "                #search backward\n",
    "                while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "                    j+=1\n",
    "                    \n",
    "                #activate next line in order to debug and troubleshoot\n",
    "                #print('backward',i,j,data[i,time_index],data[i-j,time_index],last_time)\n",
    "                \n",
    "                sma=(smart_sum[i]-smart_sum[i-j])/(j)\n",
    "                sma_values.append(sma)                \n",
    "                \n",
    "            else: \n",
    "                \n",
    "                #search forward\n",
    "                while(data[i-j,time_index]<last_time):\n",
    "                    j-=1\n",
    "                    \n",
    "                #activate next line in order to debug and troubleshoot\n",
    "                #print('forward',i,j,data[i,time_index],data[i-j,time_index],last_time)\n",
    "                \n",
    "                if j!=0:\n",
    "                    sma=(smart_sum[i]-smart_sum[i-j])/(j)\n",
    "                    sma_values.append(sma)   \n",
    "                    \n",
    "                else:\n",
    "                    sma_values.append(data[i,price_col])\n",
    "                    \n",
    "        else: #starting point is at 0\n",
    "            \n",
    "            sma=smart_sum[i]/(i+1)\n",
    "            sma_values.append(sma)                       \n",
    "\n",
    "    sma_values=np.asarray(sma_values)\n",
    "    sma_values=data[:,price_col]-sma_values\n",
    "    sma_values=np.expand_dims(sma_values,axis=1)\n",
    "    return np.concatenate((data,sma_values),axis=1)  \n",
    "\n",
    "def calc_volatility_slow(dataset,price_col,duration=15,time_index=44): \n",
    "    data=dataset.copy()\n",
    "    diff=np.diff(dataset[:,price_col])\n",
    "    diff=np.insert(diff,0,0)\n",
    "    \n",
    "    volatility_values=[]\n",
    "    for i in range(len(data)):\n",
    "            \n",
    "        #finding ending point\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        \n",
    "        #finding start point\n",
    "        j=220*duration#4x60=240\n",
    "        \n",
    "        if i-j>0:\n",
    "            if data[i-j,time_index]>last_time: \n",
    "                #if starting point time is greater than ending point time\n",
    "                #search backward\n",
    "                while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "                    j+=1\n",
    "                vol=np.std(diff[i-j:i])\n",
    "                volatility_values.append(vol)                     \n",
    "            else: \n",
    "                #search forward\n",
    "                while(data[i-j,time_index]<last_time):\n",
    "                    j-=1\n",
    "                if j!=0:\n",
    "                    vol=np.std(diff[i-j:i])\n",
    "                    volatility_values.append(vol) \n",
    "                else:\n",
    "                    volatility_values.append(0)\n",
    "        else: #starting point is at 0\n",
    "            if i==0:\n",
    "                volatility_values.append(0)\n",
    "                continue\n",
    "            vol=np.std(diff[:i])\n",
    "            volatility_values.append(vol)   \n",
    "            \n",
    "    volatility_values=np.asarray(volatility_values)\n",
    "    volatility_values=np.expand_dims(volatility_values,axis=1)\n",
    "    return np.concatenate((data,volatility_values),axis=1)\n",
    "\n",
    "def calc_past_vol(dataset,vol_col,duration=1,time_index=44): #\n",
    "    data=dataset.copy()\n",
    "    vol_values=[] \n",
    "    vol_sum=np.cumsum(data[:,vol_col])\n",
    "    for i in range(len(data)):\n",
    "        last_time=data[i,time_index]-timedelta(minutes=duration)\n",
    "        j=220*duration#4x60=240\n",
    "        while(i-j>0 and data[i-j,time_index]>last_time):\n",
    "            j+=1\n",
    "        if (i-j>=0):\n",
    "            vol=(vol_sum[i]-vol_sum[i-j])\n",
    "            vol_values.append(vol)\n",
    "        else:\n",
    "            vol=vol_sum[i]\n",
    "            vol_values.append(vol)\n",
    "    vol_values=np.asarray(vol_values)\n",
    "    vol_values=np.expand_dims(vol_values,axis=1)\n",
    "    return np.concatenate((data,vol_values),axis=1) \n",
    "\n",
    "def last_cross(dataset,price_col,time_index=44):\n",
    "    data=dataset[:]\n",
    "    last_cross=cross()\n",
    "    timings=[]\n",
    "    for i in range(len(data)):\n",
    "        timings.append(last_cross.get_time(data[i,time_index],data[i,price_col]))\n",
    "    timings=np.asarray(timings)\n",
    "    timings=np.expand_dims(timings,axis=1)\n",
    "    return np.concatenate((data,timings),axis=1)\n",
    "\n",
    "def get_case(array):\n",
    "    current=1\n",
    "    previous=0\n",
    "    temp=[]\n",
    "    for i in array:\n",
    "        if i==current:\n",
    "            if i>previous:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        elif i>current:\n",
    "            previous=current\n",
    "            current=i\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            previous=current\n",
    "            current=i\n",
    "            temp.append(0)\n",
    "    return np.asarray(temp)\n",
    "\n",
    "def process(dataset,sma_duration=1,vol_duration=1,time_index=44):\n",
    "    data=dataset[:]\n",
    "    data=calc_smart_price(data).values #new\n",
    "    data=set_index(data,time_index=time_index) #no change\n",
    "    data=calc_future_price(data,time_index=time_index,price_col=-1) #new\n",
    "    data=calc_edge(data,future_col=-1,current_col=-2) #new\n",
    "    data=calc_sma_fast(data,duration=sma_duration,time_index=time_index,price_col=-3) #new\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#demonstration of get_change function\n",
    "x=np.array([1,2,3,4,4,3,2,1,1])\n",
    "get_case(x)\n",
    "#output is 1 if increase, 0 if decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.01.02.csv read\n",
      "2019.01.03.csv read\n",
      "2019.01.04.csv read\n",
      "2019.01.07.csv read\n",
      "2019.01.08.csv read\n",
      "2019.01.09.csv read\n",
      "2019.01.10.csv read\n",
      "2019.01.11.csv read\n",
      "2019.01.14.csv read\n",
      "2019.01.15.csv read\n",
      "2019.01.16.csv read\n",
      "2019.01.17.csv read\n",
      "2019.01.18.csv read\n",
      "2019.01.21.csv read\n",
      "2019.01.22.csv read\n",
      "2019.01.23.csv read\n",
      "2019.01.24.csv read\n",
      "2019.01.25.csv read\n",
      "2019.01.28.csv read\n",
      "2019.01.29.csv read\n",
      "2019.01.30.csv read\n",
      "2019.01.31.csv read\n",
      "2019.02.01.csv read\n",
      "2019.02.11.csv read\n",
      "2019.02.12.csv read\n",
      "2019.02.13.csv read\n",
      "2019.02.14.csv read\n",
      "2019.02.15.csv read\n",
      "2019.02.18.csv read\n",
      "2019.02.19.csv read\n",
      "2019.02.20.csv read\n",
      "2019.02.21.csv read\n",
      "2019.02.22.csv read\n",
      "2019.02.25.csv read\n",
      "2019.02.26.csv read\n",
      "2019.02.27.csv read\n",
      "2019.02.28.csv read\n",
      "2019.03.01.csv read\n",
      "2019.03.04.csv read\n",
      "2019.03.05.csv read\n",
      "2019.03.06.csv read\n",
      "2019.03.07.csv read\n",
      "2019.03.08.csv read\n",
      "2019.03.11.csv read\n",
      "2019.03.12.csv read\n",
      "2019.03.13.csv read\n",
      "2019.03.14.csv read\n",
      "2019.03.15.csv read\n",
      "2019.03.18.csv read\n",
      "2019.03.19.csv read\n",
      "2019.03.20.csv read\n",
      "2019.03.21.csv read\n",
      "2019.03.22.csv read\n",
      "2019.03.25.csv read\n",
      "2019.03.26.csv read\n",
      "2019.03.27.csv read\n",
      "2019.03.28.csv read\n",
      "2019.03.29.csv read\n",
      "2019.04.01.csv read\n",
      "2019.04.02.csv read\n",
      "2019.04.03.csv read\n",
      "2019.04.04.csv read\n",
      "2019.04.08.csv read\n",
      "2019.04.09.csv read\n",
      "2019.04.10.csv read\n",
      "2019.04.11.csv read\n",
      "2019.04.12.csv read\n",
      "2019.04.15.csv read\n",
      "2019.04.16.csv read\n",
      "2019.04.17.csv read\n",
      "2019.04.18.csv read\n",
      "2019.04.19.csv read\n",
      "2019.04.22.csv read\n",
      "2019.04.23.csv read\n",
      "2019.04.24.csv read\n",
      "2019.04.25.csv read\n",
      "2019.04.26.csv read\n",
      "2019.04.29.csv read\n",
      "2019.04.30.csv read\n",
      "2019.05.06.csv read\n",
      "2019.05.07.csv read\n",
      "2019.05.08.csv read\n",
      "2019.05.09.csv read\n"
     ]
    }
   ],
   "source": [
    "#processing raw data to get technicals\n",
    "df_list=[]\n",
    "name_list=[]\n",
    "path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/'\n",
    "for file in file_list: #read all files and add them to file_list\n",
    "    if file[-3:]=='csv': #check if file is a CSV\n",
    "        name_list.append(file)\n",
    "        df_list.append(process(pd.read_csv(path+file),sma_duration=10))\n",
    "        print(file,'read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.01.29.csv\n",
      "2019.01.30.csv\n",
      "2019.01.31.csv\n",
      "2019.02.01.csv\n",
      "2019.02.11.csv\n",
      "2019.02.12.csv\n",
      "2019.02.13.csv\n",
      "2019.02.14.csv\n",
      "2019.02.15.csv\n",
      "2019.02.18.csv\n",
      "2019.02.19.csv\n",
      "2019.02.20.csv\n",
      "2019.02.21.csv\n",
      "2019.02.22.csv\n",
      "2019.02.25.csv\n",
      "2019.02.26.csv\n",
      "2019.02.27.csv\n",
      "2019.02.28.csv\n",
      "2019.03.01.csv\n",
      "2019.03.04.csv\n",
      "2019.03.05.csv\n",
      "2019.03.06.csv\n",
      "2019.03.07.csv\n",
      "2019.03.08.csv\n",
      "2019.03.11.csv\n",
      "2019.03.12.csv\n",
      "2019.03.13.csv\n",
      "2019.03.14.csv\n",
      "2019.03.15.csv\n",
      "2019.03.18.csv\n",
      "2019.03.19.csv\n",
      "2019.03.20.csv\n",
      "2019.03.21.csv\n",
      "2019.03.22.csv\n",
      "2019.03.25.csv\n",
      "2019.03.26.csv\n",
      "2019.03.27.csv\n",
      "2019.03.28.csv\n",
      "2019.03.29.csv\n",
      "2019.04.01.csv\n",
      "2019.04.02.csv\n",
      "2019.04.03.csv\n",
      "2019.04.04.csv\n",
      "2019.04.08.csv\n",
      "2019.04.09.csv\n",
      "2019.04.10.csv\n",
      "2019.04.11.csv\n",
      "2019.04.12.csv\n",
      "2019.04.15.csv\n",
      "2019.04.16.csv\n",
      "2019.04.17.csv\n",
      "2019.04.18.csv\n",
      "2019.04.19.csv\n",
      "2019.04.22.csv\n",
      "2019.04.23.csv\n",
      "2019.04.24.csv\n",
      "2019.04.25.csv\n",
      "2019.04.26.csv\n",
      "2019.04.29.csv\n",
      "2019.04.30.csv\n",
      "2019.05.06.csv\n",
      "2019.05.07.csv\n",
      "2019.05.08.csv\n",
      "2019.05.09.csv\n",
      "done /Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10split_2cases_10min_sma_weightedmean.csv\n"
     ]
    }
   ],
   "source": [
    "#calculating results\n",
    "df_path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/'\n",
    "\n",
    "#create a list to hold all the data\n",
    "data_list=[]\n",
    "#creating a list for each category\n",
    "for i in range(20):\n",
    "    data_list.append([])\n",
    "    #creating a list for each quartile\n",
    "    for _ in range(2):\n",
    "        data_list[i].append([])\n",
    "\n",
    "final_df=pd.DataFrame()    \n",
    "current_cat=1\n",
    "prev_cat=0\n",
    "for i in range(len(df_list)): #for each 20 day rolling window\n",
    "    if i<19: #skip first 19 days\n",
    "        continue\n",
    "    print(name_list[i])\n",
    "\n",
    "    #get -19 day\n",
    "    sma=df_list[i-19][:,-1].copy() #column for SMA\n",
    "    \n",
    "    #get -18 to 0 day (19 days in total)\n",
    "    for k in range((i-18),i+1): #get 20 day moving averages\n",
    "        sma=np.concatenate((sma,df_list[k][:,-1].copy()))\n",
    "        \n",
    "    cat_sma=categorise_10()\n",
    "    cat_sma.fit(sma) #calculate quartile thresholds for past 20 days\n",
    "\n",
    "    #get x,y for regression\n",
    "    x_today=df_list[i][:,-1].copy().astype(float) #column for SMA     \n",
    "    y_today=df_list[i][:,-2].copy().astype(float) #column for edge\n",
    "    \n",
    "    #removing all NA\n",
    "    isnum=(~np.isnan(x_today)) & (~np.isnan(y_today))\n",
    "    x_today=x_today[isnum]\n",
    "    y_today=y_today[isnum]    \n",
    "    #get categories of today's sma  \n",
    "    cat_x_today=cat_sma.return_quartile(x_today)\n",
    "    change=get_case(cat_x_today)\n",
    "    \n",
    "    #for each category\n",
    "    for cat in range(1,21):\n",
    "    \n",
    "        #today's sma filter\n",
    "        sma_filter_today=(cat_x_today==cat)\n",
    "\n",
    "        #for each case\n",
    "        for case in [0,1]:\n",
    "            \n",
    "            #skip these cases, since they will never happen\n",
    "            if (cat==1 and case==1)or(cat==20 and case==0):\n",
    "                continue\n",
    "                \n",
    "            filtered= sma_filter_today & (change==case) #filtering by SMA and case\n",
    "            new_y=y_today[filtered].copy()\n",
    "\n",
    "            if (len(new_y)!=0):\n",
    "                #add today's data into the list by category and case\n",
    "                data_list[(cat-1)][case].append(new_y) \n",
    "            else:\n",
    "                print('empty',cat,case)\n",
    "            \n",
    "reg_result={}                 \n",
    "for cat in range(20):\n",
    "    for case in range(2):\n",
    "      \n",
    "        if (cat==0 and case==1)or(cat==19 and case==0):\n",
    "            reg_result['category']=cat+1\n",
    "            reg_result['case']=case\n",
    "            reg_result['mean']=np.nan\n",
    "            reg_result['std']=np.nan\n",
    "            reg_result['num obs']=0\n",
    "            final_df=final_df.append(reg_result,ignore_index=True)         \n",
    "            continue        \n",
    "        \n",
    "        #getting all the data needed to calculate mean and std\n",
    "        all_data=data_list[cat][case][0]\n",
    "        for i in range(1,(len(data_list[cat][case]))):\n",
    "            all_data=np.concatenate((all_data,data_list[cat][case][i]))\n",
    "\n",
    "        #adding results to output\n",
    "        reg_result['category']=cat+1\n",
    "        reg_result['case']=case\n",
    "        reg_result['mean']=np.mean(all_data)\n",
    "        reg_result['std']=np.std(all_data)\n",
    "        reg_result['num obs']=len(all_data)\n",
    "        final_df=final_df.append(reg_result,ignore_index=True)  \n",
    "             \n",
    "temp=df_path+'result_10split_2cases_10min_sma_weightedmean.csv'\n",
    "final_df.to_csv(temp)\n",
    "print('done',temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 minute MA\n",
      "mean\n",
      "[[-0.09787832         nan]\n",
      " [-0.21662444  0.07416362]\n",
      " [-0.29217182 -0.01900061]\n",
      " [-0.20780478 -0.01929507]\n",
      " [-0.29947893  0.02002042]\n",
      " [-0.26136434 -0.04857806]\n",
      " [-0.26068331 -0.02270244]\n",
      " [-0.32717786 -0.02708931]\n",
      " [-0.2467133  -0.00908337]\n",
      " [-0.15905431  0.07042991]\n",
      " [-0.18462317  0.16798136]\n",
      " [-0.09605914  0.22270936]\n",
      " [-0.0315617   0.2844388 ]\n",
      " [-0.05403393  0.26164371]\n",
      " [-0.01216744  0.24675375]\n",
      " [ 0.0273088   0.28158597]\n",
      " [ 0.0474226   0.29826449]\n",
      " [ 0.03170547  0.24894247]\n",
      " [-0.04085961  0.3365519 ]\n",
      " [        nan  0.32685262]]\n",
      "std\n",
      "[[4.51583945        nan]\n",
      " [3.42410321 3.43685808]\n",
      " [2.94070467 3.01475722]\n",
      " [2.72682368 2.75515477]\n",
      " [2.53345443 2.59827547]\n",
      " [2.57406879 2.47394811]\n",
      " [2.53543825 2.54376285]\n",
      " [2.45737201 2.47395832]\n",
      " [2.29831508 2.29557987]\n",
      " [2.36109223 2.35037814]\n",
      " [2.33719265 2.43932495]\n",
      " [2.37186491 2.44021752]\n",
      " [2.41745655 2.38813049]\n",
      " [2.52124569 2.46947565]\n",
      " [2.5694189  2.54011142]\n",
      " [2.66884754 2.71768119]\n",
      " [2.89429313 2.84278756]\n",
      " [2.94317056 2.91687542]\n",
      " [3.38892075 3.18740554]\n",
      " [       nan 4.50900384]]\n",
      "num obs\n",
      "[[141494.      0.]\n",
      " [ 88413.  57272.]\n",
      " [ 77524.  73463.]\n",
      " [ 74245.  79663.]\n",
      " [ 72171.  83038.]\n",
      " [ 73105.  86318.]\n",
      " [ 73395.  86647.]\n",
      " [ 75359.  87994.]\n",
      " [ 80717.  84943.]\n",
      " [ 85300.  86247.]\n",
      " [ 86408.  84343.]\n",
      " [ 85048.  78462.]\n",
      " [ 84589.  75125.]\n",
      " [ 85442.  71526.]\n",
      " [ 85352.  71630.]\n",
      " [ 81330.  71526.]\n",
      " [ 76286.  72225.]\n",
      " [ 69255.  76653.]\n",
      " [ 54483.  86876.]\n",
      " [     0. 137448.]]\n",
      "3 minute MA\n",
      "mean\n",
      "[[ 0.00125039         nan]\n",
      " [-0.07070008  0.00287438]\n",
      " [-0.15891235  0.08741522]\n",
      " [-0.25176804  0.06580367]\n",
      " [-0.3428751  -0.06255915]\n",
      " [-0.33542179 -0.09244054]\n",
      " [-0.34986679 -0.01519465]\n",
      " [-0.2949684   0.01326735]\n",
      " [-0.19922657 -0.04023989]\n",
      " [-0.17730208  0.03426439]\n",
      " [-0.22706712  0.06034398]\n",
      " [-0.07814773  0.21010577]\n",
      " [-0.0322417   0.25032382]\n",
      " [-0.04549953  0.204134  ]\n",
      " [ 0.02035024  0.23182417]\n",
      " [-0.06958833  0.28294627]\n",
      " [ 0.01367688  0.38469439]\n",
      " [ 0.11434176  0.21967257]\n",
      " [ 0.20126789  0.27383147]\n",
      " [        nan  0.26754802]]\n",
      "std\n",
      "[[4.60202321        nan]\n",
      " [3.4920459  3.3422879 ]\n",
      " [3.08698993 2.99769328]\n",
      " [2.64707279 2.71060491]\n",
      " [2.57169594 2.49680303]\n",
      " [2.54182605 2.46162036]\n",
      " [2.46974929 2.44240266]\n",
      " [2.36387363 2.26173487]\n",
      " [2.37721581 2.20750719]\n",
      " [2.36326405 2.26921162]\n",
      " [2.25922711 2.31814974]\n",
      " [2.35778094 2.44799008]\n",
      " [2.51647512 2.40905063]\n",
      " [2.45672479 2.49817316]\n",
      " [2.54377124 2.54750949]\n",
      " [2.65221592 2.67103494]\n",
      " [2.72738443 2.88662312]\n",
      " [3.04354406 3.0063931 ]\n",
      " [3.27437873 3.49117472]\n",
      " [       nan 4.48496783]]\n",
      "num obs\n",
      "[[144185.      0.]\n",
      " [ 87572.  58622.]\n",
      " [ 85088.  65377.]\n",
      " [ 85410.  71406.]\n",
      " [ 84142.  76081.]\n",
      " [ 82309.  79430.]\n",
      " [ 83751.  82015.]\n",
      " [ 84691.  78007.]\n",
      " [ 82615.  82553.]\n",
      " [ 82367.  82308.]\n",
      " [ 82857.  80768.]\n",
      " [ 80092.  78621.]\n",
      " [ 78215.  81462.]\n",
      " [ 78267.  80817.]\n",
      " [ 75023.  81471.]\n",
      " [ 71900.  79924.]\n",
      " [ 69748.  80594.]\n",
      " [ 65264.  78501.]\n",
      " [ 57134.  83112.]\n",
      " [     0. 139616.]]\n",
      "5 minute MA\n",
      "mean\n",
      "[[ 0.10594129         nan]\n",
      " [-0.0006457  -0.06226951]\n",
      " [-0.16139151  0.05240734]\n",
      " [-0.2482364   0.03341267]\n",
      " [-0.32863025 -0.07565962]\n",
      " [-0.26773039  0.02605257]\n",
      " [-0.32425109  0.02545767]\n",
      " [-0.22061605  0.04175933]\n",
      " [-0.34878706  0.03882591]\n",
      " [-0.25152647  0.07857231]\n",
      " [-0.20952432  0.18652147]\n",
      " [-0.10645064  0.17238895]\n",
      " [-0.06509627  0.21086483]\n",
      " [-0.07665301  0.31843125]\n",
      " [-0.09961877  0.3418585 ]\n",
      " [-0.16908879  0.40953036]\n",
      " [ 0.05378453  0.28900888]\n",
      " [-0.09740277  0.36507602]\n",
      " [ 0.03672177  0.18427282]\n",
      " [        nan  0.15807158]]\n",
      "std\n",
      "[[4.51763614        nan]\n",
      " [3.26982021 3.6857665 ]\n",
      " [2.95456818 2.83686861]\n",
      " [2.93541587 2.7118914 ]\n",
      " [2.59062903 2.66868717]\n",
      " [2.52937295 2.43248415]\n",
      " [2.47947292 2.34904627]\n",
      " [2.33571802 2.36936455]\n",
      " [2.36308436 2.26970913]\n",
      " [2.37876608 2.20886573]\n",
      " [2.41475989 2.32515129]\n",
      " [2.35656162 2.43536075]\n",
      " [2.41742625 2.41770927]\n",
      " [2.41527591 2.50813413]\n",
      " [2.48055866 2.72630023]\n",
      " [2.55492967 2.76042581]\n",
      " [2.7701707  2.92320828]\n",
      " [2.93660508 3.20747959]\n",
      " [3.07402596 3.46250262]\n",
      " [       nan 4.46557236]]\n",
      "num obs\n",
      "[[143547.      0.]\n",
      " [ 89306.  60430.]\n",
      " [ 86423.  66921.]\n",
      " [ 85558.  73025.]\n",
      " [ 85643.  76285.]\n",
      " [ 86806.  76747.]\n",
      " [ 84271.  79967.]\n",
      " [ 86242.  79770.]\n",
      " [ 82504.  83960.]\n",
      " [ 83447.  81897.]\n",
      " [ 79838.  79712.]\n",
      " [ 80716.  77509.]\n",
      " [ 76908.  80659.]\n",
      " [ 74177.  82397.]\n",
      " [ 75334.  80382.]\n",
      " [ 72562.  79080.]\n",
      " [ 68198.  78858.]\n",
      " [ 65050.  77185.]\n",
      " [ 63762.  77934.]\n",
      " [     0. 138305.]]\n",
      "10 minute MA\n",
      "mean\n",
      "[[ 0.10358106         nan]\n",
      " [-0.00615257  0.05028899]\n",
      " [-0.26169024 -0.01873185]\n",
      " [-0.2244088  -0.01464372]\n",
      " [-0.135803    0.15882392]\n",
      " [-0.29747291  0.05303072]\n",
      " [-0.25334591 -0.0347068 ]\n",
      " [-0.22707436  0.00172284]\n",
      " [-0.12265399  0.17548268]\n",
      " [-0.17708188  0.19562242]\n",
      " [-0.17039142  0.16354379]\n",
      " [-0.1364665   0.15620788]\n",
      " [-0.08680098  0.28474011]\n",
      " [-0.0260649   0.29065739]\n",
      " [-0.11284191  0.37061088]\n",
      " [-0.0436813   0.29024046]\n",
      " [-0.37114168  0.39142819]\n",
      " [-0.12639945  0.08018812]\n",
      " [-0.09029855  0.25865451]\n",
      " [        nan -0.0230114 ]]\n",
      "std\n",
      "[[4.42956354        nan]\n",
      " [3.5015224  3.05668678]\n",
      " [3.25510145 2.81891624]\n",
      " [3.05280633 2.71686623]\n",
      " [2.7600055  2.41508902]\n",
      " [2.63386427 2.41091623]\n",
      " [2.36424635 2.50664672]\n",
      " [2.4838995  2.32328394]\n",
      " [2.32370398 2.35238658]\n",
      " [2.219574   2.33570119]\n",
      " [2.39517645 2.40282718]\n",
      " [2.48729197 2.36457047]\n",
      " [2.34690876 2.42375554]\n",
      " [2.54144853 2.50767102]\n",
      " [2.60960141 2.82189819]\n",
      " [2.60893572 2.83258265]\n",
      " [2.67981038 2.9380964 ]\n",
      " [2.78480595 3.150044  ]\n",
      " [3.16592739 3.66123503]\n",
      " [       nan 4.30108761]]\n",
      "num obs\n",
      "[[140108.      0.]\n",
      " [ 84950.  66978.]\n",
      " [ 81381.  73669.]\n",
      " [ 83404.  76219.]\n",
      " [ 89420.  74921.]\n",
      " [ 82868.  77543.]\n",
      " [ 87553.  75408.]\n",
      " [ 84984.  80192.]\n",
      " [ 81446.  82701.]\n",
      " [ 88680.  82110.]\n",
      " [ 82298.  79424.]\n",
      " [ 76331.  82458.]\n",
      " [ 74090.  83379.]\n",
      " [ 74100.  78356.]\n",
      " [ 70917.  82182.]\n",
      " [ 74218.  76889.]\n",
      " [ 69815.  78949.]\n",
      " [ 68510.  74781.]\n",
      " [ 68766.  74537.]\n",
      " [     0. 136780.]]\n"
     ]
    }
   ],
   "source": [
    "for time in [1,3,5,10]:\n",
    "    data=pd.read_csv('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10split_2cases_'+str(time)+'min_sma_weightedmean.csv')\n",
    "    length=len(data)\n",
    "    print(time,'minute MA')\n",
    "    print('mean')\n",
    "    print(np.reshape(data.loc[:,'mean'].values,(20,2)))\n",
    "    print('std')\n",
    "    print(np.reshape(data.loc[:,'std'].values,(20,2)))\n",
    "    print('num obs')\n",
    "    print(np.reshape(data.loc[:,'num obs'].values,(20,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
