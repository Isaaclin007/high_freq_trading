{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into 20 categories (10-90% percentile for positive and negative so 10x2) based on SMA 1 minute from past 20 days, \n",
    "#then within each SMA category, separate into quartiles based on cumulative volume in 1 minute\n",
    "#calculate the mean and std of the edge in each case\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from datetime import datetime,timedelta\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA')\n",
    "file_list=os.listdir('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA')\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '2019.01.02.csv',\n",
       " '2019.01.03.csv',\n",
       " '2019.01.04.csv',\n",
       " '2019.01.07.csv',\n",
       " '2019.01.08.csv',\n",
       " '2019.01.09.csv',\n",
       " '2019.01.10.csv',\n",
       " '2019.01.11.csv',\n",
       " '2019.01.14.csv',\n",
       " '2019.01.15.csv',\n",
       " '2019.01.16.csv',\n",
       " '2019.01.17.csv',\n",
       " '2019.01.18.csv',\n",
       " '2019.01.21.csv',\n",
       " '2019.01.22.csv',\n",
       " '2019.01.23.csv',\n",
       " '2019.01.24.csv',\n",
       " '2019.01.25.csv',\n",
       " '2019.01.28.csv',\n",
       " '2019.01.29.csv',\n",
       " '2019.01.30.csv',\n",
       " '2019.01.31.csv',\n",
       " '2019.02.01.csv',\n",
       " '2019.02.11.csv',\n",
       " '2019.02.12.csv',\n",
       " '2019.02.13.csv',\n",
       " '2019.02.14.csv',\n",
       " '2019.02.15.csv',\n",
       " '2019.02.18.csv',\n",
       " '2019.02.19.csv',\n",
       " '2019.02.20.csv',\n",
       " '2019.02.21.csv',\n",
       " '2019.02.22.csv',\n",
       " '2019.02.25.csv',\n",
       " '2019.02.26.csv',\n",
       " '2019.02.27.csv',\n",
       " '2019.02.28.csv',\n",
       " '2019.03.01.csv',\n",
       " '2019.03.04.csv',\n",
       " '2019.03.05.csv',\n",
       " '2019.03.06.csv',\n",
       " '2019.03.07.csv',\n",
       " '2019.03.08.csv',\n",
       " '2019.03.11.csv',\n",
       " '2019.03.12.csv',\n",
       " '2019.03.13.csv',\n",
       " '2019.03.14.csv',\n",
       " '2019.03.15.csv',\n",
       " '2019.03.18.csv',\n",
       " '2019.03.19.csv',\n",
       " '2019.03.20.csv',\n",
       " '2019.03.21.csv',\n",
       " '2019.03.22.csv',\n",
       " '2019.03.25.csv',\n",
       " '2019.03.26.csv',\n",
       " '2019.03.27.csv',\n",
       " '2019.03.28.csv',\n",
       " '2019.03.29.csv',\n",
       " '2019.04.01.csv',\n",
       " '2019.04.02.csv',\n",
       " '2019.04.03.csv',\n",
       " '2019.04.04.csv',\n",
       " '2019.04.08.csv',\n",
       " '2019.04.09.csv',\n",
       " '2019.04.10.csv',\n",
       " '2019.04.11.csv',\n",
       " '2019.04.12.csv',\n",
       " '2019.04.15.csv',\n",
       " '2019.04.16.csv',\n",
       " '2019.04.17.csv',\n",
       " '2019.04.18.csv',\n",
       " '2019.04.19.csv',\n",
       " '2019.04.22.csv',\n",
       " '2019.04.23.csv',\n",
       " '2019.04.24.csv',\n",
       " '2019.04.25.csv',\n",
       " '2019.04.26.csv',\n",
       " '2019.04.29.csv',\n",
       " '2019.04.30.csv',\n",
       " '2019.05.06.csv',\n",
       " '2019.05.07.csv',\n",
       " '2019.05.08.csv',\n",
       " '2019.05.09.csv',\n",
       " 'results']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class categorise():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(7)\n",
    "                else:\n",
    "                    temp.append(8)\n",
    "            if i<0:\n",
    "                if i>self.threshold[0][2]:\n",
    "                    temp.append(4)\n",
    "                elif i>self.threshold[0][1]:\n",
    "                    temp.append(3)\n",
    "                elif i>self.threshold[0][0]:\n",
    "                    temp.append(2)\n",
    "                else:\n",
    "                    temp.append(1)\n",
    "        return np.asarray(temp)\n",
    "    \n",
    "class categorise_simple():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[25,50,75]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        self.threshold.append(np.percentile(array,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                else:\n",
    "                    temp.append(4)\n",
    "        return np.asarray(temp)    \n",
    "    \n",
    "class categorise_10():\n",
    "    def __init__(self):\n",
    "        self.threshold=[]\n",
    "        self.percentiles=[10,20,30,40,50,60,70,80,90]\n",
    "        \n",
    "    def fit(self,array):\n",
    "        positive=array[array>0]\n",
    "        negative=array[array<0]\n",
    "        self.threshold.append(np.percentile(negative,self.percentiles))   \n",
    "        self.threshold.append(np.percentile(positive,self.percentiles))\n",
    "     \n",
    "    def return_quartile(self,array):\n",
    "        temp=[]\n",
    "        for i in array:\n",
    "            if i>=0:\n",
    "                if i<self.threshold[1][0]:\n",
    "                    temp.append(11)\n",
    "                elif i<self.threshold[1][1]:\n",
    "                    temp.append(12)\n",
    "                elif i<self.threshold[1][2]:\n",
    "                    temp.append(13)\n",
    "                elif i<self.threshold[1][3]:\n",
    "                    temp.append(14)\n",
    "                elif i<self.threshold[1][4]:\n",
    "                    temp.append(15)\n",
    "                elif i<self.threshold[1][5]:\n",
    "                    temp.append(16)\n",
    "                elif i<self.threshold[1][6]:\n",
    "                    temp.append(17)\n",
    "                elif i<self.threshold[1][7]:\n",
    "                    temp.append(18)\n",
    "                elif i<self.threshold[1][8]:\n",
    "                    temp.append(19)                    \n",
    "                else:\n",
    "                    temp.append(20)\n",
    "            if i<0:\n",
    "                if i<self.threshold[0][0]:\n",
    "                    temp.append(1)\n",
    "                elif i<self.threshold[0][1]:\n",
    "                    temp.append(2)\n",
    "                elif i<self.threshold[0][2]:\n",
    "                    temp.append(3)\n",
    "                elif i<self.threshold[0][3]:\n",
    "                    temp.append(4)\n",
    "                elif i<self.threshold[0][4]:\n",
    "                    temp.append(5)\n",
    "                elif i<self.threshold[0][5]:\n",
    "                    temp.append(6)\n",
    "                elif i<self.threshold[0][6]:\n",
    "                    temp.append(7)\n",
    "                elif i<self.threshold[0][7]:\n",
    "                    temp.append(8)\n",
    "                elif i<self.threshold[0][8]:\n",
    "                    temp.append(9)                    \n",
    "                else:\n",
    "                    temp.append(10)\n",
    "        return np.asarray(temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_smart_price(dataset):\n",
    "    data=dataset[:]\n",
    "    \n",
    "    #to combat the limit up event, where price is set to 0. \n",
    "    rows=(data.loc[:,'BidPrice1']==0) #count rows of bid price equal 0\n",
    "    if (np.any(rows)): #if there is such a row\n",
    "        data.at[rows,'BidPrice1']=data.loc[rows,'AskPrice1'] #for that row, assign ask price to it\n",
    "    rows=(data.loc[:,'AskPrice1']==0) #do the same for ask price\n",
    "    if (np.any(rows)):\n",
    "        data.at[rows,'AskPrice1']=data.loc[rows,'BidPrice1'] \n",
    "        \n",
    "    data['smart_price']=data.loc[:,'BidPrice1']*data.loc[:,'AskVol1']+data.loc[:,'AskPrice1']*data.loc[:,'BidVol1']\n",
    "    data.at[:,'smart_price']=data.loc[:,'smart_price']/(data.loc[:,['BidVol1','AskVol1']].sum(axis=1))  \n",
    "    return data\n",
    "\n",
    "def calc_present_vol(dataset):\n",
    "    data=dataset[:]\n",
    "    data['current_vol']=data.loc[:,'Volume'].diff().fillna(0)/2\n",
    "    return data\n",
    "\n",
    "def calc_future_price(dataset,time_ahead=30):\n",
    "    data=dataset[:]\n",
    "    future_price=[]\n",
    "    length=len(data)\n",
    "    for i in range(len(data)):\n",
    "        current_time=data[i,44]+timedelta(seconds=time_ahead)\n",
    "        #print(data[i,44])\n",
    "        j=0\n",
    "        #print(current_time)\n",
    "        while((i+j)<length and current_time>data[(i+j),44]):\n",
    "            j+=1\n",
    "        #print(i,j,(data[(i+j-1),44]))\n",
    "        if (i+j)<length:\n",
    "            future_price.append(data[(i+j),51]) #51 is the index for smart price            \n",
    "        else:\n",
    "            future_price.append(np.nan)\n",
    "    future_price=np.asarray(future_price)\n",
    "    future_price=np.expand_dims(future_price,axis=1)\n",
    "    return np.concatenate((data,future_price),axis=1)\n",
    "\n",
    "\n",
    "def calc_edge(dataset):\n",
    "    data=dataset.copy()\n",
    "    temp=data[:,53]-data[:,51]\n",
    "    temp=np.expand_dims(temp,axis=1)\n",
    "    return np.concatenate((data,temp),axis=1)\n",
    "\n",
    "def set_index(dataset):\n",
    "    data=dataset[:]\n",
    "    index=data[:,44]\n",
    "    new_index=[]\n",
    "    for j in range(len(index)):\n",
    "        i=str(index[j]*1000)\n",
    "        if len(i)==11:\n",
    "            i='0'+i\n",
    "        i=i[:-10]+':'+i[-10:]\n",
    "        i=i[:-8]+':'+i[-8:]\n",
    "        i=i[:-6]+':'+i[-6:]\n",
    "        new_index.append(datetime.strptime(i,\"%H:%M:%S:%f\"))\n",
    "    data[:,44]=new_index\n",
    "    return data\n",
    "\n",
    "def calc_sma_fast(dataset,duration=1): #faster way to calculate SMA, 0.05 seconds for 5000 rows\n",
    "    data=dataset[:]\n",
    "    sma_values=[] \n",
    "    smart_sum=np.cumsum(data[:,51])\n",
    "    for i in range(len(data)):\n",
    "        last_time=data[i,44]-timedelta(minutes=duration)\n",
    "        j=220*duration#4x60=240\n",
    "        while(i-j>0 and data[i-j,44]>last_time):\n",
    "            j+=1\n",
    "        if (i-j>=0):\n",
    "            sma=(smart_sum[i]-smart_sum[i-j])/(j)\n",
    "            sma_values.append(sma)\n",
    "        else:\n",
    "            sma=smart_sum[i]/(i+1)\n",
    "            sma_values.append(sma)\n",
    "\n",
    "    sma_values=np.asarray(sma_values)\n",
    "    sma_values=data[:,51]-sma_values\n",
    "    sma_values=np.expand_dims(sma_values,axis=1)\n",
    "    return np.concatenate((data,sma_values),axis=1)  \n",
    "\n",
    "def calc_past_vol(dataset,duration=1): #\n",
    "    data=dataset[:]\n",
    "    vol_values=[] \n",
    "    vol_sum=np.cumsum(data[:,52])\n",
    "    for i in range(len(data)):\n",
    "        last_time=data[i,44]-timedelta(minutes=duration)\n",
    "        j=220*duration#4x60=240\n",
    "        while(i-j>0 and data[i-j,44]>last_time):\n",
    "            j+=1\n",
    "        if (i-j>=0):\n",
    "            vol=(vol_sum[i]-vol_sum[i-j])\n",
    "            vol_values.append(vol)\n",
    "        else:\n",
    "            vol=vol_sum[i]\n",
    "            vol_values.append(vol)\n",
    "    vol_values=np.asarray(vol_values)\n",
    "    vol_values=np.expand_dims(vol_values,axis=1)\n",
    "    return np.concatenate((data,vol_values),axis=1) #52  \n",
    "\n",
    "def process(dataset,sma_duration=1,vol_duration=1):\n",
    "    data=dataset[:]\n",
    "    data=calc_smart_price(data) #51\n",
    "    data=calc_present_vol(data).values #52\n",
    "    data=set_index(data)\n",
    "    data=calc_future_price(data) #53\n",
    "    data=calc_edge(data) #54\n",
    "    data=calc_sma_fast(data,duration=sma_duration) #55\n",
    "    data=calc_past_vol(data,duration=vol_duration) #56\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.01.02.csv read\n",
      "2019.01.03.csv read\n",
      "2019.01.04.csv read\n",
      "2019.01.07.csv read\n",
      "2019.01.08.csv read\n",
      "2019.01.09.csv read\n",
      "2019.01.10.csv read\n",
      "2019.01.11.csv read\n",
      "2019.01.14.csv read\n",
      "2019.01.15.csv read\n",
      "2019.01.16.csv read\n",
      "2019.01.17.csv read\n",
      "2019.01.18.csv read\n",
      "2019.01.21.csv read\n",
      "2019.01.22.csv read\n",
      "2019.01.23.csv read\n",
      "2019.01.24.csv read\n",
      "2019.01.25.csv read\n",
      "2019.01.28.csv read\n",
      "2019.01.29.csv read\n",
      "2019.01.30.csv read\n",
      "2019.01.31.csv read\n",
      "2019.02.01.csv read\n",
      "2019.02.11.csv read\n",
      "2019.02.12.csv read\n",
      "2019.02.13.csv read\n",
      "2019.02.14.csv read\n",
      "2019.02.15.csv read\n",
      "2019.02.18.csv read\n",
      "2019.02.19.csv read\n",
      "2019.02.20.csv read\n",
      "2019.02.21.csv read\n",
      "2019.02.22.csv read\n",
      "2019.02.25.csv read\n",
      "2019.02.26.csv read\n",
      "2019.02.27.csv read\n",
      "2019.02.28.csv read\n",
      "2019.03.01.csv read\n",
      "2019.03.04.csv read\n",
      "2019.03.05.csv read\n",
      "2019.03.06.csv read\n",
      "2019.03.07.csv read\n",
      "2019.03.08.csv read\n",
      "2019.03.11.csv read\n",
      "2019.03.12.csv read\n",
      "2019.03.13.csv read\n",
      "2019.03.14.csv read\n",
      "2019.03.15.csv read\n",
      "2019.03.18.csv read\n",
      "2019.03.19.csv read\n",
      "2019.03.20.csv read\n",
      "2019.03.21.csv read\n",
      "2019.03.22.csv read\n",
      "2019.03.25.csv read\n",
      "2019.03.26.csv read\n",
      "2019.03.27.csv read\n",
      "2019.03.28.csv read\n",
      "2019.03.29.csv read\n",
      "2019.04.01.csv read\n",
      "2019.04.02.csv read\n",
      "2019.04.03.csv read\n",
      "2019.04.04.csv read\n",
      "2019.04.08.csv read\n",
      "2019.04.09.csv read\n",
      "2019.04.10.csv read\n",
      "2019.04.11.csv read\n",
      "2019.04.12.csv read\n",
      "2019.04.15.csv read\n",
      "2019.04.16.csv read\n",
      "2019.04.17.csv read\n",
      "2019.04.18.csv read\n",
      "2019.04.19.csv read\n",
      "2019.04.22.csv read\n",
      "2019.04.23.csv read\n",
      "2019.04.24.csv read\n",
      "2019.04.25.csv read\n",
      "2019.04.26.csv read\n",
      "2019.04.29.csv read\n",
      "2019.04.30.csv read\n",
      "2019.05.06.csv read\n",
      "2019.05.07.csv read\n",
      "2019.05.08.csv read\n",
      "2019.05.09.csv read\n"
     ]
    }
   ],
   "source": [
    "file_list[1][-3:]\n",
    "df_list=[]\n",
    "name_list=[]\n",
    "path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/'\n",
    "for file in file_list: #read all files and add them to file_list\n",
    "    if file[-3:]=='csv': #check if file is a CSV\n",
    "        name_list.append(file)\n",
    "        df_list.append(process(pd.read_csv(path+file),sma_duration=1))\n",
    "        print(file,'read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.01.29.csv\n",
      "2019.01.30.csv\n",
      "2019.01.31.csv\n",
      "2019.02.01.csv\n",
      "2019.02.11.csv\n",
      "2019.02.12.csv\n",
      "2019.02.13.csv\n",
      "2019.02.14.csv\n",
      "2019.02.15.csv\n",
      "2019.02.18.csv\n",
      "2019.02.19.csv\n",
      "2019.02.20.csv\n",
      "2019.02.21.csv\n",
      "2019.02.22.csv\n",
      "2019.02.25.csv\n",
      "2019.02.26.csv\n",
      "2019.02.27.csv\n",
      "2019.02.28.csv\n",
      "2019.03.01.csv\n",
      "2019.03.04.csv\n",
      "2019.03.05.csv\n",
      "2019.03.06.csv\n",
      "2019.03.07.csv\n",
      "2019.03.08.csv\n",
      "2019.03.11.csv\n",
      "2019.03.12.csv\n",
      "2019.03.13.csv\n",
      "2019.03.14.csv\n",
      "2019.03.15.csv\n",
      "2019.03.18.csv\n",
      "2019.03.19.csv\n",
      "2019.03.20.csv\n",
      "2019.03.21.csv\n",
      "2019.03.22.csv\n",
      "2019.03.25.csv\n",
      "2019.03.26.csv\n",
      "2019.03.27.csv\n",
      "2019.03.28.csv\n",
      "2019.03.29.csv\n",
      "2019.04.01.csv\n",
      "2019.04.02.csv\n",
      "2019.04.03.csv\n",
      "2019.04.04.csv\n",
      "2019.04.08.csv\n",
      "2019.04.09.csv\n",
      "2019.04.10.csv\n",
      "2019.04.11.csv\n",
      "2019.04.12.csv\n",
      "2019.04.15.csv\n",
      "2019.04.16.csv\n",
      "2019.04.17.csv\n",
      "2019.04.18.csv\n",
      "2019.04.19.csv\n",
      "2019.04.22.csv\n",
      "2019.04.23.csv\n",
      "2019.04.24.csv\n",
      "2019.04.25.csv\n",
      "2019.04.26.csv\n",
      "2019.04.29.csv\n",
      "2019.04.30.csv\n",
      "2019.05.06.csv\n",
      "2019.05.07.csv\n",
      "2019.05.08.csv\n",
      "2019.05.09.csv\n",
      "done /Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10sma,6vol_1min,1min_sma,vol_mean.csv\n"
     ]
    }
   ],
   "source": [
    "df_path='/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/'\n",
    "\n",
    "final_df=pd.DataFrame()    \n",
    "\n",
    "for i in range(len(df_list)): #for each 20 day rolling window\n",
    "    if i<19:\n",
    "        continue\n",
    "    print(name_list[i])\n",
    "\n",
    "    #get -19 day\n",
    "    sma=df_list[i-19][:,55].copy() #column for SMA\n",
    "    vol=df_list[i-19][:,56].copy()\n",
    "    \n",
    "    #get -18 to 0 day (19 days in total)\n",
    "    for k in range((i-18),i+1): #get 20 day moving averages\n",
    "        sma=np.concatenate((sma,df_list[k][:,55].copy()))\n",
    "        vol=np.concatenate((vol,df_list[k][:,56].copy()))\n",
    "        \n",
    "    cat_sma=categorise_10()\n",
    "    cat_sma.fit(sma) #calculate quartile thresholds for past 20 days\n",
    "    \n",
    "    #get categories for past 20 days\n",
    "    cat_sma_20=(cat_sma.return_quartile(sma))   \n",
    "\n",
    "    #get x,y for regression\n",
    "    x_today=df_list[i][:,55].copy().astype(float) #column for SMA     \n",
    "    y_today=df_list[i][:,54].copy().astype(float) #column for edge\n",
    "    \n",
    "    vol_today=df_list[i][:,56].copy()    \n",
    "    #removing all NA\n",
    "    isnum=(~np.isnan(x_today)) & (~np.isnan(y_today))\n",
    "    #get categories of today's sma  \n",
    "    cat_x_today=cat_sma.return_quartile(x_today)\n",
    "    \n",
    "    \n",
    "    reg_result={}\n",
    "    reg_result['date']=name_list[i]\n",
    "    reg_result['total_obs']=len(x_today[isnum])   \n",
    "    \n",
    "    for cat in range(1,21):\n",
    "        #check past 20 days quartiles and filter volume by category\n",
    "        vol_fit=vol[cat_sma_20==cat].copy()\n",
    "\n",
    "        #simple quartile categorisation\n",
    "        cat_vol=categorise_simple()\n",
    "        cat_vol.fit(vol_fit)\n",
    "    \n",
    "        \n",
    "        #today's sma filter\n",
    "        sma_filter_today=(cat_x_today==cat)\n",
    "        #today's vol categories\n",
    "        cat_vol_today=cat_vol.return_quartile(vol_today)\n",
    "\n",
    "\n",
    "        for quartile in [1,2,3,4]:\n",
    "\n",
    "            filtered= (isnum & sma_filter_today) #filtering NA and sma quartile\n",
    "            filtered= filtered & (cat_vol_today==quartile) #filtering volume\n",
    "            new_y=y_today[filtered].copy()\n",
    "\n",
    "            q='ma_cat_'+str(cat)+'_vol_quartile'+str(quartile)+'_'\n",
    "            if (len(new_y)!=0):\n",
    "\n",
    "                reg_result[(q+'mean')]=np.mean(new_y)\n",
    "                reg_result[(q+'std')]=np.std(new_y)\n",
    "                reg_result[(q+'num_obs')]=len(new_y)\n",
    "\n",
    "            else:\n",
    "\n",
    "                reg_result[(q+'mean')]=np.nan\n",
    "                reg_result[(q+'std')]=np.nan\n",
    "                reg_result[(q+'num_obs')]='0'\n",
    "\n",
    "    final_df=final_df.append(reg_result,ignore_index=True)                \n",
    "temp=df_path+'result_10sma,6vol_1min,1min_sma,vol_mean.csv'\n",
    "final_df.to_csv(temp)\n",
    "print('done',temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ma_cat_1_vol_quartile1_mean 0.07843796890674151\n",
      "ma_cat_1_vol_quartile2_mean -0.23048597495827733\n",
      "ma_cat_1_vol_quartile3_mean 0.11534965594026822\n",
      "ma_cat_1_vol_quartile4_mean 0.5988207968812828\n",
      "ma_cat_2_vol_quartile1_mean -0.13283748203919638\n",
      "ma_cat_2_vol_quartile2_mean 0.05105563800246096\n",
      "ma_cat_2_vol_quartile3_mean -0.178849146807583\n",
      "ma_cat_2_vol_quartile4_mean 0.026943247547413358\n",
      "ma_cat_3_vol_quartile1_mean -0.15872109880519042\n",
      "ma_cat_3_vol_quartile2_mean -0.06577319023028595\n",
      "ma_cat_3_vol_quartile3_mean -0.24579427775494966\n",
      "ma_cat_3_vol_quartile4_mean -0.050043537137311744\n",
      "ma_cat_4_vol_quartile1_mean -0.20478466771871634\n",
      "ma_cat_4_vol_quartile2_mean -0.06841721999877456\n",
      "ma_cat_4_vol_quartile3_mean -0.10002672376336848\n",
      "ma_cat_4_vol_quartile4_mean 0.015620905127824658\n",
      "ma_cat_5_vol_quartile1_mean -0.24717686543640344\n",
      "ma_cat_5_vol_quartile2_mean -0.17034711143877768\n",
      "ma_cat_5_vol_quartile3_mean -0.22237342327677406\n",
      "ma_cat_5_vol_quartile4_mean 0.07284985029921925\n",
      "ma_cat_6_vol_quartile1_mean -0.23010978598393186\n",
      "ma_cat_6_vol_quartile2_mean -0.18772595854747637\n",
      "ma_cat_6_vol_quartile3_mean -0.12555670745253605\n",
      "ma_cat_6_vol_quartile4_mean -0.05189646140602226\n",
      "ma_cat_7_vol_quartile1_mean -0.1566382126123556\n",
      "ma_cat_7_vol_quartile2_mean -0.16381253610134874\n",
      "ma_cat_7_vol_quartile3_mean -0.05347151768842986\n",
      "ma_cat_7_vol_quartile4_mean -0.04049585793407185\n",
      "ma_cat_8_vol_quartile1_mean -0.2527403721092222\n",
      "ma_cat_8_vol_quartile2_mean -0.2113911599274423\n",
      "ma_cat_8_vol_quartile3_mean -0.10949278808754212\n",
      "ma_cat_8_vol_quartile4_mean -0.01679177784879844\n",
      "ma_cat_9_vol_quartile1_mean -0.21805336394578492\n",
      "ma_cat_9_vol_quartile2_mean -0.1716697807974128\n",
      "ma_cat_9_vol_quartile3_mean -0.1517110047383781\n",
      "ma_cat_9_vol_quartile4_mean -0.016165148592203808\n",
      "ma_cat_10_vol_quartile1_mean -0.0754943051087126\n",
      "ma_cat_10_vol_quartile2_mean -0.05488275185048013\n",
      "ma_cat_10_vol_quartile3_mean 0.019441202575934728\n",
      "ma_cat_10_vol_quartile4_mean -0.023607751123378037\n",
      "ma_cat_11_vol_quartile1_mean -0.009090399499424334\n",
      "ma_cat_11_vol_quartile2_mean -0.06663311567812379\n",
      "ma_cat_11_vol_quartile3_mean 0.0186861935133021\n",
      "ma_cat_11_vol_quartile4_mean 0.08437054443840265\n",
      "ma_cat_12_vol_quartile1_mean 0.12454441916920858\n",
      "ma_cat_12_vol_quartile2_mean -0.0009675916051335224\n",
      "ma_cat_12_vol_quartile3_mean 0.0028139837026468694\n",
      "ma_cat_12_vol_quartile4_mean 0.11445081944503174\n",
      "ma_cat_13_vol_quartile1_mean 0.0739862978746506\n",
      "ma_cat_13_vol_quartile2_mean 0.17285095747196816\n",
      "ma_cat_13_vol_quartile3_mean 0.02678769141300344\n",
      "ma_cat_13_vol_quartile4_mean 0.07144232961863947\n",
      "ma_cat_14_vol_quartile1_mean 0.06699674687687382\n",
      "ma_cat_14_vol_quartile2_mean 0.17697387233273562\n",
      "ma_cat_14_vol_quartile3_mean 0.1097173979552134\n",
      "ma_cat_14_vol_quartile4_mean -0.02173618714879303\n",
      "ma_cat_15_vol_quartile1_mean 0.08352516013548501\n",
      "ma_cat_15_vol_quartile2_mean 0.15526393076492223\n",
      "ma_cat_15_vol_quartile3_mean 0.009126609843816896\n",
      "ma_cat_15_vol_quartile4_mean 0.10020403253792272\n",
      "ma_cat_16_vol_quartile1_mean 0.27470054786608145\n",
      "ma_cat_16_vol_quartile2_mean 0.137452627521566\n",
      "ma_cat_16_vol_quartile3_mean 0.0838480468600085\n",
      "ma_cat_16_vol_quartile4_mean 0.13445329897603608\n",
      "ma_cat_17_vol_quartile1_mean 0.1633597672835126\n",
      "ma_cat_17_vol_quartile2_mean 0.19592326191369208\n",
      "ma_cat_17_vol_quartile3_mean 0.13778884494151988\n",
      "ma_cat_17_vol_quartile4_mean 0.07450819113689149\n",
      "ma_cat_18_vol_quartile1_mean 0.2591274625981985\n",
      "ma_cat_18_vol_quartile2_mean 0.1904758188973191\n",
      "ma_cat_18_vol_quartile3_mean 0.09879136502270093\n",
      "ma_cat_18_vol_quartile4_mean -0.009714679715891373\n",
      "ma_cat_19_vol_quartile1_mean 0.39241841363979685\n",
      "ma_cat_19_vol_quartile2_mean 0.16436613019632718\n",
      "ma_cat_19_vol_quartile3_mean -0.001247095280177704\n",
      "ma_cat_19_vol_quartile4_mean 0.11328626420681225\n",
      "ma_cat_20_vol_quartile1_mean 0.2743441154390815\n",
      "ma_cat_20_vol_quartile2_mean 0.2010649774453047\n",
      "ma_cat_20_vol_quartile3_mean 0.11130333219553282\n",
      "ma_cat_20_vol_quartile4_mean -0.5510075069124497\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10sma,6vol_1min,1min_sma,vol_mean.csv')\n",
    "x=[]\n",
    "for ma_cat in range(1,21):\n",
    "    for vol_cat in range(1,5):\n",
    "        col='ma_cat_'+str(ma_cat)+'_vol_quartile'+str(vol_cat)+'_mean'\n",
    "        mean=data.loc[:,col].mean()\n",
    "        x.append(mean)\n",
    "        print(col,mean)\n",
    "x=np.asarray(x)\n",
    "x=np.reshape(x,(20,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07843797, -0.23048597,  0.11534966,  0.5988208 ],\n",
       "       [-0.13283748,  0.05105564, -0.17884915,  0.02694325],\n",
       "       [-0.1587211 , -0.06577319, -0.24579428, -0.05004354],\n",
       "       [-0.20478467, -0.06841722, -0.10002672,  0.01562091],\n",
       "       [-0.24717687, -0.17034711, -0.22237342,  0.07284985],\n",
       "       [-0.23010979, -0.18772596, -0.12555671, -0.05189646],\n",
       "       [-0.15663821, -0.16381254, -0.05347152, -0.04049586],\n",
       "       [-0.25274037, -0.21139116, -0.10949279, -0.01679178],\n",
       "       [-0.21805336, -0.17166978, -0.151711  , -0.01616515],\n",
       "       [-0.07549431, -0.05488275,  0.0194412 , -0.02360775],\n",
       "       [-0.0090904 , -0.06663312,  0.01868619,  0.08437054],\n",
       "       [ 0.12454442, -0.00096759,  0.00281398,  0.11445082],\n",
       "       [ 0.0739863 ,  0.17285096,  0.02678769,  0.07144233],\n",
       "       [ 0.06699675,  0.17697387,  0.1097174 , -0.02173619],\n",
       "       [ 0.08352516,  0.15526393,  0.00912661,  0.10020403],\n",
       "       [ 0.27470055,  0.13745263,  0.08384805,  0.1344533 ],\n",
       "       [ 0.16335977,  0.19592326,  0.13778884,  0.07450819],\n",
       "       [ 0.25912746,  0.19047582,  0.09879137, -0.00971468],\n",
       "       [ 0.39241841,  0.16436613, -0.0012471 ,  0.11328626],\n",
       "       [ 0.27434412,  0.20106498,  0.11130333, -0.55100751]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ma_cat_1_vol_quartile1_mean 0.8166629282975199\n",
      "ma_cat_1_vol_quartile2_mean 1.0714726382302857\n",
      "ma_cat_1_vol_quartile3_mean 1.4279569903225486\n",
      "ma_cat_1_vol_quartile4_mean 1.9979839908576902\n",
      "ma_cat_2_vol_quartile1_mean 0.7206237858339807\n",
      "ma_cat_2_vol_quartile2_mean 0.6343679558111511\n",
      "ma_cat_2_vol_quartile3_mean 0.8744186266362368\n",
      "ma_cat_2_vol_quartile4_mean 1.1593565652150544\n",
      "ma_cat_3_vol_quartile1_mean 0.5818745100439409\n",
      "ma_cat_3_vol_quartile2_mean 0.6907587583000138\n",
      "ma_cat_3_vol_quartile3_mean 0.6499411066192667\n",
      "ma_cat_3_vol_quartile4_mean 0.9053290863372553\n",
      "ma_cat_4_vol_quartile1_mean 0.5219226731410466\n",
      "ma_cat_4_vol_quartile2_mean 0.537662517072484\n",
      "ma_cat_4_vol_quartile3_mean 0.5365405610082081\n",
      "ma_cat_4_vol_quartile4_mean 0.7296912113226797\n",
      "ma_cat_5_vol_quartile1_mean 0.5838094914603221\n",
      "ma_cat_5_vol_quartile2_mean 0.40843531506057534\n",
      "ma_cat_5_vol_quartile3_mean 0.5449168537479936\n",
      "ma_cat_5_vol_quartile4_mean 0.6426291097701372\n",
      "ma_cat_6_vol_quartile1_mean 0.5998096831461123\n",
      "ma_cat_6_vol_quartile2_mean 0.5676035336033621\n",
      "ma_cat_6_vol_quartile3_mean 0.5191269254582135\n",
      "ma_cat_6_vol_quartile4_mean 0.6310581306417059\n",
      "ma_cat_7_vol_quartile1_mean 0.41161562732058843\n",
      "ma_cat_7_vol_quartile2_mean 0.50266522469342\n",
      "ma_cat_7_vol_quartile3_mean 0.45824383182193823\n",
      "ma_cat_7_vol_quartile4_mean 0.5517922584430703\n",
      "ma_cat_8_vol_quartile1_mean 0.43911721498980105\n",
      "ma_cat_8_vol_quartile2_mean 0.3940553455752767\n",
      "ma_cat_8_vol_quartile3_mean 0.46537357705177984\n",
      "ma_cat_8_vol_quartile4_mean 0.5321622352505613\n",
      "ma_cat_9_vol_quartile1_mean 0.494765924708478\n",
      "ma_cat_9_vol_quartile2_mean 0.4501643324210821\n",
      "ma_cat_9_vol_quartile3_mean 0.5534371094449188\n",
      "ma_cat_9_vol_quartile4_mean 0.5215241609520342\n",
      "ma_cat_10_vol_quartile1_mean 0.7162953069214004\n",
      "ma_cat_10_vol_quartile2_mean 0.480853813506507\n",
      "ma_cat_10_vol_quartile3_mean 0.4165391471198306\n",
      "ma_cat_10_vol_quartile4_mean 0.5846109671748644\n",
      "ma_cat_11_vol_quartile1_mean 0.5459270159735314\n",
      "ma_cat_11_vol_quartile2_mean 0.41313902078683923\n",
      "ma_cat_11_vol_quartile3_mean 0.5529749013811627\n",
      "ma_cat_11_vol_quartile4_mean 0.4369541450095148\n",
      "ma_cat_12_vol_quartile1_mean 0.6772586046716793\n",
      "ma_cat_12_vol_quartile2_mean 0.5136658138689012\n",
      "ma_cat_12_vol_quartile3_mean 0.4577911982190232\n",
      "ma_cat_12_vol_quartile4_mean 0.47884609954558566\n",
      "ma_cat_13_vol_quartile1_mean 0.42865416608207724\n",
      "ma_cat_13_vol_quartile2_mean 0.4355156075837466\n",
      "ma_cat_13_vol_quartile3_mean 0.5328670219591111\n",
      "ma_cat_13_vol_quartile4_mean 0.4706944054107266\n",
      "ma_cat_14_vol_quartile1_mean 0.4834202069299063\n",
      "ma_cat_14_vol_quartile2_mean 0.47696762748938043\n",
      "ma_cat_14_vol_quartile3_mean 0.4990653500380326\n",
      "ma_cat_14_vol_quartile4_mean 0.5747575868313303\n",
      "ma_cat_15_vol_quartile1_mean 0.4236633390451836\n",
      "ma_cat_15_vol_quartile2_mean 0.4640154196670763\n",
      "ma_cat_15_vol_quartile3_mean 0.4940841069410133\n",
      "ma_cat_15_vol_quartile4_mean 0.6161371898098761\n",
      "ma_cat_16_vol_quartile1_mean 0.4797487181678494\n",
      "ma_cat_16_vol_quartile2_mean 0.5531766073080655\n",
      "ma_cat_16_vol_quartile3_mean 0.5368616526314993\n",
      "ma_cat_16_vol_quartile4_mean 0.615081039931705\n",
      "ma_cat_17_vol_quartile1_mean 0.6051295508309482\n",
      "ma_cat_17_vol_quartile2_mean 0.5498445863543122\n",
      "ma_cat_17_vol_quartile3_mean 0.5131711854562916\n",
      "ma_cat_17_vol_quartile4_mean 0.681242091907328\n",
      "ma_cat_18_vol_quartile1_mean 0.671961724995911\n",
      "ma_cat_18_vol_quartile2_mean 0.6256957497478457\n",
      "ma_cat_18_vol_quartile3_mean 0.7092083254901251\n",
      "ma_cat_18_vol_quartile4_mean 0.892697564787778\n",
      "ma_cat_19_vol_quartile1_mean 0.7989713407498632\n",
      "ma_cat_19_vol_quartile2_mean 0.883849053095509\n",
      "ma_cat_19_vol_quartile3_mean 0.889216203550848\n",
      "ma_cat_19_vol_quartile4_mean 0.9554290885850615\n",
      "ma_cat_20_vol_quartile1_mean 1.0021403878193047\n",
      "ma_cat_20_vol_quartile2_mean 1.2456938096404726\n",
      "ma_cat_20_vol_quartile3_mean 1.6620614034631234\n",
      "ma_cat_20_vol_quartile4_mean 2.049087324130189\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('/Users/hudsonyeo/Desktop/Python/leo/data/day/TA/results/result_10sma,6vol_1min,1min_sma,vol_mean.csv')\n",
    "x_std=[]\n",
    "for ma_cat in range(1,21):\n",
    "    for vol_cat in range(1,5):\n",
    "        col='ma_cat_'+str(ma_cat)+'_vol_quartile'+str(vol_cat)+'_mean'\n",
    "        std=data.loc[:,col].std()\n",
    "        x_std.append(std)\n",
    "        print(col,std)\n",
    "x_std=np.asarray(x_std)\n",
    "x_std=np.reshape(x_std,(20,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81666293, 1.07147264, 1.42795699, 1.99798399],\n",
       "       [0.72062379, 0.63436796, 0.87441863, 1.15935657],\n",
       "       [0.58187451, 0.69075876, 0.64994111, 0.90532909],\n",
       "       [0.52192267, 0.53766252, 0.53654056, 0.72969121],\n",
       "       [0.58380949, 0.40843532, 0.54491685, 0.64262911],\n",
       "       [0.59980968, 0.56760353, 0.51912693, 0.63105813],\n",
       "       [0.41161563, 0.50266522, 0.45824383, 0.55179226],\n",
       "       [0.43911721, 0.39405535, 0.46537358, 0.53216224],\n",
       "       [0.49476592, 0.45016433, 0.55343711, 0.52152416],\n",
       "       [0.71629531, 0.48085381, 0.41653915, 0.58461097],\n",
       "       [0.54592702, 0.41313902, 0.5529749 , 0.43695415],\n",
       "       [0.6772586 , 0.51366581, 0.4577912 , 0.4788461 ],\n",
       "       [0.42865417, 0.43551561, 0.53286702, 0.47069441],\n",
       "       [0.48342021, 0.47696763, 0.49906535, 0.57475759],\n",
       "       [0.42366334, 0.46401542, 0.49408411, 0.61613719],\n",
       "       [0.47974872, 0.55317661, 0.53686165, 0.61508104],\n",
       "       [0.60512955, 0.54984459, 0.51317119, 0.68124209],\n",
       "       [0.67196172, 0.62569575, 0.70920833, 0.89269756],\n",
       "       [0.79897134, 0.88384905, 0.8892162 , 0.95542909],\n",
       "       [1.00214039, 1.24569381, 1.6620614 , 2.04908732]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
